// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: yarn_service_protos.proto

package org.spiderdt.hadoop.yarn.proto;

public final class YarnServiceProtos {
  private YarnServiceProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  /**
   * Protobuf enum {@code hadoop.yarn.SchedulerResourceTypes}
   */
  public enum SchedulerResourceTypes
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MEMORY = 0;</code>
     */
    MEMORY(0),
    /**
     * <code>CPU = 1;</code>
     */
    CPU(1),
    ;

    /**
     * <code>MEMORY = 0;</code>
     */
    public static final int MEMORY_VALUE = 0;
    /**
     * <code>CPU = 1;</code>
     */
    public static final int CPU_VALUE = 1;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static SchedulerResourceTypes valueOf(int value) {
      return forNumber(value);
    }

    public static SchedulerResourceTypes forNumber(int value) {
      switch (value) {
        case 0: return MEMORY;
        case 1: return CPU;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<SchedulerResourceTypes>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        SchedulerResourceTypes> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<SchedulerResourceTypes>() {
            public SchedulerResourceTypes findValueByNumber(int number) {
              return SchedulerResourceTypes.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final SchedulerResourceTypes[] VALUES = values();

    public static SchedulerResourceTypes valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private SchedulerResourceTypes(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.SchedulerResourceTypes)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.ApplicationsRequestScopeProto}
   */
  public enum ApplicationsRequestScopeProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ALL = 0;</code>
     */
    ALL(0),
    /**
     * <code>VIEWABLE = 1;</code>
     */
    VIEWABLE(1),
    /**
     * <code>OWN = 2;</code>
     */
    OWN(2),
    ;

    /**
     * <code>ALL = 0;</code>
     */
    public static final int ALL_VALUE = 0;
    /**
     * <code>VIEWABLE = 1;</code>
     */
    public static final int VIEWABLE_VALUE = 1;
    /**
     * <code>OWN = 2;</code>
     */
    public static final int OWN_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ApplicationsRequestScopeProto valueOf(int value) {
      return forNumber(value);
    }

    public static ApplicationsRequestScopeProto forNumber(int value) {
      switch (value) {
        case 0: return ALL;
        case 1: return VIEWABLE;
        case 2: return OWN;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ApplicationsRequestScopeProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        ApplicationsRequestScopeProto> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ApplicationsRequestScopeProto>() {
            public ApplicationsRequestScopeProto findValueByNumber(int number) {
              return ApplicationsRequestScopeProto.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.getDescriptor().getEnumTypes().get(1);
    }

    private static final ApplicationsRequestScopeProto[] VALUES = values();

    public static ApplicationsRequestScopeProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ApplicationsRequestScopeProto(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ApplicationsRequestScopeProto)
  }

  public interface RegisterApplicationMasterRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.RegisterApplicationMasterRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string host = 1;</code>
     */
    boolean hasHost();
    /**
     * <code>optional string host = 1;</code>
     */
    java.lang.String getHost();
    /**
     * <code>optional string host = 1;</code>
     */
    com.google.protobuf.ByteString
        getHostBytes();

    /**
     * <code>optional int32 rpc_port = 2;</code>
     */
    boolean hasRpcPort();
    /**
     * <code>optional int32 rpc_port = 2;</code>
     */
    int getRpcPort();

    /**
     * <code>optional string tracking_url = 3;</code>
     */
    boolean hasTrackingUrl();
    /**
     * <code>optional string tracking_url = 3;</code>
     */
    java.lang.String getTrackingUrl();
    /**
     * <code>optional string tracking_url = 3;</code>
     */
    com.google.protobuf.ByteString
        getTrackingUrlBytes();
  }
  /**
   * <pre>
   *&#47;///////////////////////////////////////////////////
   * ///// AM_RM_Protocol ///////////////////////////////
   * ////////////////////////////////////////////////////
   * </pre>
   *
   * Protobuf type {@code hadoop.yarn.RegisterApplicationMasterRequestProto}
   */
  public  static final class RegisterApplicationMasterRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.RegisterApplicationMasterRequestProto)
      RegisterApplicationMasterRequestProtoOrBuilder {
    // Use RegisterApplicationMasterRequestProto.newBuilder() to construct.
    private RegisterApplicationMasterRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RegisterApplicationMasterRequestProto() {
      host_ = "";
      rpcPort_ = 0;
      trackingUrl_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RegisterApplicationMasterRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              host_ = bs;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              rpcPort_ = input.readInt32();
              break;
            }
            case 26: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000004;
              trackingUrl_ = bs;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RegisterApplicationMasterRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RegisterApplicationMasterRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int HOST_FIELD_NUMBER = 1;
    private volatile java.lang.Object host_;
    /**
     * <code>optional string host = 1;</code>
     */
    public boolean hasHost() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string host = 1;</code>
     */
    public java.lang.String getHost() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          host_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string host = 1;</code>
     */
    public com.google.protobuf.ByteString
        getHostBytes() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        host_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int RPC_PORT_FIELD_NUMBER = 2;
    private int rpcPort_;
    /**
     * <code>optional int32 rpc_port = 2;</code>
     */
    public boolean hasRpcPort() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 rpc_port = 2;</code>
     */
    public int getRpcPort() {
      return rpcPort_;
    }

    public static final int TRACKING_URL_FIELD_NUMBER = 3;
    private volatile java.lang.Object trackingUrl_;
    /**
     * <code>optional string tracking_url = 3;</code>
     */
    public boolean hasTrackingUrl() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string tracking_url = 3;</code>
     */
    public java.lang.String getTrackingUrl() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          trackingUrl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string tracking_url = 3;</code>
     */
    public com.google.protobuf.ByteString
        getTrackingUrlBytes() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        trackingUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, host_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, rpcPort_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, trackingUrl_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, host_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, rpcPort_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, trackingUrl_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto) obj;

      boolean result = true;
      result = result && (hasHost() == other.hasHost());
      if (hasHost()) {
        result = result && getHost()
            .equals(other.getHost());
      }
      result = result && (hasRpcPort() == other.hasRpcPort());
      if (hasRpcPort()) {
        result = result && (getRpcPort()
            == other.getRpcPort());
      }
      result = result && (hasTrackingUrl() == other.hasTrackingUrl());
      if (hasTrackingUrl()) {
        result = result && getTrackingUrl()
            .equals(other.getTrackingUrl());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasHost()) {
        hash = (37 * hash) + HOST_FIELD_NUMBER;
        hash = (53 * hash) + getHost().hashCode();
      }
      if (hasRpcPort()) {
        hash = (37 * hash) + RPC_PORT_FIELD_NUMBER;
        hash = (53 * hash) + getRpcPort();
      }
      if (hasTrackingUrl()) {
        hash = (37 * hash) + TRACKING_URL_FIELD_NUMBER;
        hash = (53 * hash) + getTrackingUrl().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#47;///////////////////////////////////////////////////
     * ///// AM_RM_Protocol ///////////////////////////////
     * ////////////////////////////////////////////////////
     * </pre>
     *
     * Protobuf type {@code hadoop.yarn.RegisterApplicationMasterRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.RegisterApplicationMasterRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RegisterApplicationMasterRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RegisterApplicationMasterRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        host_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        rpcPort_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        trackingUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RegisterApplicationMasterRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.host_ = host_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.rpcPort_ = rpcPort_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.trackingUrl_ = trackingUrl_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto.getDefaultInstance()) return this;
        if (other.hasHost()) {
          bitField0_ |= 0x00000001;
          host_ = other.host_;
          onChanged();
        }
        if (other.hasRpcPort()) {
          setRpcPort(other.getRpcPort());
        }
        if (other.hasTrackingUrl()) {
          bitField0_ |= 0x00000004;
          trackingUrl_ = other.trackingUrl_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object host_ = "";
      /**
       * <code>optional string host = 1;</code>
       */
      public boolean hasHost() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public java.lang.String getHost() {
        java.lang.Object ref = host_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            host_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public com.google.protobuf.ByteString
          getHostBytes() {
        java.lang.Object ref = host_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          host_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public Builder setHost(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        host_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public Builder clearHost() {
        bitField0_ = (bitField0_ & ~0x00000001);
        host_ = getDefaultInstance().getHost();
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public Builder setHostBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        host_ = value;
        onChanged();
        return this;
      }

      private int rpcPort_ ;
      /**
       * <code>optional int32 rpc_port = 2;</code>
       */
      public boolean hasRpcPort() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 rpc_port = 2;</code>
       */
      public int getRpcPort() {
        return rpcPort_;
      }
      /**
       * <code>optional int32 rpc_port = 2;</code>
       */
      public Builder setRpcPort(int value) {
        bitField0_ |= 0x00000002;
        rpcPort_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 rpc_port = 2;</code>
       */
      public Builder clearRpcPort() {
        bitField0_ = (bitField0_ & ~0x00000002);
        rpcPort_ = 0;
        onChanged();
        return this;
      }

      private java.lang.Object trackingUrl_ = "";
      /**
       * <code>optional string tracking_url = 3;</code>
       */
      public boolean hasTrackingUrl() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string tracking_url = 3;</code>
       */
      public java.lang.String getTrackingUrl() {
        java.lang.Object ref = trackingUrl_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            trackingUrl_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string tracking_url = 3;</code>
       */
      public com.google.protobuf.ByteString
          getTrackingUrlBytes() {
        java.lang.Object ref = trackingUrl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          trackingUrl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string tracking_url = 3;</code>
       */
      public Builder setTrackingUrl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        trackingUrl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string tracking_url = 3;</code>
       */
      public Builder clearTrackingUrl() {
        bitField0_ = (bitField0_ & ~0x00000004);
        trackingUrl_ = getDefaultInstance().getTrackingUrl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string tracking_url = 3;</code>
       */
      public Builder setTrackingUrlBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        trackingUrl_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.RegisterApplicationMasterRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.RegisterApplicationMasterRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<RegisterApplicationMasterRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<RegisterApplicationMasterRequestProto>() {
      public RegisterApplicationMasterRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new RegisterApplicationMasterRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<RegisterApplicationMasterRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<RegisterApplicationMasterRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RegisterApplicationMasterResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.RegisterApplicationMasterResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 1;</code>
     */
    boolean hasMaximumCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto getMaximumCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMaximumCapabilityOrBuilder();

    /**
     * <code>optional bytes client_to_am_token_master_key = 2;</code>
     */
    boolean hasClientToAmTokenMasterKey();
    /**
     * <code>optional bytes client_to_am_token_master_key = 2;</code>
     */
    com.google.protobuf.ByteString getClientToAmTokenMasterKey();

    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> 
        getApplicationACLsList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getApplicationACLs(int index);
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
     */
    int getApplicationACLsCount();
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
        getApplicationACLsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder getApplicationACLsOrBuilder(
        int index);

    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> 
        getContainersFromPreviousAttemptsList();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto getContainersFromPreviousAttempts(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
     */
    int getContainersFromPreviousAttemptsCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
        getContainersFromPreviousAttemptsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getContainersFromPreviousAttemptsOrBuilder(
        int index);

    /**
     * <code>optional string queue = 5;</code>
     */
    boolean hasQueue();
    /**
     * <code>optional string queue = 5;</code>
     */
    java.lang.String getQueue();
    /**
     * <code>optional string queue = 5;</code>
     */
    com.google.protobuf.ByteString
        getQueueBytes();

    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto> 
        getNmTokensFromPreviousAttemptsList();
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto getNmTokensFromPreviousAttempts(int index);
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
     */
    int getNmTokensFromPreviousAttemptsCount();
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder> 
        getNmTokensFromPreviousAttemptsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder getNmTokensFromPreviousAttemptsOrBuilder(
        int index);

    /**
     * <code>repeated .hadoop.yarn.SchedulerResourceTypes scheduler_resource_types = 7;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes> getSchedulerResourceTypesList();
    /**
     * <code>repeated .hadoop.yarn.SchedulerResourceTypes scheduler_resource_types = 7;</code>
     */
    int getSchedulerResourceTypesCount();
    /**
     * <code>repeated .hadoop.yarn.SchedulerResourceTypes scheduler_resource_types = 7;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes getSchedulerResourceTypes(int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.RegisterApplicationMasterResponseProto}
   */
  public  static final class RegisterApplicationMasterResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.RegisterApplicationMasterResponseProto)
      RegisterApplicationMasterResponseProtoOrBuilder {
    // Use RegisterApplicationMasterResponseProto.newBuilder() to construct.
    private RegisterApplicationMasterResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RegisterApplicationMasterResponseProto() {
      clientToAmTokenMasterKey_ = com.google.protobuf.ByteString.EMPTY;
      applicationACLs_ = java.util.Collections.emptyList();
      containersFromPreviousAttempts_ = java.util.Collections.emptyList();
      queue_ = "";
      nmTokensFromPreviousAttempts_ = java.util.Collections.emptyList();
      schedulerResourceTypes_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RegisterApplicationMasterResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = maximumCapability_.toBuilder();
              }
              maximumCapability_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(maximumCapability_);
                maximumCapability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              clientToAmTokenMasterKey_ = input.readBytes();
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                applicationACLs_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto>();
                mutable_bitField0_ |= 0x00000004;
              }
              applicationACLs_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.PARSER, extensionRegistry));
              break;
            }
            case 34: {
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                containersFromPreviousAttempts_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto>();
                mutable_bitField0_ |= 0x00000008;
              }
              containersFromPreviousAttempts_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.PARSER, extensionRegistry));
              break;
            }
            case 42: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000004;
              queue_ = bs;
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                nmTokensFromPreviousAttempts_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto>();
                mutable_bitField0_ |= 0x00000020;
              }
              nmTokensFromPreviousAttempts_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.PARSER, extensionRegistry));
              break;
            }
            case 56: {
              int rawValue = input.readEnum();
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes value = org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(7, rawValue);
              } else {
                if (!((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
                  schedulerResourceTypes_ = new java.util.ArrayList<java.lang.Integer>();
                  mutable_bitField0_ |= 0x00000040;
                }
                schedulerResourceTypes_.add(rawValue);
              }
              break;
            }
            case 58: {
              int length = input.readRawVarint32();
              int oldLimit = input.pushLimit(length);
              while(input.getBytesUntilLimit() > 0) {
                int rawValue = input.readEnum();
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes value = org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes.valueOf(rawValue);
                if (value == null) {
                  unknownFields.mergeVarintField(7, rawValue);
                } else {
                  if (!((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
                    schedulerResourceTypes_ = new java.util.ArrayList<java.lang.Integer>();
                    mutable_bitField0_ |= 0x00000040;
                  }
                  schedulerResourceTypes_.add(rawValue);
                }
              }
              input.popLimit(oldLimit);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          applicationACLs_ = java.util.Collections.unmodifiableList(applicationACLs_);
        }
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          containersFromPreviousAttempts_ = java.util.Collections.unmodifiableList(containersFromPreviousAttempts_);
        }
        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
          nmTokensFromPreviousAttempts_ = java.util.Collections.unmodifiableList(nmTokensFromPreviousAttempts_);
        }
        if (((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
          schedulerResourceTypes_ = java.util.Collections.unmodifiableList(schedulerResourceTypes_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RegisterApplicationMasterResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RegisterApplicationMasterResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.Builder.class);
    }

    private int bitField0_;
    public static final int MAXIMUMCAPABILITY_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto maximumCapability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 1;</code>
     */
    public boolean hasMaximumCapability() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto getMaximumCapability() {
      return maximumCapability_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : maximumCapability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMaximumCapabilityOrBuilder() {
      return maximumCapability_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : maximumCapability_;
    }

    public static final int CLIENT_TO_AM_TOKEN_MASTER_KEY_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString clientToAmTokenMasterKey_;
    /**
     * <code>optional bytes client_to_am_token_master_key = 2;</code>
     */
    public boolean hasClientToAmTokenMasterKey() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bytes client_to_am_token_master_key = 2;</code>
     */
    public com.google.protobuf.ByteString getClientToAmTokenMasterKey() {
      return clientToAmTokenMasterKey_;
    }

    public static final int APPLICATION_ACLS_FIELD_NUMBER = 3;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> applicationACLs_;
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> getApplicationACLsList() {
      return applicationACLs_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
        getApplicationACLsOrBuilderList() {
      return applicationACLs_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
     */
    public int getApplicationACLsCount() {
      return applicationACLs_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getApplicationACLs(int index) {
      return applicationACLs_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder getApplicationACLsOrBuilder(
        int index) {
      return applicationACLs_.get(index);
    }

    public static final int CONTAINERS_FROM_PREVIOUS_ATTEMPTS_FIELD_NUMBER = 4;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> containersFromPreviousAttempts_;
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> getContainersFromPreviousAttemptsList() {
      return containersFromPreviousAttempts_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
        getContainersFromPreviousAttemptsOrBuilderList() {
      return containersFromPreviousAttempts_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
     */
    public int getContainersFromPreviousAttemptsCount() {
      return containersFromPreviousAttempts_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto getContainersFromPreviousAttempts(int index) {
      return containersFromPreviousAttempts_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getContainersFromPreviousAttemptsOrBuilder(
        int index) {
      return containersFromPreviousAttempts_.get(index);
    }

    public static final int QUEUE_FIELD_NUMBER = 5;
    private volatile java.lang.Object queue_;
    /**
     * <code>optional string queue = 5;</code>
     */
    public boolean hasQueue() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string queue = 5;</code>
     */
    public java.lang.String getQueue() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queue_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queue = 5;</code>
     */
    public com.google.protobuf.ByteString
        getQueueBytes() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queue_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int NM_TOKENS_FROM_PREVIOUS_ATTEMPTS_FIELD_NUMBER = 6;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto> nmTokensFromPreviousAttempts_;
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto> getNmTokensFromPreviousAttemptsList() {
      return nmTokensFromPreviousAttempts_;
    }
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder> 
        getNmTokensFromPreviousAttemptsOrBuilderList() {
      return nmTokensFromPreviousAttempts_;
    }
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
     */
    public int getNmTokensFromPreviousAttemptsCount() {
      return nmTokensFromPreviousAttempts_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto getNmTokensFromPreviousAttempts(int index) {
      return nmTokensFromPreviousAttempts_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder getNmTokensFromPreviousAttemptsOrBuilder(
        int index) {
      return nmTokensFromPreviousAttempts_.get(index);
    }

    public static final int SCHEDULER_RESOURCE_TYPES_FIELD_NUMBER = 7;
    private java.util.List<java.lang.Integer> schedulerResourceTypes_;
    private static final com.google.protobuf.Internal.ListAdapter.Converter<
        java.lang.Integer, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes> schedulerResourceTypes_converter_ =
            new com.google.protobuf.Internal.ListAdapter.Converter<
                java.lang.Integer, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes>() {
              public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes convert(java.lang.Integer from) {
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes result = org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes.valueOf(from);
                return result == null ? org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes.MEMORY : result;
              }
            };
    /**
     * <code>repeated .hadoop.yarn.SchedulerResourceTypes scheduler_resource_types = 7;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes> getSchedulerResourceTypesList() {
      return new com.google.protobuf.Internal.ListAdapter<
          java.lang.Integer, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes>(schedulerResourceTypes_, schedulerResourceTypes_converter_);
    }
    /**
     * <code>repeated .hadoop.yarn.SchedulerResourceTypes scheduler_resource_types = 7;</code>
     */
    public int getSchedulerResourceTypesCount() {
      return schedulerResourceTypes_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.SchedulerResourceTypes scheduler_resource_types = 7;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes getSchedulerResourceTypes(int index) {
      return schedulerResourceTypes_converter_.convert(schedulerResourceTypes_.get(index));
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getContainersFromPreviousAttemptsCount(); i++) {
        if (!getContainersFromPreviousAttempts(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getNmTokensFromPreviousAttemptsCount(); i++) {
        if (!getNmTokensFromPreviousAttempts(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getMaximumCapability());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, clientToAmTokenMasterKey_);
      }
      for (int i = 0; i < applicationACLs_.size(); i++) {
        output.writeMessage(3, applicationACLs_.get(i));
      }
      for (int i = 0; i < containersFromPreviousAttempts_.size(); i++) {
        output.writeMessage(4, containersFromPreviousAttempts_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, queue_);
      }
      for (int i = 0; i < nmTokensFromPreviousAttempts_.size(); i++) {
        output.writeMessage(6, nmTokensFromPreviousAttempts_.get(i));
      }
      for (int i = 0; i < schedulerResourceTypes_.size(); i++) {
        output.writeEnum(7, schedulerResourceTypes_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getMaximumCapability());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, clientToAmTokenMasterKey_);
      }
      for (int i = 0; i < applicationACLs_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, applicationACLs_.get(i));
      }
      for (int i = 0; i < containersFromPreviousAttempts_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, containersFromPreviousAttempts_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, queue_);
      }
      for (int i = 0; i < nmTokensFromPreviousAttempts_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, nmTokensFromPreviousAttempts_.get(i));
      }
      {
        int dataSize = 0;
        for (int i = 0; i < schedulerResourceTypes_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeEnumSizeNoTag(schedulerResourceTypes_.get(i));
        }
        size += dataSize;
        size += 1 * schedulerResourceTypes_.size();
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto) obj;

      boolean result = true;
      result = result && (hasMaximumCapability() == other.hasMaximumCapability());
      if (hasMaximumCapability()) {
        result = result && getMaximumCapability()
            .equals(other.getMaximumCapability());
      }
      result = result && (hasClientToAmTokenMasterKey() == other.hasClientToAmTokenMasterKey());
      if (hasClientToAmTokenMasterKey()) {
        result = result && getClientToAmTokenMasterKey()
            .equals(other.getClientToAmTokenMasterKey());
      }
      result = result && getApplicationACLsList()
          .equals(other.getApplicationACLsList());
      result = result && getContainersFromPreviousAttemptsList()
          .equals(other.getContainersFromPreviousAttemptsList());
      result = result && (hasQueue() == other.hasQueue());
      if (hasQueue()) {
        result = result && getQueue()
            .equals(other.getQueue());
      }
      result = result && getNmTokensFromPreviousAttemptsList()
          .equals(other.getNmTokensFromPreviousAttemptsList());
      result = result && schedulerResourceTypes_.equals(other.schedulerResourceTypes_);
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasMaximumCapability()) {
        hash = (37 * hash) + MAXIMUMCAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getMaximumCapability().hashCode();
      }
      if (hasClientToAmTokenMasterKey()) {
        hash = (37 * hash) + CLIENT_TO_AM_TOKEN_MASTER_KEY_FIELD_NUMBER;
        hash = (53 * hash) + getClientToAmTokenMasterKey().hashCode();
      }
      if (getApplicationACLsCount() > 0) {
        hash = (37 * hash) + APPLICATION_ACLS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationACLsList().hashCode();
      }
      if (getContainersFromPreviousAttemptsCount() > 0) {
        hash = (37 * hash) + CONTAINERS_FROM_PREVIOUS_ATTEMPTS_FIELD_NUMBER;
        hash = (53 * hash) + getContainersFromPreviousAttemptsList().hashCode();
      }
      if (hasQueue()) {
        hash = (37 * hash) + QUEUE_FIELD_NUMBER;
        hash = (53 * hash) + getQueue().hashCode();
      }
      if (getNmTokensFromPreviousAttemptsCount() > 0) {
        hash = (37 * hash) + NM_TOKENS_FROM_PREVIOUS_ATTEMPTS_FIELD_NUMBER;
        hash = (53 * hash) + getNmTokensFromPreviousAttemptsList().hashCode();
      }
      if (getSchedulerResourceTypesCount() > 0) {
        hash = (37 * hash) + SCHEDULER_RESOURCE_TYPES_FIELD_NUMBER;
        hash = (53 * hash) + schedulerResourceTypes_.hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.RegisterApplicationMasterResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.RegisterApplicationMasterResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RegisterApplicationMasterResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RegisterApplicationMasterResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getMaximumCapabilityFieldBuilder();
          getApplicationACLsFieldBuilder();
          getContainersFromPreviousAttemptsFieldBuilder();
          getNmTokensFromPreviousAttemptsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (maximumCapabilityBuilder_ == null) {
          maximumCapability_ = null;
        } else {
          maximumCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        clientToAmTokenMasterKey_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (applicationACLsBuilder_ == null) {
          applicationACLs_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          applicationACLsBuilder_.clear();
        }
        if (containersFromPreviousAttemptsBuilder_ == null) {
          containersFromPreviousAttempts_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          containersFromPreviousAttemptsBuilder_.clear();
        }
        queue_ = "";
        bitField0_ = (bitField0_ & ~0x00000010);
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          nmTokensFromPreviousAttempts_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          nmTokensFromPreviousAttemptsBuilder_.clear();
        }
        schedulerResourceTypes_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RegisterApplicationMasterResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (maximumCapabilityBuilder_ == null) {
          result.maximumCapability_ = maximumCapability_;
        } else {
          result.maximumCapability_ = maximumCapabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.clientToAmTokenMasterKey_ = clientToAmTokenMasterKey_;
        if (applicationACLsBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            applicationACLs_ = java.util.Collections.unmodifiableList(applicationACLs_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.applicationACLs_ = applicationACLs_;
        } else {
          result.applicationACLs_ = applicationACLsBuilder_.build();
        }
        if (containersFromPreviousAttemptsBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            containersFromPreviousAttempts_ = java.util.Collections.unmodifiableList(containersFromPreviousAttempts_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.containersFromPreviousAttempts_ = containersFromPreviousAttempts_;
        } else {
          result.containersFromPreviousAttempts_ = containersFromPreviousAttemptsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000004;
        }
        result.queue_ = queue_;
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            nmTokensFromPreviousAttempts_ = java.util.Collections.unmodifiableList(nmTokensFromPreviousAttempts_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.nmTokensFromPreviousAttempts_ = nmTokensFromPreviousAttempts_;
        } else {
          result.nmTokensFromPreviousAttempts_ = nmTokensFromPreviousAttemptsBuilder_.build();
        }
        if (((bitField0_ & 0x00000040) == 0x00000040)) {
          schedulerResourceTypes_ = java.util.Collections.unmodifiableList(schedulerResourceTypes_);
          bitField0_ = (bitField0_ & ~0x00000040);
        }
        result.schedulerResourceTypes_ = schedulerResourceTypes_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.getDefaultInstance()) return this;
        if (other.hasMaximumCapability()) {
          mergeMaximumCapability(other.getMaximumCapability());
        }
        if (other.hasClientToAmTokenMasterKey()) {
          setClientToAmTokenMasterKey(other.getClientToAmTokenMasterKey());
        }
        if (applicationACLsBuilder_ == null) {
          if (!other.applicationACLs_.isEmpty()) {
            if (applicationACLs_.isEmpty()) {
              applicationACLs_ = other.applicationACLs_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureApplicationACLsIsMutable();
              applicationACLs_.addAll(other.applicationACLs_);
            }
            onChanged();
          }
        } else {
          if (!other.applicationACLs_.isEmpty()) {
            if (applicationACLsBuilder_.isEmpty()) {
              applicationACLsBuilder_.dispose();
              applicationACLsBuilder_ = null;
              applicationACLs_ = other.applicationACLs_;
              bitField0_ = (bitField0_ & ~0x00000004);
              applicationACLsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getApplicationACLsFieldBuilder() : null;
            } else {
              applicationACLsBuilder_.addAllMessages(other.applicationACLs_);
            }
          }
        }
        if (containersFromPreviousAttemptsBuilder_ == null) {
          if (!other.containersFromPreviousAttempts_.isEmpty()) {
            if (containersFromPreviousAttempts_.isEmpty()) {
              containersFromPreviousAttempts_ = other.containersFromPreviousAttempts_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureContainersFromPreviousAttemptsIsMutable();
              containersFromPreviousAttempts_.addAll(other.containersFromPreviousAttempts_);
            }
            onChanged();
          }
        } else {
          if (!other.containersFromPreviousAttempts_.isEmpty()) {
            if (containersFromPreviousAttemptsBuilder_.isEmpty()) {
              containersFromPreviousAttemptsBuilder_.dispose();
              containersFromPreviousAttemptsBuilder_ = null;
              containersFromPreviousAttempts_ = other.containersFromPreviousAttempts_;
              bitField0_ = (bitField0_ & ~0x00000008);
              containersFromPreviousAttemptsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getContainersFromPreviousAttemptsFieldBuilder() : null;
            } else {
              containersFromPreviousAttemptsBuilder_.addAllMessages(other.containersFromPreviousAttempts_);
            }
          }
        }
        if (other.hasQueue()) {
          bitField0_ |= 0x00000010;
          queue_ = other.queue_;
          onChanged();
        }
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          if (!other.nmTokensFromPreviousAttempts_.isEmpty()) {
            if (nmTokensFromPreviousAttempts_.isEmpty()) {
              nmTokensFromPreviousAttempts_ = other.nmTokensFromPreviousAttempts_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureNmTokensFromPreviousAttemptsIsMutable();
              nmTokensFromPreviousAttempts_.addAll(other.nmTokensFromPreviousAttempts_);
            }
            onChanged();
          }
        } else {
          if (!other.nmTokensFromPreviousAttempts_.isEmpty()) {
            if (nmTokensFromPreviousAttemptsBuilder_.isEmpty()) {
              nmTokensFromPreviousAttemptsBuilder_.dispose();
              nmTokensFromPreviousAttemptsBuilder_ = null;
              nmTokensFromPreviousAttempts_ = other.nmTokensFromPreviousAttempts_;
              bitField0_ = (bitField0_ & ~0x00000020);
              nmTokensFromPreviousAttemptsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getNmTokensFromPreviousAttemptsFieldBuilder() : null;
            } else {
              nmTokensFromPreviousAttemptsBuilder_.addAllMessages(other.nmTokensFromPreviousAttempts_);
            }
          }
        }
        if (!other.schedulerResourceTypes_.isEmpty()) {
          if (schedulerResourceTypes_.isEmpty()) {
            schedulerResourceTypes_ = other.schedulerResourceTypes_;
            bitField0_ = (bitField0_ & ~0x00000040);
          } else {
            ensureSchedulerResourceTypesIsMutable();
            schedulerResourceTypes_.addAll(other.schedulerResourceTypes_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getContainersFromPreviousAttemptsCount(); i++) {
          if (!getContainersFromPreviousAttempts(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getNmTokensFromPreviousAttemptsCount(); i++) {
          if (!getNmTokensFromPreviousAttempts(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto maximumCapability_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> maximumCapabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 1;</code>
       */
      public boolean hasMaximumCapability() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto getMaximumCapability() {
        if (maximumCapabilityBuilder_ == null) {
          return maximumCapability_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : maximumCapability_;
        } else {
          return maximumCapabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 1;</code>
       */
      public Builder setMaximumCapability(org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (maximumCapabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          maximumCapability_ = value;
          onChanged();
        } else {
          maximumCapabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 1;</code>
       */
      public Builder setMaximumCapability(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (maximumCapabilityBuilder_ == null) {
          maximumCapability_ = builderForValue.build();
          onChanged();
        } else {
          maximumCapabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 1;</code>
       */
      public Builder mergeMaximumCapability(org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (maximumCapabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              maximumCapability_ != null &&
              maximumCapability_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            maximumCapability_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(maximumCapability_).mergeFrom(value).buildPartial();
          } else {
            maximumCapability_ = value;
          }
          onChanged();
        } else {
          maximumCapabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 1;</code>
       */
      public Builder clearMaximumCapability() {
        if (maximumCapabilityBuilder_ == null) {
          maximumCapability_ = null;
          onChanged();
        } else {
          maximumCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getMaximumCapabilityBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getMaximumCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMaximumCapabilityOrBuilder() {
        if (maximumCapabilityBuilder_ != null) {
          return maximumCapabilityBuilder_.getMessageOrBuilder();
        } else {
          return maximumCapability_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : maximumCapability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getMaximumCapabilityFieldBuilder() {
        if (maximumCapabilityBuilder_ == null) {
          maximumCapabilityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getMaximumCapability(),
                  getParentForChildren(),
                  isClean());
          maximumCapability_ = null;
        }
        return maximumCapabilityBuilder_;
      }

      private com.google.protobuf.ByteString clientToAmTokenMasterKey_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes client_to_am_token_master_key = 2;</code>
       */
      public boolean hasClientToAmTokenMasterKey() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bytes client_to_am_token_master_key = 2;</code>
       */
      public com.google.protobuf.ByteString getClientToAmTokenMasterKey() {
        return clientToAmTokenMasterKey_;
      }
      /**
       * <code>optional bytes client_to_am_token_master_key = 2;</code>
       */
      public Builder setClientToAmTokenMasterKey(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        clientToAmTokenMasterKey_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes client_to_am_token_master_key = 2;</code>
       */
      public Builder clearClientToAmTokenMasterKey() {
        bitField0_ = (bitField0_ & ~0x00000002);
        clientToAmTokenMasterKey_ = getDefaultInstance().getClientToAmTokenMasterKey();
        onChanged();
        return this;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> applicationACLs_ =
        java.util.Collections.emptyList();
      private void ensureApplicationACLsIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          applicationACLs_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto>(applicationACLs_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> applicationACLsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> getApplicationACLsList() {
        if (applicationACLsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(applicationACLs_);
        } else {
          return applicationACLsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public int getApplicationACLsCount() {
        if (applicationACLsBuilder_ == null) {
          return applicationACLs_.size();
        } else {
          return applicationACLsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getApplicationACLs(int index) {
        if (applicationACLsBuilder_ == null) {
          return applicationACLs_.get(index);
        } else {
          return applicationACLsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public Builder setApplicationACLs(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto value) {
        if (applicationACLsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationACLsIsMutable();
          applicationACLs_.set(index, value);
          onChanged();
        } else {
          applicationACLsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public Builder setApplicationACLs(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder builderForValue) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.set(index, builderForValue.build());
          onChanged();
        } else {
          applicationACLsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public Builder addApplicationACLs(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto value) {
        if (applicationACLsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(value);
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public Builder addApplicationACLs(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto value) {
        if (applicationACLsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(index, value);
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public Builder addApplicationACLs(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder builderForValue) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(builderForValue.build());
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public Builder addApplicationACLs(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder builderForValue) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(index, builderForValue.build());
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public Builder addAllApplicationACLs(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> values) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, applicationACLs_);
          onChanged();
        } else {
          applicationACLsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public Builder clearApplicationACLs() {
        if (applicationACLsBuilder_ == null) {
          applicationACLs_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          applicationACLsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public Builder removeApplicationACLs(int index) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.remove(index);
          onChanged();
        } else {
          applicationACLsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder getApplicationACLsBuilder(
          int index) {
        return getApplicationACLsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder getApplicationACLsOrBuilder(
          int index) {
        if (applicationACLsBuilder_ == null) {
          return applicationACLs_.get(index);  } else {
          return applicationACLsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
           getApplicationACLsOrBuilderList() {
        if (applicationACLsBuilder_ != null) {
          return applicationACLsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(applicationACLs_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder addApplicationACLsBuilder() {
        return getApplicationACLsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder addApplicationACLsBuilder(
          int index) {
        return getApplicationACLsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder> 
           getApplicationACLsBuilderList() {
        return getApplicationACLsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
          getApplicationACLsFieldBuilder() {
        if (applicationACLsBuilder_ == null) {
          applicationACLsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder>(
                  applicationACLs_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          applicationACLs_ = null;
        }
        return applicationACLsBuilder_;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> containersFromPreviousAttempts_ =
        java.util.Collections.emptyList();
      private void ensureContainersFromPreviousAttemptsIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          containersFromPreviousAttempts_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto>(containersFromPreviousAttempts_);
          bitField0_ |= 0x00000008;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> containersFromPreviousAttemptsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> getContainersFromPreviousAttemptsList() {
        if (containersFromPreviousAttemptsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(containersFromPreviousAttempts_);
        } else {
          return containersFromPreviousAttemptsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public int getContainersFromPreviousAttemptsCount() {
        if (containersFromPreviousAttemptsBuilder_ == null) {
          return containersFromPreviousAttempts_.size();
        } else {
          return containersFromPreviousAttemptsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto getContainersFromPreviousAttempts(int index) {
        if (containersFromPreviousAttemptsBuilder_ == null) {
          return containersFromPreviousAttempts_.get(index);
        } else {
          return containersFromPreviousAttemptsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public Builder setContainersFromPreviousAttempts(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (containersFromPreviousAttemptsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersFromPreviousAttemptsIsMutable();
          containersFromPreviousAttempts_.set(index, value);
          onChanged();
        } else {
          containersFromPreviousAttemptsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public Builder setContainersFromPreviousAttempts(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (containersFromPreviousAttemptsBuilder_ == null) {
          ensureContainersFromPreviousAttemptsIsMutable();
          containersFromPreviousAttempts_.set(index, builderForValue.build());
          onChanged();
        } else {
          containersFromPreviousAttemptsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public Builder addContainersFromPreviousAttempts(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (containersFromPreviousAttemptsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersFromPreviousAttemptsIsMutable();
          containersFromPreviousAttempts_.add(value);
          onChanged();
        } else {
          containersFromPreviousAttemptsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public Builder addContainersFromPreviousAttempts(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (containersFromPreviousAttemptsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersFromPreviousAttemptsIsMutable();
          containersFromPreviousAttempts_.add(index, value);
          onChanged();
        } else {
          containersFromPreviousAttemptsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public Builder addContainersFromPreviousAttempts(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (containersFromPreviousAttemptsBuilder_ == null) {
          ensureContainersFromPreviousAttemptsIsMutable();
          containersFromPreviousAttempts_.add(builderForValue.build());
          onChanged();
        } else {
          containersFromPreviousAttemptsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public Builder addContainersFromPreviousAttempts(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (containersFromPreviousAttemptsBuilder_ == null) {
          ensureContainersFromPreviousAttemptsIsMutable();
          containersFromPreviousAttempts_.add(index, builderForValue.build());
          onChanged();
        } else {
          containersFromPreviousAttemptsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public Builder addAllContainersFromPreviousAttempts(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> values) {
        if (containersFromPreviousAttemptsBuilder_ == null) {
          ensureContainersFromPreviousAttemptsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, containersFromPreviousAttempts_);
          onChanged();
        } else {
          containersFromPreviousAttemptsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public Builder clearContainersFromPreviousAttempts() {
        if (containersFromPreviousAttemptsBuilder_ == null) {
          containersFromPreviousAttempts_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          containersFromPreviousAttemptsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public Builder removeContainersFromPreviousAttempts(int index) {
        if (containersFromPreviousAttemptsBuilder_ == null) {
          ensureContainersFromPreviousAttemptsIsMutable();
          containersFromPreviousAttempts_.remove(index);
          onChanged();
        } else {
          containersFromPreviousAttemptsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder getContainersFromPreviousAttemptsBuilder(
          int index) {
        return getContainersFromPreviousAttemptsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getContainersFromPreviousAttemptsOrBuilder(
          int index) {
        if (containersFromPreviousAttemptsBuilder_ == null) {
          return containersFromPreviousAttempts_.get(index);  } else {
          return containersFromPreviousAttemptsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
           getContainersFromPreviousAttemptsOrBuilderList() {
        if (containersFromPreviousAttemptsBuilder_ != null) {
          return containersFromPreviousAttemptsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(containersFromPreviousAttempts_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder addContainersFromPreviousAttemptsBuilder() {
        return getContainersFromPreviousAttemptsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder addContainersFromPreviousAttemptsBuilder(
          int index) {
        return getContainersFromPreviousAttemptsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_from_previous_attempts = 4;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder> 
           getContainersFromPreviousAttemptsBuilderList() {
        return getContainersFromPreviousAttemptsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
          getContainersFromPreviousAttemptsFieldBuilder() {
        if (containersFromPreviousAttemptsBuilder_ == null) {
          containersFromPreviousAttemptsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder>(
                  containersFromPreviousAttempts_,
                  ((bitField0_ & 0x00000008) == 0x00000008),
                  getParentForChildren(),
                  isClean());
          containersFromPreviousAttempts_ = null;
        }
        return containersFromPreviousAttemptsBuilder_;
      }

      private java.lang.Object queue_ = "";
      /**
       * <code>optional string queue = 5;</code>
       */
      public boolean hasQueue() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional string queue = 5;</code>
       */
      public java.lang.String getQueue() {
        java.lang.Object ref = queue_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            queue_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queue = 5;</code>
       */
      public com.google.protobuf.ByteString
          getQueueBytes() {
        java.lang.Object ref = queue_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queue_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queue = 5;</code>
       */
      public Builder setQueue(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        queue_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 5;</code>
       */
      public Builder clearQueue() {
        bitField0_ = (bitField0_ & ~0x00000010);
        queue_ = getDefaultInstance().getQueue();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 5;</code>
       */
      public Builder setQueueBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        queue_ = value;
        onChanged();
        return this;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto> nmTokensFromPreviousAttempts_ =
        java.util.Collections.emptyList();
      private void ensureNmTokensFromPreviousAttemptsIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          nmTokensFromPreviousAttempts_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto>(nmTokensFromPreviousAttempts_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder> nmTokensFromPreviousAttemptsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto> getNmTokensFromPreviousAttemptsList() {
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(nmTokensFromPreviousAttempts_);
        } else {
          return nmTokensFromPreviousAttemptsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public int getNmTokensFromPreviousAttemptsCount() {
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          return nmTokensFromPreviousAttempts_.size();
        } else {
          return nmTokensFromPreviousAttemptsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto getNmTokensFromPreviousAttempts(int index) {
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          return nmTokensFromPreviousAttempts_.get(index);
        } else {
          return nmTokensFromPreviousAttemptsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public Builder setNmTokensFromPreviousAttempts(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto value) {
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNmTokensFromPreviousAttemptsIsMutable();
          nmTokensFromPreviousAttempts_.set(index, value);
          onChanged();
        } else {
          nmTokensFromPreviousAttemptsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public Builder setNmTokensFromPreviousAttempts(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder builderForValue) {
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          ensureNmTokensFromPreviousAttemptsIsMutable();
          nmTokensFromPreviousAttempts_.set(index, builderForValue.build());
          onChanged();
        } else {
          nmTokensFromPreviousAttemptsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public Builder addNmTokensFromPreviousAttempts(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto value) {
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNmTokensFromPreviousAttemptsIsMutable();
          nmTokensFromPreviousAttempts_.add(value);
          onChanged();
        } else {
          nmTokensFromPreviousAttemptsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public Builder addNmTokensFromPreviousAttempts(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto value) {
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNmTokensFromPreviousAttemptsIsMutable();
          nmTokensFromPreviousAttempts_.add(index, value);
          onChanged();
        } else {
          nmTokensFromPreviousAttemptsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public Builder addNmTokensFromPreviousAttempts(
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder builderForValue) {
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          ensureNmTokensFromPreviousAttemptsIsMutable();
          nmTokensFromPreviousAttempts_.add(builderForValue.build());
          onChanged();
        } else {
          nmTokensFromPreviousAttemptsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public Builder addNmTokensFromPreviousAttempts(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder builderForValue) {
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          ensureNmTokensFromPreviousAttemptsIsMutable();
          nmTokensFromPreviousAttempts_.add(index, builderForValue.build());
          onChanged();
        } else {
          nmTokensFromPreviousAttemptsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public Builder addAllNmTokensFromPreviousAttempts(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto> values) {
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          ensureNmTokensFromPreviousAttemptsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, nmTokensFromPreviousAttempts_);
          onChanged();
        } else {
          nmTokensFromPreviousAttemptsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public Builder clearNmTokensFromPreviousAttempts() {
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          nmTokensFromPreviousAttempts_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          nmTokensFromPreviousAttemptsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public Builder removeNmTokensFromPreviousAttempts(int index) {
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          ensureNmTokensFromPreviousAttemptsIsMutable();
          nmTokensFromPreviousAttempts_.remove(index);
          onChanged();
        } else {
          nmTokensFromPreviousAttemptsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder getNmTokensFromPreviousAttemptsBuilder(
          int index) {
        return getNmTokensFromPreviousAttemptsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder getNmTokensFromPreviousAttemptsOrBuilder(
          int index) {
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          return nmTokensFromPreviousAttempts_.get(index);  } else {
          return nmTokensFromPreviousAttemptsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder> 
           getNmTokensFromPreviousAttemptsOrBuilderList() {
        if (nmTokensFromPreviousAttemptsBuilder_ != null) {
          return nmTokensFromPreviousAttemptsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(nmTokensFromPreviousAttempts_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder addNmTokensFromPreviousAttemptsBuilder() {
        return getNmTokensFromPreviousAttemptsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder addNmTokensFromPreviousAttemptsBuilder(
          int index) {
        return getNmTokensFromPreviousAttemptsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens_from_previous_attempts = 6;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder> 
           getNmTokensFromPreviousAttemptsBuilderList() {
        return getNmTokensFromPreviousAttemptsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder> 
          getNmTokensFromPreviousAttemptsFieldBuilder() {
        if (nmTokensFromPreviousAttemptsBuilder_ == null) {
          nmTokensFromPreviousAttemptsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder>(
                  nmTokensFromPreviousAttempts_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          nmTokensFromPreviousAttempts_ = null;
        }
        return nmTokensFromPreviousAttemptsBuilder_;
      }

      private java.util.List<java.lang.Integer> schedulerResourceTypes_ =
        java.util.Collections.emptyList();
      private void ensureSchedulerResourceTypesIsMutable() {
        if (!((bitField0_ & 0x00000040) == 0x00000040)) {
          schedulerResourceTypes_ = new java.util.ArrayList<java.lang.Integer>(schedulerResourceTypes_);
          bitField0_ |= 0x00000040;
        }
      }
      /**
       * <code>repeated .hadoop.yarn.SchedulerResourceTypes scheduler_resource_types = 7;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes> getSchedulerResourceTypesList() {
        return new com.google.protobuf.Internal.ListAdapter<
            java.lang.Integer, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes>(schedulerResourceTypes_, schedulerResourceTypes_converter_);
      }
      /**
       * <code>repeated .hadoop.yarn.SchedulerResourceTypes scheduler_resource_types = 7;</code>
       */
      public int getSchedulerResourceTypesCount() {
        return schedulerResourceTypes_.size();
      }
      /**
       * <code>repeated .hadoop.yarn.SchedulerResourceTypes scheduler_resource_types = 7;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes getSchedulerResourceTypes(int index) {
        return schedulerResourceTypes_converter_.convert(schedulerResourceTypes_.get(index));
      }
      /**
       * <code>repeated .hadoop.yarn.SchedulerResourceTypes scheduler_resource_types = 7;</code>
       */
      public Builder setSchedulerResourceTypes(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureSchedulerResourceTypesIsMutable();
        schedulerResourceTypes_.set(index, value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SchedulerResourceTypes scheduler_resource_types = 7;</code>
       */
      public Builder addSchedulerResourceTypes(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureSchedulerResourceTypesIsMutable();
        schedulerResourceTypes_.add(value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SchedulerResourceTypes scheduler_resource_types = 7;</code>
       */
      public Builder addAllSchedulerResourceTypes(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes> values) {
        ensureSchedulerResourceTypesIsMutable();
        for (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes value : values) {
          schedulerResourceTypes_.add(value.getNumber());
        }
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SchedulerResourceTypes scheduler_resource_types = 7;</code>
       */
      public Builder clearSchedulerResourceTypes() {
        schedulerResourceTypes_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000040);
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.RegisterApplicationMasterResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.RegisterApplicationMasterResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<RegisterApplicationMasterResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<RegisterApplicationMasterResponseProto>() {
      public RegisterApplicationMasterResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new RegisterApplicationMasterResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<RegisterApplicationMasterResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<RegisterApplicationMasterResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FinishApplicationMasterRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.FinishApplicationMasterRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string diagnostics = 1;</code>
     */
    boolean hasDiagnostics();
    /**
     * <code>optional string diagnostics = 1;</code>
     */
    java.lang.String getDiagnostics();
    /**
     * <code>optional string diagnostics = 1;</code>
     */
    com.google.protobuf.ByteString
        getDiagnosticsBytes();

    /**
     * <code>optional string tracking_url = 2;</code>
     */
    boolean hasTrackingUrl();
    /**
     * <code>optional string tracking_url = 2;</code>
     */
    java.lang.String getTrackingUrl();
    /**
     * <code>optional string tracking_url = 2;</code>
     */
    com.google.protobuf.ByteString
        getTrackingUrlBytes();

    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 3;</code>
     */
    boolean hasFinalApplicationStatus();
    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 3;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto getFinalApplicationStatus();
  }
  /**
   * Protobuf type {@code hadoop.yarn.FinishApplicationMasterRequestProto}
   */
  public  static final class FinishApplicationMasterRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.FinishApplicationMasterRequestProto)
      FinishApplicationMasterRequestProtoOrBuilder {
    // Use FinishApplicationMasterRequestProto.newBuilder() to construct.
    private FinishApplicationMasterRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FinishApplicationMasterRequestProto() {
      diagnostics_ = "";
      trackingUrl_ = "";
      finalApplicationStatus_ = 0;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private FinishApplicationMasterRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              diagnostics_ = bs;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              trackingUrl_ = bs;
              break;
            }
            case 24: {
              int rawValue = input.readEnum();
              org.spiderdt.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto value = org.spiderdt.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(3, rawValue);
              } else {
                bitField0_ |= 0x00000004;
                finalApplicationStatus_ = rawValue;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FinishApplicationMasterRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FinishApplicationMasterRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int DIAGNOSTICS_FIELD_NUMBER = 1;
    private volatile java.lang.Object diagnostics_;
    /**
     * <code>optional string diagnostics = 1;</code>
     */
    public boolean hasDiagnostics() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string diagnostics = 1;</code>
     */
    public java.lang.String getDiagnostics() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          diagnostics_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string diagnostics = 1;</code>
     */
    public com.google.protobuf.ByteString
        getDiagnosticsBytes() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diagnostics_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int TRACKING_URL_FIELD_NUMBER = 2;
    private volatile java.lang.Object trackingUrl_;
    /**
     * <code>optional string tracking_url = 2;</code>
     */
    public boolean hasTrackingUrl() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string tracking_url = 2;</code>
     */
    public java.lang.String getTrackingUrl() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          trackingUrl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string tracking_url = 2;</code>
     */
    public com.google.protobuf.ByteString
        getTrackingUrlBytes() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        trackingUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int FINAL_APPLICATION_STATUS_FIELD_NUMBER = 3;
    private int finalApplicationStatus_;
    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 3;</code>
     */
    public boolean hasFinalApplicationStatus() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 3;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto getFinalApplicationStatus() {
      org.spiderdt.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto result = org.spiderdt.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.valueOf(finalApplicationStatus_);
      return result == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED : result;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, diagnostics_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, trackingUrl_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeEnum(3, finalApplicationStatus_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, diagnostics_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, trackingUrl_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(3, finalApplicationStatus_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto) obj;

      boolean result = true;
      result = result && (hasDiagnostics() == other.hasDiagnostics());
      if (hasDiagnostics()) {
        result = result && getDiagnostics()
            .equals(other.getDiagnostics());
      }
      result = result && (hasTrackingUrl() == other.hasTrackingUrl());
      if (hasTrackingUrl()) {
        result = result && getTrackingUrl()
            .equals(other.getTrackingUrl());
      }
      result = result && (hasFinalApplicationStatus() == other.hasFinalApplicationStatus());
      if (hasFinalApplicationStatus()) {
        result = result && finalApplicationStatus_ == other.finalApplicationStatus_;
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasDiagnostics()) {
        hash = (37 * hash) + DIAGNOSTICS_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnostics().hashCode();
      }
      if (hasTrackingUrl()) {
        hash = (37 * hash) + TRACKING_URL_FIELD_NUMBER;
        hash = (53 * hash) + getTrackingUrl().hashCode();
      }
      if (hasFinalApplicationStatus()) {
        hash = (37 * hash) + FINAL_APPLICATION_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + finalApplicationStatus_;
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.FinishApplicationMasterRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.FinishApplicationMasterRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FinishApplicationMasterRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FinishApplicationMasterRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        diagnostics_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        trackingUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        finalApplicationStatus_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FinishApplicationMasterRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.diagnostics_ = diagnostics_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.trackingUrl_ = trackingUrl_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.finalApplicationStatus_ = finalApplicationStatus_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto.getDefaultInstance()) return this;
        if (other.hasDiagnostics()) {
          bitField0_ |= 0x00000001;
          diagnostics_ = other.diagnostics_;
          onChanged();
        }
        if (other.hasTrackingUrl()) {
          bitField0_ |= 0x00000002;
          trackingUrl_ = other.trackingUrl_;
          onChanged();
        }
        if (other.hasFinalApplicationStatus()) {
          setFinalApplicationStatus(other.getFinalApplicationStatus());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object diagnostics_ = "";
      /**
       * <code>optional string diagnostics = 1;</code>
       */
      public boolean hasDiagnostics() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string diagnostics = 1;</code>
       */
      public java.lang.String getDiagnostics() {
        java.lang.Object ref = diagnostics_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            diagnostics_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 1;</code>
       */
      public com.google.protobuf.ByteString
          getDiagnosticsBytes() {
        java.lang.Object ref = diagnostics_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diagnostics_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 1;</code>
       */
      public Builder setDiagnostics(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        diagnostics_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 1;</code>
       */
      public Builder clearDiagnostics() {
        bitField0_ = (bitField0_ & ~0x00000001);
        diagnostics_ = getDefaultInstance().getDiagnostics();
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 1;</code>
       */
      public Builder setDiagnosticsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        diagnostics_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object trackingUrl_ = "";
      /**
       * <code>optional string tracking_url = 2;</code>
       */
      public boolean hasTrackingUrl() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string tracking_url = 2;</code>
       */
      public java.lang.String getTrackingUrl() {
        java.lang.Object ref = trackingUrl_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            trackingUrl_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string tracking_url = 2;</code>
       */
      public com.google.protobuf.ByteString
          getTrackingUrlBytes() {
        java.lang.Object ref = trackingUrl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          trackingUrl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string tracking_url = 2;</code>
       */
      public Builder setTrackingUrl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        trackingUrl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string tracking_url = 2;</code>
       */
      public Builder clearTrackingUrl() {
        bitField0_ = (bitField0_ & ~0x00000002);
        trackingUrl_ = getDefaultInstance().getTrackingUrl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string tracking_url = 2;</code>
       */
      public Builder setTrackingUrlBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        trackingUrl_ = value;
        onChanged();
        return this;
      }

      private int finalApplicationStatus_ = 0;
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 3;</code>
       */
      public boolean hasFinalApplicationStatus() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto getFinalApplicationStatus() {
        org.spiderdt.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto result = org.spiderdt.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.valueOf(finalApplicationStatus_);
        return result == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED : result;
      }
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 3;</code>
       */
      public Builder setFinalApplicationStatus(org.spiderdt.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000004;
        finalApplicationStatus_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 3;</code>
       */
      public Builder clearFinalApplicationStatus() {
        bitField0_ = (bitField0_ & ~0x00000004);
        finalApplicationStatus_ = 0;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.FinishApplicationMasterRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.FinishApplicationMasterRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<FinishApplicationMasterRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<FinishApplicationMasterRequestProto>() {
      public FinishApplicationMasterRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new FinishApplicationMasterRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<FinishApplicationMasterRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<FinishApplicationMasterRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FinishApplicationMasterResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.FinishApplicationMasterResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional bool isUnregistered = 1 [default = false];</code>
     */
    boolean hasIsUnregistered();
    /**
     * <code>optional bool isUnregistered = 1 [default = false];</code>
     */
    boolean getIsUnregistered();
  }
  /**
   * Protobuf type {@code hadoop.yarn.FinishApplicationMasterResponseProto}
   */
  public  static final class FinishApplicationMasterResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.FinishApplicationMasterResponseProto)
      FinishApplicationMasterResponseProtoOrBuilder {
    // Use FinishApplicationMasterResponseProto.newBuilder() to construct.
    private FinishApplicationMasterResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FinishApplicationMasterResponseProto() {
      isUnregistered_ = false;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private FinishApplicationMasterResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              isUnregistered_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FinishApplicationMasterResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FinishApplicationMasterResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto.Builder.class);
    }

    private int bitField0_;
    public static final int ISUNREGISTERED_FIELD_NUMBER = 1;
    private boolean isUnregistered_;
    /**
     * <code>optional bool isUnregistered = 1 [default = false];</code>
     */
    public boolean hasIsUnregistered() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bool isUnregistered = 1 [default = false];</code>
     */
    public boolean getIsUnregistered() {
      return isUnregistered_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBool(1, isUnregistered_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, isUnregistered_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto) obj;

      boolean result = true;
      result = result && (hasIsUnregistered() == other.hasIsUnregistered());
      if (hasIsUnregistered()) {
        result = result && (getIsUnregistered()
            == other.getIsUnregistered());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasIsUnregistered()) {
        hash = (37 * hash) + ISUNREGISTERED_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getIsUnregistered());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.FinishApplicationMasterResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.FinishApplicationMasterResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FinishApplicationMasterResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FinishApplicationMasterResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        isUnregistered_ = false;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FinishApplicationMasterResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.isUnregistered_ = isUnregistered_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto.getDefaultInstance()) return this;
        if (other.hasIsUnregistered()) {
          setIsUnregistered(other.getIsUnregistered());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private boolean isUnregistered_ ;
      /**
       * <code>optional bool isUnregistered = 1 [default = false];</code>
       */
      public boolean hasIsUnregistered() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional bool isUnregistered = 1 [default = false];</code>
       */
      public boolean getIsUnregistered() {
        return isUnregistered_;
      }
      /**
       * <code>optional bool isUnregistered = 1 [default = false];</code>
       */
      public Builder setIsUnregistered(boolean value) {
        bitField0_ |= 0x00000001;
        isUnregistered_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool isUnregistered = 1 [default = false];</code>
       */
      public Builder clearIsUnregistered() {
        bitField0_ = (bitField0_ & ~0x00000001);
        isUnregistered_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.FinishApplicationMasterResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.FinishApplicationMasterResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<FinishApplicationMasterResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<FinishApplicationMasterResponseProto>() {
      public FinishApplicationMasterResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new FinishApplicationMasterResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<FinishApplicationMasterResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<FinishApplicationMasterResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface AllocateRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.AllocateRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> 
        getAskList();
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getAsk(int index);
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
     */
    int getAskCount();
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
        getAskOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getAskOrBuilder(
        int index);

    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> 
        getReleaseList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getRelease(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
     */
    int getReleaseCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getReleaseOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getReleaseOrBuilder(
        int index);

    /**
     * <code>optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;</code>
     */
    boolean hasBlacklistRequest();
    /**
     * <code>optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto getBlacklistRequest();
    /**
     * <code>optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProtoOrBuilder getBlacklistRequestOrBuilder();

    /**
     * <code>optional int32 response_id = 4;</code>
     */
    boolean hasResponseId();
    /**
     * <code>optional int32 response_id = 4;</code>
     */
    int getResponseId();

    /**
     * <code>optional float progress = 5;</code>
     */
    boolean hasProgress();
    /**
     * <code>optional float progress = 5;</code>
     */
    float getProgress();

    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto> 
        getIncreaseRequestList();
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto getIncreaseRequest(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
     */
    int getIncreaseRequestCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder> 
        getIncreaseRequestOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder getIncreaseRequestOrBuilder(
        int index);

    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto> 
        getDecreaseRequestList();
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto getDecreaseRequest(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
     */
    int getDecreaseRequestCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder> 
        getDecreaseRequestOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder getDecreaseRequestOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.AllocateRequestProto}
   */
  public  static final class AllocateRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.AllocateRequestProto)
      AllocateRequestProtoOrBuilder {
    // Use AllocateRequestProto.newBuilder() to construct.
    private AllocateRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private AllocateRequestProto() {
      ask_ = java.util.Collections.emptyList();
      release_ = java.util.Collections.emptyList();
      responseId_ = 0;
      progress_ = 0F;
      increaseRequest_ = java.util.Collections.emptyList();
      decreaseRequest_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private AllocateRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                ask_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              ask_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.PARSER, extensionRegistry));
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                release_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto>();
                mutable_bitField0_ |= 0x00000002;
              }
              release_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry));
              break;
            }
            case 26: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = blacklistRequest_.toBuilder();
              }
              blacklistRequest_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(blacklistRequest_);
                blacklistRequest_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 32: {
              bitField0_ |= 0x00000002;
              responseId_ = input.readInt32();
              break;
            }
            case 45: {
              bitField0_ |= 0x00000004;
              progress_ = input.readFloat();
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                increaseRequest_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto>();
                mutable_bitField0_ |= 0x00000020;
              }
              increaseRequest_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.PARSER, extensionRegistry));
              break;
            }
            case 58: {
              if (!((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
                decreaseRequest_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto>();
                mutable_bitField0_ |= 0x00000040;
              }
              decreaseRequest_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          ask_ = java.util.Collections.unmodifiableList(ask_);
        }
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          release_ = java.util.Collections.unmodifiableList(release_);
        }
        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
          increaseRequest_ = java.util.Collections.unmodifiableList(increaseRequest_);
        }
        if (((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
          decreaseRequest_ = java.util.Collections.unmodifiableList(decreaseRequest_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_AllocateRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_AllocateRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int ASK_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> ask_;
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> getAskList() {
      return ask_;
    }
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
        getAskOrBuilderList() {
      return ask_;
    }
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
     */
    public int getAskCount() {
      return ask_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getAsk(int index) {
      return ask_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getAskOrBuilder(
        int index) {
      return ask_.get(index);
    }

    public static final int RELEASE_FIELD_NUMBER = 2;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> release_;
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getReleaseList() {
      return release_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getReleaseOrBuilderList() {
      return release_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
     */
    public int getReleaseCount() {
      return release_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getRelease(int index) {
      return release_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getReleaseOrBuilder(
        int index) {
      return release_.get(index);
    }

    public static final int BLACKLIST_REQUEST_FIELD_NUMBER = 3;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto blacklistRequest_;
    /**
     * <code>optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;</code>
     */
    public boolean hasBlacklistRequest() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto getBlacklistRequest() {
      return blacklistRequest_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.getDefaultInstance() : blacklistRequest_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProtoOrBuilder getBlacklistRequestOrBuilder() {
      return blacklistRequest_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.getDefaultInstance() : blacklistRequest_;
    }

    public static final int RESPONSE_ID_FIELD_NUMBER = 4;
    private int responseId_;
    /**
     * <code>optional int32 response_id = 4;</code>
     */
    public boolean hasResponseId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 response_id = 4;</code>
     */
    public int getResponseId() {
      return responseId_;
    }

    public static final int PROGRESS_FIELD_NUMBER = 5;
    private float progress_;
    /**
     * <code>optional float progress = 5;</code>
     */
    public boolean hasProgress() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional float progress = 5;</code>
     */
    public float getProgress() {
      return progress_;
    }

    public static final int INCREASE_REQUEST_FIELD_NUMBER = 6;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto> increaseRequest_;
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto> getIncreaseRequestList() {
      return increaseRequest_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder> 
        getIncreaseRequestOrBuilderList() {
      return increaseRequest_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
     */
    public int getIncreaseRequestCount() {
      return increaseRequest_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto getIncreaseRequest(int index) {
      return increaseRequest_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder getIncreaseRequestOrBuilder(
        int index) {
      return increaseRequest_.get(index);
    }

    public static final int DECREASE_REQUEST_FIELD_NUMBER = 7;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto> decreaseRequest_;
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto> getDecreaseRequestList() {
      return decreaseRequest_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder> 
        getDecreaseRequestOrBuilderList() {
      return decreaseRequest_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
     */
    public int getDecreaseRequestCount() {
      return decreaseRequest_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto getDecreaseRequest(int index) {
      return decreaseRequest_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder getDecreaseRequestOrBuilder(
        int index) {
      return decreaseRequest_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < ask_.size(); i++) {
        output.writeMessage(1, ask_.get(i));
      }
      for (int i = 0; i < release_.size(); i++) {
        output.writeMessage(2, release_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(3, getBlacklistRequest());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(4, responseId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeFloat(5, progress_);
      }
      for (int i = 0; i < increaseRequest_.size(); i++) {
        output.writeMessage(6, increaseRequest_.get(i));
      }
      for (int i = 0; i < decreaseRequest_.size(); i++) {
        output.writeMessage(7, decreaseRequest_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < ask_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, ask_.get(i));
      }
      for (int i = 0; i < release_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, release_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getBlacklistRequest());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, responseId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(5, progress_);
      }
      for (int i = 0; i < increaseRequest_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, increaseRequest_.get(i));
      }
      for (int i = 0; i < decreaseRequest_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, decreaseRequest_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto) obj;

      boolean result = true;
      result = result && getAskList()
          .equals(other.getAskList());
      result = result && getReleaseList()
          .equals(other.getReleaseList());
      result = result && (hasBlacklistRequest() == other.hasBlacklistRequest());
      if (hasBlacklistRequest()) {
        result = result && getBlacklistRequest()
            .equals(other.getBlacklistRequest());
      }
      result = result && (hasResponseId() == other.hasResponseId());
      if (hasResponseId()) {
        result = result && (getResponseId()
            == other.getResponseId());
      }
      result = result && (hasProgress() == other.hasProgress());
      if (hasProgress()) {
        result = result && (
            java.lang.Float.floatToIntBits(getProgress())
            == java.lang.Float.floatToIntBits(
                other.getProgress()));
      }
      result = result && getIncreaseRequestList()
          .equals(other.getIncreaseRequestList());
      result = result && getDecreaseRequestList()
          .equals(other.getDecreaseRequestList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getAskCount() > 0) {
        hash = (37 * hash) + ASK_FIELD_NUMBER;
        hash = (53 * hash) + getAskList().hashCode();
      }
      if (getReleaseCount() > 0) {
        hash = (37 * hash) + RELEASE_FIELD_NUMBER;
        hash = (53 * hash) + getReleaseList().hashCode();
      }
      if (hasBlacklistRequest()) {
        hash = (37 * hash) + BLACKLIST_REQUEST_FIELD_NUMBER;
        hash = (53 * hash) + getBlacklistRequest().hashCode();
      }
      if (hasResponseId()) {
        hash = (37 * hash) + RESPONSE_ID_FIELD_NUMBER;
        hash = (53 * hash) + getResponseId();
      }
      if (hasProgress()) {
        hash = (37 * hash) + PROGRESS_FIELD_NUMBER;
        hash = (53 * hash) + java.lang.Float.floatToIntBits(
            getProgress());
      }
      if (getIncreaseRequestCount() > 0) {
        hash = (37 * hash) + INCREASE_REQUEST_FIELD_NUMBER;
        hash = (53 * hash) + getIncreaseRequestList().hashCode();
      }
      if (getDecreaseRequestCount() > 0) {
        hash = (37 * hash) + DECREASE_REQUEST_FIELD_NUMBER;
        hash = (53 * hash) + getDecreaseRequestList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.AllocateRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.AllocateRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_AllocateRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_AllocateRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getAskFieldBuilder();
          getReleaseFieldBuilder();
          getBlacklistRequestFieldBuilder();
          getIncreaseRequestFieldBuilder();
          getDecreaseRequestFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (askBuilder_ == null) {
          ask_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          askBuilder_.clear();
        }
        if (releaseBuilder_ == null) {
          release_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          releaseBuilder_.clear();
        }
        if (blacklistRequestBuilder_ == null) {
          blacklistRequest_ = null;
        } else {
          blacklistRequestBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        responseId_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        progress_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000010);
        if (increaseRequestBuilder_ == null) {
          increaseRequest_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          increaseRequestBuilder_.clear();
        }
        if (decreaseRequestBuilder_ == null) {
          decreaseRequest_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
        } else {
          decreaseRequestBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_AllocateRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (askBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            ask_ = java.util.Collections.unmodifiableList(ask_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.ask_ = ask_;
        } else {
          result.ask_ = askBuilder_.build();
        }
        if (releaseBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            release_ = java.util.Collections.unmodifiableList(release_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.release_ = release_;
        } else {
          result.release_ = releaseBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000001;
        }
        if (blacklistRequestBuilder_ == null) {
          result.blacklistRequest_ = blacklistRequest_;
        } else {
          result.blacklistRequest_ = blacklistRequestBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000002;
        }
        result.responseId_ = responseId_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000004;
        }
        result.progress_ = progress_;
        if (increaseRequestBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            increaseRequest_ = java.util.Collections.unmodifiableList(increaseRequest_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.increaseRequest_ = increaseRequest_;
        } else {
          result.increaseRequest_ = increaseRequestBuilder_.build();
        }
        if (decreaseRequestBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040)) {
            decreaseRequest_ = java.util.Collections.unmodifiableList(decreaseRequest_);
            bitField0_ = (bitField0_ & ~0x00000040);
          }
          result.decreaseRequest_ = decreaseRequest_;
        } else {
          result.decreaseRequest_ = decreaseRequestBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.getDefaultInstance()) return this;
        if (askBuilder_ == null) {
          if (!other.ask_.isEmpty()) {
            if (ask_.isEmpty()) {
              ask_ = other.ask_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureAskIsMutable();
              ask_.addAll(other.ask_);
            }
            onChanged();
          }
        } else {
          if (!other.ask_.isEmpty()) {
            if (askBuilder_.isEmpty()) {
              askBuilder_.dispose();
              askBuilder_ = null;
              ask_ = other.ask_;
              bitField0_ = (bitField0_ & ~0x00000001);
              askBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getAskFieldBuilder() : null;
            } else {
              askBuilder_.addAllMessages(other.ask_);
            }
          }
        }
        if (releaseBuilder_ == null) {
          if (!other.release_.isEmpty()) {
            if (release_.isEmpty()) {
              release_ = other.release_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureReleaseIsMutable();
              release_.addAll(other.release_);
            }
            onChanged();
          }
        } else {
          if (!other.release_.isEmpty()) {
            if (releaseBuilder_.isEmpty()) {
              releaseBuilder_.dispose();
              releaseBuilder_ = null;
              release_ = other.release_;
              bitField0_ = (bitField0_ & ~0x00000002);
              releaseBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getReleaseFieldBuilder() : null;
            } else {
              releaseBuilder_.addAllMessages(other.release_);
            }
          }
        }
        if (other.hasBlacklistRequest()) {
          mergeBlacklistRequest(other.getBlacklistRequest());
        }
        if (other.hasResponseId()) {
          setResponseId(other.getResponseId());
        }
        if (other.hasProgress()) {
          setProgress(other.getProgress());
        }
        if (increaseRequestBuilder_ == null) {
          if (!other.increaseRequest_.isEmpty()) {
            if (increaseRequest_.isEmpty()) {
              increaseRequest_ = other.increaseRequest_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureIncreaseRequestIsMutable();
              increaseRequest_.addAll(other.increaseRequest_);
            }
            onChanged();
          }
        } else {
          if (!other.increaseRequest_.isEmpty()) {
            if (increaseRequestBuilder_.isEmpty()) {
              increaseRequestBuilder_.dispose();
              increaseRequestBuilder_ = null;
              increaseRequest_ = other.increaseRequest_;
              bitField0_ = (bitField0_ & ~0x00000020);
              increaseRequestBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getIncreaseRequestFieldBuilder() : null;
            } else {
              increaseRequestBuilder_.addAllMessages(other.increaseRequest_);
            }
          }
        }
        if (decreaseRequestBuilder_ == null) {
          if (!other.decreaseRequest_.isEmpty()) {
            if (decreaseRequest_.isEmpty()) {
              decreaseRequest_ = other.decreaseRequest_;
              bitField0_ = (bitField0_ & ~0x00000040);
            } else {
              ensureDecreaseRequestIsMutable();
              decreaseRequest_.addAll(other.decreaseRequest_);
            }
            onChanged();
          }
        } else {
          if (!other.decreaseRequest_.isEmpty()) {
            if (decreaseRequestBuilder_.isEmpty()) {
              decreaseRequestBuilder_.dispose();
              decreaseRequestBuilder_ = null;
              decreaseRequest_ = other.decreaseRequest_;
              bitField0_ = (bitField0_ & ~0x00000040);
              decreaseRequestBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getDecreaseRequestFieldBuilder() : null;
            } else {
              decreaseRequestBuilder_.addAllMessages(other.decreaseRequest_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> ask_ =
        java.util.Collections.emptyList();
      private void ensureAskIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          ask_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto>(ask_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> askBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> getAskList() {
        if (askBuilder_ == null) {
          return java.util.Collections.unmodifiableList(ask_);
        } else {
          return askBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public int getAskCount() {
        if (askBuilder_ == null) {
          return ask_.size();
        } else {
          return askBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getAsk(int index) {
        if (askBuilder_ == null) {
          return ask_.get(index);
        } else {
          return askBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public Builder setAsk(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (askBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAskIsMutable();
          ask_.set(index, value);
          onChanged();
        } else {
          askBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public Builder setAsk(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder builderForValue) {
        if (askBuilder_ == null) {
          ensureAskIsMutable();
          ask_.set(index, builderForValue.build());
          onChanged();
        } else {
          askBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public Builder addAsk(org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (askBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAskIsMutable();
          ask_.add(value);
          onChanged();
        } else {
          askBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public Builder addAsk(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (askBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAskIsMutable();
          ask_.add(index, value);
          onChanged();
        } else {
          askBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public Builder addAsk(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder builderForValue) {
        if (askBuilder_ == null) {
          ensureAskIsMutable();
          ask_.add(builderForValue.build());
          onChanged();
        } else {
          askBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public Builder addAsk(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder builderForValue) {
        if (askBuilder_ == null) {
          ensureAskIsMutable();
          ask_.add(index, builderForValue.build());
          onChanged();
        } else {
          askBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public Builder addAllAsk(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> values) {
        if (askBuilder_ == null) {
          ensureAskIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, ask_);
          onChanged();
        } else {
          askBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public Builder clearAsk() {
        if (askBuilder_ == null) {
          ask_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          askBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public Builder removeAsk(int index) {
        if (askBuilder_ == null) {
          ensureAskIsMutable();
          ask_.remove(index);
          onChanged();
        } else {
          askBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder getAskBuilder(
          int index) {
        return getAskFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getAskOrBuilder(
          int index) {
        if (askBuilder_ == null) {
          return ask_.get(index);  } else {
          return askBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
           getAskOrBuilderList() {
        if (askBuilder_ != null) {
          return askBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(ask_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder addAskBuilder() {
        return getAskFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder addAskBuilder(
          int index) {
        return getAskFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto ask = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder> 
           getAskBuilderList() {
        return getAskFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
          getAskFieldBuilder() {
        if (askBuilder_ == null) {
          askBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder>(
                  ask_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          ask_ = null;
        }
        return askBuilder_;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> release_ =
        java.util.Collections.emptyList();
      private void ensureReleaseIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          release_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto>(release_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> releaseBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getReleaseList() {
        if (releaseBuilder_ == null) {
          return java.util.Collections.unmodifiableList(release_);
        } else {
          return releaseBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public int getReleaseCount() {
        if (releaseBuilder_ == null) {
          return release_.size();
        } else {
          return releaseBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getRelease(int index) {
        if (releaseBuilder_ == null) {
          return release_.get(index);
        } else {
          return releaseBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public Builder setRelease(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (releaseBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReleaseIsMutable();
          release_.set(index, value);
          onChanged();
        } else {
          releaseBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public Builder setRelease(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (releaseBuilder_ == null) {
          ensureReleaseIsMutable();
          release_.set(index, builderForValue.build());
          onChanged();
        } else {
          releaseBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public Builder addRelease(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (releaseBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReleaseIsMutable();
          release_.add(value);
          onChanged();
        } else {
          releaseBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public Builder addRelease(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (releaseBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReleaseIsMutable();
          release_.add(index, value);
          onChanged();
        } else {
          releaseBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public Builder addRelease(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (releaseBuilder_ == null) {
          ensureReleaseIsMutable();
          release_.add(builderForValue.build());
          onChanged();
        } else {
          releaseBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public Builder addRelease(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (releaseBuilder_ == null) {
          ensureReleaseIsMutable();
          release_.add(index, builderForValue.build());
          onChanged();
        } else {
          releaseBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public Builder addAllRelease(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> values) {
        if (releaseBuilder_ == null) {
          ensureReleaseIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, release_);
          onChanged();
        } else {
          releaseBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public Builder clearRelease() {
        if (releaseBuilder_ == null) {
          release_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          releaseBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public Builder removeRelease(int index) {
        if (releaseBuilder_ == null) {
          ensureReleaseIsMutable();
          release_.remove(index);
          onChanged();
        } else {
          releaseBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getReleaseBuilder(
          int index) {
        return getReleaseFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getReleaseOrBuilder(
          int index) {
        if (releaseBuilder_ == null) {
          return release_.get(index);  } else {
          return releaseBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
           getReleaseOrBuilderList() {
        if (releaseBuilder_ != null) {
          return releaseBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(release_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addReleaseBuilder() {
        return getReleaseFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addReleaseBuilder(
          int index) {
        return getReleaseFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto release = 2;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder> 
           getReleaseBuilderList() {
        return getReleaseFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getReleaseFieldBuilder() {
        if (releaseBuilder_ == null) {
          releaseBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  release_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          release_ = null;
        }
        return releaseBuilder_;
      }

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto blacklistRequest_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProtoOrBuilder> blacklistRequestBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;</code>
       */
      public boolean hasBlacklistRequest() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto getBlacklistRequest() {
        if (blacklistRequestBuilder_ == null) {
          return blacklistRequest_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.getDefaultInstance() : blacklistRequest_;
        } else {
          return blacklistRequestBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;</code>
       */
      public Builder setBlacklistRequest(org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto value) {
        if (blacklistRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          blacklistRequest_ = value;
          onChanged();
        } else {
          blacklistRequestBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;</code>
       */
      public Builder setBlacklistRequest(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.Builder builderForValue) {
        if (blacklistRequestBuilder_ == null) {
          blacklistRequest_ = builderForValue.build();
          onChanged();
        } else {
          blacklistRequestBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;</code>
       */
      public Builder mergeBlacklistRequest(org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto value) {
        if (blacklistRequestBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              blacklistRequest_ != null &&
              blacklistRequest_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.getDefaultInstance()) {
            blacklistRequest_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.newBuilder(blacklistRequest_).mergeFrom(value).buildPartial();
          } else {
            blacklistRequest_ = value;
          }
          onChanged();
        } else {
          blacklistRequestBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;</code>
       */
      public Builder clearBlacklistRequest() {
        if (blacklistRequestBuilder_ == null) {
          blacklistRequest_ = null;
          onChanged();
        } else {
          blacklistRequestBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.Builder getBlacklistRequestBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getBlacklistRequestFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProtoOrBuilder getBlacklistRequestOrBuilder() {
        if (blacklistRequestBuilder_ != null) {
          return blacklistRequestBuilder_.getMessageOrBuilder();
        } else {
          return blacklistRequest_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.getDefaultInstance() : blacklistRequest_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProtoOrBuilder> 
          getBlacklistRequestFieldBuilder() {
        if (blacklistRequestBuilder_ == null) {
          blacklistRequestBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProtoOrBuilder>(
                  getBlacklistRequest(),
                  getParentForChildren(),
                  isClean());
          blacklistRequest_ = null;
        }
        return blacklistRequestBuilder_;
      }

      private int responseId_ ;
      /**
       * <code>optional int32 response_id = 4;</code>
       */
      public boolean hasResponseId() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int32 response_id = 4;</code>
       */
      public int getResponseId() {
        return responseId_;
      }
      /**
       * <code>optional int32 response_id = 4;</code>
       */
      public Builder setResponseId(int value) {
        bitField0_ |= 0x00000008;
        responseId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 response_id = 4;</code>
       */
      public Builder clearResponseId() {
        bitField0_ = (bitField0_ & ~0x00000008);
        responseId_ = 0;
        onChanged();
        return this;
      }

      private float progress_ ;
      /**
       * <code>optional float progress = 5;</code>
       */
      public boolean hasProgress() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional float progress = 5;</code>
       */
      public float getProgress() {
        return progress_;
      }
      /**
       * <code>optional float progress = 5;</code>
       */
      public Builder setProgress(float value) {
        bitField0_ |= 0x00000010;
        progress_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float progress = 5;</code>
       */
      public Builder clearProgress() {
        bitField0_ = (bitField0_ & ~0x00000010);
        progress_ = 0F;
        onChanged();
        return this;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto> increaseRequest_ =
        java.util.Collections.emptyList();
      private void ensureIncreaseRequestIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          increaseRequest_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto>(increaseRequest_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder> increaseRequestBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto> getIncreaseRequestList() {
        if (increaseRequestBuilder_ == null) {
          return java.util.Collections.unmodifiableList(increaseRequest_);
        } else {
          return increaseRequestBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public int getIncreaseRequestCount() {
        if (increaseRequestBuilder_ == null) {
          return increaseRequest_.size();
        } else {
          return increaseRequestBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto getIncreaseRequest(int index) {
        if (increaseRequestBuilder_ == null) {
          return increaseRequest_.get(index);
        } else {
          return increaseRequestBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public Builder setIncreaseRequest(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto value) {
        if (increaseRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureIncreaseRequestIsMutable();
          increaseRequest_.set(index, value);
          onChanged();
        } else {
          increaseRequestBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public Builder setIncreaseRequest(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder builderForValue) {
        if (increaseRequestBuilder_ == null) {
          ensureIncreaseRequestIsMutable();
          increaseRequest_.set(index, builderForValue.build());
          onChanged();
        } else {
          increaseRequestBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public Builder addIncreaseRequest(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto value) {
        if (increaseRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureIncreaseRequestIsMutable();
          increaseRequest_.add(value);
          onChanged();
        } else {
          increaseRequestBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public Builder addIncreaseRequest(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto value) {
        if (increaseRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureIncreaseRequestIsMutable();
          increaseRequest_.add(index, value);
          onChanged();
        } else {
          increaseRequestBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public Builder addIncreaseRequest(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder builderForValue) {
        if (increaseRequestBuilder_ == null) {
          ensureIncreaseRequestIsMutable();
          increaseRequest_.add(builderForValue.build());
          onChanged();
        } else {
          increaseRequestBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public Builder addIncreaseRequest(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder builderForValue) {
        if (increaseRequestBuilder_ == null) {
          ensureIncreaseRequestIsMutable();
          increaseRequest_.add(index, builderForValue.build());
          onChanged();
        } else {
          increaseRequestBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public Builder addAllIncreaseRequest(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto> values) {
        if (increaseRequestBuilder_ == null) {
          ensureIncreaseRequestIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, increaseRequest_);
          onChanged();
        } else {
          increaseRequestBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public Builder clearIncreaseRequest() {
        if (increaseRequestBuilder_ == null) {
          increaseRequest_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          increaseRequestBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public Builder removeIncreaseRequest(int index) {
        if (increaseRequestBuilder_ == null) {
          ensureIncreaseRequestIsMutable();
          increaseRequest_.remove(index);
          onChanged();
        } else {
          increaseRequestBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder getIncreaseRequestBuilder(
          int index) {
        return getIncreaseRequestFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder getIncreaseRequestOrBuilder(
          int index) {
        if (increaseRequestBuilder_ == null) {
          return increaseRequest_.get(index);  } else {
          return increaseRequestBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder> 
           getIncreaseRequestOrBuilderList() {
        if (increaseRequestBuilder_ != null) {
          return increaseRequestBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(increaseRequest_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder addIncreaseRequestBuilder() {
        return getIncreaseRequestFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder addIncreaseRequestBuilder(
          int index) {
        return getIncreaseRequestFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto increase_request = 6;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder> 
           getIncreaseRequestBuilderList() {
        return getIncreaseRequestFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder> 
          getIncreaseRequestFieldBuilder() {
        if (increaseRequestBuilder_ == null) {
          increaseRequestBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder>(
                  increaseRequest_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          increaseRequest_ = null;
        }
        return increaseRequestBuilder_;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto> decreaseRequest_ =
        java.util.Collections.emptyList();
      private void ensureDecreaseRequestIsMutable() {
        if (!((bitField0_ & 0x00000040) == 0x00000040)) {
          decreaseRequest_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto>(decreaseRequest_);
          bitField0_ |= 0x00000040;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder> decreaseRequestBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto> getDecreaseRequestList() {
        if (decreaseRequestBuilder_ == null) {
          return java.util.Collections.unmodifiableList(decreaseRequest_);
        } else {
          return decreaseRequestBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public int getDecreaseRequestCount() {
        if (decreaseRequestBuilder_ == null) {
          return decreaseRequest_.size();
        } else {
          return decreaseRequestBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto getDecreaseRequest(int index) {
        if (decreaseRequestBuilder_ == null) {
          return decreaseRequest_.get(index);
        } else {
          return decreaseRequestBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public Builder setDecreaseRequest(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto value) {
        if (decreaseRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDecreaseRequestIsMutable();
          decreaseRequest_.set(index, value);
          onChanged();
        } else {
          decreaseRequestBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public Builder setDecreaseRequest(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder builderForValue) {
        if (decreaseRequestBuilder_ == null) {
          ensureDecreaseRequestIsMutable();
          decreaseRequest_.set(index, builderForValue.build());
          onChanged();
        } else {
          decreaseRequestBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public Builder addDecreaseRequest(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto value) {
        if (decreaseRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDecreaseRequestIsMutable();
          decreaseRequest_.add(value);
          onChanged();
        } else {
          decreaseRequestBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public Builder addDecreaseRequest(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto value) {
        if (decreaseRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDecreaseRequestIsMutable();
          decreaseRequest_.add(index, value);
          onChanged();
        } else {
          decreaseRequestBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public Builder addDecreaseRequest(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder builderForValue) {
        if (decreaseRequestBuilder_ == null) {
          ensureDecreaseRequestIsMutable();
          decreaseRequest_.add(builderForValue.build());
          onChanged();
        } else {
          decreaseRequestBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public Builder addDecreaseRequest(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder builderForValue) {
        if (decreaseRequestBuilder_ == null) {
          ensureDecreaseRequestIsMutable();
          decreaseRequest_.add(index, builderForValue.build());
          onChanged();
        } else {
          decreaseRequestBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public Builder addAllDecreaseRequest(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto> values) {
        if (decreaseRequestBuilder_ == null) {
          ensureDecreaseRequestIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, decreaseRequest_);
          onChanged();
        } else {
          decreaseRequestBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public Builder clearDecreaseRequest() {
        if (decreaseRequestBuilder_ == null) {
          decreaseRequest_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
          onChanged();
        } else {
          decreaseRequestBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public Builder removeDecreaseRequest(int index) {
        if (decreaseRequestBuilder_ == null) {
          ensureDecreaseRequestIsMutable();
          decreaseRequest_.remove(index);
          onChanged();
        } else {
          decreaseRequestBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder getDecreaseRequestBuilder(
          int index) {
        return getDecreaseRequestFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder getDecreaseRequestOrBuilder(
          int index) {
        if (decreaseRequestBuilder_ == null) {
          return decreaseRequest_.get(index);  } else {
          return decreaseRequestBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder> 
           getDecreaseRequestOrBuilderList() {
        if (decreaseRequestBuilder_ != null) {
          return decreaseRequestBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(decreaseRequest_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder addDecreaseRequestBuilder() {
        return getDecreaseRequestFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder addDecreaseRequestBuilder(
          int index) {
        return getDecreaseRequestFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerResourceChangeRequestProto decrease_request = 7;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder> 
           getDecreaseRequestBuilderList() {
        return getDecreaseRequestFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder> 
          getDecreaseRequestFieldBuilder() {
        if (decreaseRequestBuilder_ == null) {
          decreaseRequestBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerResourceChangeRequestProtoOrBuilder>(
                  decreaseRequest_,
                  ((bitField0_ & 0x00000040) == 0x00000040),
                  getParentForChildren(),
                  isClean());
          decreaseRequest_ = null;
        }
        return decreaseRequestBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.AllocateRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.AllocateRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<AllocateRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<AllocateRequestProto>() {
      public AllocateRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new AllocateRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<AllocateRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<AllocateRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface NMTokenProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.NMTokenProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    /**
     * <code>optional .hadoop.common.TokenProto token = 2;</code>
     */
    boolean hasToken();
    /**
     * <code>optional .hadoop.common.TokenProto token = 2;</code>
     */
    org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto getToken();
    /**
     * <code>optional .hadoop.common.TokenProto token = 2;</code>
     */
    org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getTokenOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.NMTokenProto}
   */
  public  static final class NMTokenProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.NMTokenProto)
      NMTokenProtoOrBuilder {
    // Use NMTokenProto.newBuilder() to construct.
    private NMTokenProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private NMTokenProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private NMTokenProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = token_.toBuilder();
              }
              token_ = input.readMessage(org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(token_);
                token_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_NMTokenProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_NMTokenProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder.class);
    }

    private int bitField0_;
    public static final int NODEID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
    }

    public static final int TOKEN_FIELD_NUMBER = 2;
    private org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto token_;
    /**
     * <code>optional .hadoop.common.TokenProto token = 2;</code>
     */
    public boolean hasToken() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.common.TokenProto token = 2;</code>
     */
    public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto getToken() {
      return token_ == null ? org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : token_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto token = 2;</code>
     */
    public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getTokenOrBuilder() {
      return token_ == null ? org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : token_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasToken()) {
        if (!getToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getNodeId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getToken());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getNodeId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getToken());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto) obj;

      boolean result = true;
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && (hasToken() == other.hasToken());
      if (hasToken()) {
        result = result && getToken()
            .equals(other.getToken());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNodeId()) {
        hash = (37 * hash) + NODEID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (hasToken()) {
        hash = (37 * hash) + TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getToken().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NMTokenProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.NMTokenProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_NMTokenProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_NMTokenProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNodeIdFieldBuilder();
          getTokenFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (nodeIdBuilder_ == null) {
          nodeId_ = null;
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tokenBuilder_ == null) {
          token_ = null;
        } else {
          tokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_NMTokenProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (tokenBuilder_ == null) {
          result.token_ = token_;
        } else {
          result.token_ = tokenBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.getDefaultInstance()) return this;
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (other.hasToken()) {
          mergeToken(other.getToken());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (hasToken()) {
          if (!getToken().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder setNodeId(org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder setNodeId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder mergeNodeId(org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              nodeId_ != null &&
              nodeId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = null;
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  getNodeId(),
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      private org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto token_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> tokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto token = 2;</code>
       */
      public boolean hasToken() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.common.TokenProto token = 2;</code>
       */
      public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto getToken() {
        if (tokenBuilder_ == null) {
          return token_ == null ? org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : token_;
        } else {
          return tokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto token = 2;</code>
       */
      public Builder setToken(org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (tokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          token_ = value;
          onChanged();
        } else {
          tokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto token = 2;</code>
       */
      public Builder setToken(
          org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (tokenBuilder_ == null) {
          token_ = builderForValue.build();
          onChanged();
        } else {
          tokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto token = 2;</code>
       */
      public Builder mergeToken(org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (tokenBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              token_ != null &&
              token_ != org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            token_ =
              org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(token_).mergeFrom(value).buildPartial();
          } else {
            token_ = value;
          }
          onChanged();
        } else {
          tokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto token = 2;</code>
       */
      public Builder clearToken() {
        if (tokenBuilder_ == null) {
          token_ = null;
          onChanged();
        } else {
          tokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto token = 2;</code>
       */
      public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder getTokenBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto token = 2;</code>
       */
      public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getTokenOrBuilder() {
        if (tokenBuilder_ != null) {
          return tokenBuilder_.getMessageOrBuilder();
        } else {
          return token_ == null ?
              org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : token_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto token = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getTokenFieldBuilder() {
        if (tokenBuilder_ == null) {
          tokenBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  getToken(),
                  getParentForChildren(),
                  isClean());
          token_ = null;
        }
        return tokenBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NMTokenProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NMTokenProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<NMTokenProto>
        PARSER = new com.google.protobuf.AbstractParser<NMTokenProto>() {
      public NMTokenProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new NMTokenProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<NMTokenProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<NMTokenProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface AllocateResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.AllocateResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.AMCommandProto a_m_command = 1;</code>
     */
    boolean hasAMCommand();
    /**
     * <code>optional .hadoop.yarn.AMCommandProto a_m_command = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.AMCommandProto getAMCommand();

    /**
     * <code>optional int32 response_id = 2;</code>
     */
    boolean hasResponseId();
    /**
     * <code>optional int32 response_id = 2;</code>
     */
    int getResponseId();

    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> 
        getAllocatedContainersList();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto getAllocatedContainers(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
     */
    int getAllocatedContainersCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
        getAllocatedContainersOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getAllocatedContainersOrBuilder(
        int index);

    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> 
        getCompletedContainerStatusesList();
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getCompletedContainerStatuses(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
     */
    int getCompletedContainerStatusesCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> 
        getCompletedContainerStatusesOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder getCompletedContainerStatusesOrBuilder(
        int index);

    /**
     * <code>optional .hadoop.yarn.ResourceProto limit = 5;</code>
     */
    boolean hasLimit();
    /**
     * <code>optional .hadoop.yarn.ResourceProto limit = 5;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto getLimit();
    /**
     * <code>optional .hadoop.yarn.ResourceProto limit = 5;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getLimitOrBuilder();

    /**
     * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto> 
        getUpdatedNodesList();
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto getUpdatedNodes(int index);
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
     */
    int getUpdatedNodesCount();
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder> 
        getUpdatedNodesOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder getUpdatedNodesOrBuilder(
        int index);

    /**
     * <code>optional int32 num_cluster_nodes = 7;</code>
     */
    boolean hasNumClusterNodes();
    /**
     * <code>optional int32 num_cluster_nodes = 7;</code>
     */
    int getNumClusterNodes();

    /**
     * <code>optional .hadoop.yarn.PreemptionMessageProto preempt = 8;</code>
     */
    boolean hasPreempt();
    /**
     * <code>optional .hadoop.yarn.PreemptionMessageProto preempt = 8;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto getPreempt();
    /**
     * <code>optional .hadoop.yarn.PreemptionMessageProto preempt = 8;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProtoOrBuilder getPreemptOrBuilder();

    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto> 
        getNmTokensList();
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto getNmTokens(int index);
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
     */
    int getNmTokensCount();
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder> 
        getNmTokensOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder getNmTokensOrBuilder(
        int index);

    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> 
        getIncreasedContainersList();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto getIncreasedContainers(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
     */
    int getIncreasedContainersCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
        getIncreasedContainersOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getIncreasedContainersOrBuilder(
        int index);

    /**
     * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> 
        getDecreasedContainersList();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto getDecreasedContainers(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
     */
    int getDecreasedContainersCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
        getDecreasedContainersOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getDecreasedContainersOrBuilder(
        int index);

    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 12;</code>
     */
    boolean hasAmRmToken();
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 12;</code>
     */
    org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto getAmRmToken();
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 12;</code>
     */
    org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getAmRmTokenOrBuilder();

    /**
     * <code>optional .hadoop.yarn.PriorityProto application_priority = 13;</code>
     */
    boolean hasApplicationPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto application_priority = 13;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto getApplicationPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto application_priority = 13;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getApplicationPriorityOrBuilder();

    /**
     * <code>optional string collector_addr = 14;</code>
     */
    boolean hasCollectorAddr();
    /**
     * <code>optional string collector_addr = 14;</code>
     */
    java.lang.String getCollectorAddr();
    /**
     * <code>optional string collector_addr = 14;</code>
     */
    com.google.protobuf.ByteString
        getCollectorAddrBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.AllocateResponseProto}
   */
  public  static final class AllocateResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.AllocateResponseProto)
      AllocateResponseProtoOrBuilder {
    // Use AllocateResponseProto.newBuilder() to construct.
    private AllocateResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private AllocateResponseProto() {
      aMCommand_ = 1;
      responseId_ = 0;
      allocatedContainers_ = java.util.Collections.emptyList();
      completedContainerStatuses_ = java.util.Collections.emptyList();
      updatedNodes_ = java.util.Collections.emptyList();
      numClusterNodes_ = 0;
      nmTokens_ = java.util.Collections.emptyList();
      increasedContainers_ = java.util.Collections.emptyList();
      decreasedContainers_ = java.util.Collections.emptyList();
      collectorAddr_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private AllocateResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.spiderdt.hadoop.yarn.proto.YarnProtos.AMCommandProto value = org.spiderdt.hadoop.yarn.proto.YarnProtos.AMCommandProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                aMCommand_ = rawValue;
              }
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              responseId_ = input.readInt32();
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                allocatedContainers_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto>();
                mutable_bitField0_ |= 0x00000004;
              }
              allocatedContainers_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.PARSER, extensionRegistry));
              break;
            }
            case 34: {
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                completedContainerStatuses_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto>();
                mutable_bitField0_ |= 0x00000008;
              }
              completedContainerStatuses_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.PARSER, extensionRegistry));
              break;
            }
            case 42: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = limit_.toBuilder();
              }
              limit_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(limit_);
                limit_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                updatedNodes_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto>();
                mutable_bitField0_ |= 0x00000020;
              }
              updatedNodes_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.PARSER, extensionRegistry));
              break;
            }
            case 56: {
              bitField0_ |= 0x00000008;
              numClusterNodes_ = input.readInt32();
              break;
            }
            case 66: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = preempt_.toBuilder();
              }
              preempt_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(preempt_);
                preempt_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 74: {
              if (!((mutable_bitField0_ & 0x00000100) == 0x00000100)) {
                nmTokens_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto>();
                mutable_bitField0_ |= 0x00000100;
              }
              nmTokens_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.PARSER, extensionRegistry));
              break;
            }
            case 82: {
              if (!((mutable_bitField0_ & 0x00000200) == 0x00000200)) {
                increasedContainers_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto>();
                mutable_bitField0_ |= 0x00000200;
              }
              increasedContainers_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.PARSER, extensionRegistry));
              break;
            }
            case 90: {
              if (!((mutable_bitField0_ & 0x00000400) == 0x00000400)) {
                decreasedContainers_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto>();
                mutable_bitField0_ |= 0x00000400;
              }
              decreasedContainers_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.PARSER, extensionRegistry));
              break;
            }
            case 98: {
              org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000020) == 0x00000020)) {
                subBuilder = amRmToken_.toBuilder();
              }
              amRmToken_ = input.readMessage(org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(amRmToken_);
                amRmToken_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000020;
              break;
            }
            case 106: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000040) == 0x00000040)) {
                subBuilder = applicationPriority_.toBuilder();
              }
              applicationPriority_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationPriority_);
                applicationPriority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000040;
              break;
            }
            case 114: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000080;
              collectorAddr_ = bs;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          allocatedContainers_ = java.util.Collections.unmodifiableList(allocatedContainers_);
        }
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          completedContainerStatuses_ = java.util.Collections.unmodifiableList(completedContainerStatuses_);
        }
        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
          updatedNodes_ = java.util.Collections.unmodifiableList(updatedNodes_);
        }
        if (((mutable_bitField0_ & 0x00000100) == 0x00000100)) {
          nmTokens_ = java.util.Collections.unmodifiableList(nmTokens_);
        }
        if (((mutable_bitField0_ & 0x00000200) == 0x00000200)) {
          increasedContainers_ = java.util.Collections.unmodifiableList(increasedContainers_);
        }
        if (((mutable_bitField0_ & 0x00000400) == 0x00000400)) {
          decreasedContainers_ = java.util.Collections.unmodifiableList(decreasedContainers_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_AllocateResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_AllocateResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.Builder.class);
    }

    private int bitField0_;
    public static final int A_M_COMMAND_FIELD_NUMBER = 1;
    private int aMCommand_;
    /**
     * <code>optional .hadoop.yarn.AMCommandProto a_m_command = 1;</code>
     */
    public boolean hasAMCommand() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.AMCommandProto a_m_command = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.AMCommandProto getAMCommand() {
      org.spiderdt.hadoop.yarn.proto.YarnProtos.AMCommandProto result = org.spiderdt.hadoop.yarn.proto.YarnProtos.AMCommandProto.valueOf(aMCommand_);
      return result == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.AMCommandProto.AM_RESYNC : result;
    }

    public static final int RESPONSE_ID_FIELD_NUMBER = 2;
    private int responseId_;
    /**
     * <code>optional int32 response_id = 2;</code>
     */
    public boolean hasResponseId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 response_id = 2;</code>
     */
    public int getResponseId() {
      return responseId_;
    }

    public static final int ALLOCATED_CONTAINERS_FIELD_NUMBER = 3;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> allocatedContainers_;
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> getAllocatedContainersList() {
      return allocatedContainers_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
        getAllocatedContainersOrBuilderList() {
      return allocatedContainers_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
     */
    public int getAllocatedContainersCount() {
      return allocatedContainers_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto getAllocatedContainers(int index) {
      return allocatedContainers_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getAllocatedContainersOrBuilder(
        int index) {
      return allocatedContainers_.get(index);
    }

    public static final int COMPLETED_CONTAINER_STATUSES_FIELD_NUMBER = 4;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> completedContainerStatuses_;
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> getCompletedContainerStatusesList() {
      return completedContainerStatuses_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> 
        getCompletedContainerStatusesOrBuilderList() {
      return completedContainerStatuses_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
     */
    public int getCompletedContainerStatusesCount() {
      return completedContainerStatuses_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getCompletedContainerStatuses(int index) {
      return completedContainerStatuses_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder getCompletedContainerStatusesOrBuilder(
        int index) {
      return completedContainerStatuses_.get(index);
    }

    public static final int LIMIT_FIELD_NUMBER = 5;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto limit_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto limit = 5;</code>
     */
    public boolean hasLimit() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto limit = 5;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto getLimit() {
      return limit_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : limit_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto limit = 5;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getLimitOrBuilder() {
      return limit_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : limit_;
    }

    public static final int UPDATED_NODES_FIELD_NUMBER = 6;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto> updatedNodes_;
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto> getUpdatedNodesList() {
      return updatedNodes_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder> 
        getUpdatedNodesOrBuilderList() {
      return updatedNodes_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
     */
    public int getUpdatedNodesCount() {
      return updatedNodes_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto getUpdatedNodes(int index) {
      return updatedNodes_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder getUpdatedNodesOrBuilder(
        int index) {
      return updatedNodes_.get(index);
    }

    public static final int NUM_CLUSTER_NODES_FIELD_NUMBER = 7;
    private int numClusterNodes_;
    /**
     * <code>optional int32 num_cluster_nodes = 7;</code>
     */
    public boolean hasNumClusterNodes() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional int32 num_cluster_nodes = 7;</code>
     */
    public int getNumClusterNodes() {
      return numClusterNodes_;
    }

    public static final int PREEMPT_FIELD_NUMBER = 8;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto preempt_;
    /**
     * <code>optional .hadoop.yarn.PreemptionMessageProto preempt = 8;</code>
     */
    public boolean hasPreempt() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.PreemptionMessageProto preempt = 8;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto getPreempt() {
      return preempt_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.getDefaultInstance() : preempt_;
    }
    /**
     * <code>optional .hadoop.yarn.PreemptionMessageProto preempt = 8;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProtoOrBuilder getPreemptOrBuilder() {
      return preempt_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.getDefaultInstance() : preempt_;
    }

    public static final int NM_TOKENS_FIELD_NUMBER = 9;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto> nmTokens_;
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto> getNmTokensList() {
      return nmTokens_;
    }
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder> 
        getNmTokensOrBuilderList() {
      return nmTokens_;
    }
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
     */
    public int getNmTokensCount() {
      return nmTokens_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto getNmTokens(int index) {
      return nmTokens_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder getNmTokensOrBuilder(
        int index) {
      return nmTokens_.get(index);
    }

    public static final int INCREASED_CONTAINERS_FIELD_NUMBER = 10;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> increasedContainers_;
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> getIncreasedContainersList() {
      return increasedContainers_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
        getIncreasedContainersOrBuilderList() {
      return increasedContainers_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
     */
    public int getIncreasedContainersCount() {
      return increasedContainers_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto getIncreasedContainers(int index) {
      return increasedContainers_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getIncreasedContainersOrBuilder(
        int index) {
      return increasedContainers_.get(index);
    }

    public static final int DECREASED_CONTAINERS_FIELD_NUMBER = 11;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> decreasedContainers_;
    /**
     * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> getDecreasedContainersList() {
      return decreasedContainers_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
        getDecreasedContainersOrBuilderList() {
      return decreasedContainers_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
     */
    public int getDecreasedContainersCount() {
      return decreasedContainers_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto getDecreasedContainers(int index) {
      return decreasedContainers_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getDecreasedContainersOrBuilder(
        int index) {
      return decreasedContainers_.get(index);
    }

    public static final int AM_RM_TOKEN_FIELD_NUMBER = 12;
    private org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto amRmToken_;
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 12;</code>
     */
    public boolean hasAmRmToken() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 12;</code>
     */
    public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto getAmRmToken() {
      return amRmToken_ == null ? org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : amRmToken_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 12;</code>
     */
    public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getAmRmTokenOrBuilder() {
      return amRmToken_ == null ? org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : amRmToken_;
    }

    public static final int APPLICATION_PRIORITY_FIELD_NUMBER = 13;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto applicationPriority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto application_priority = 13;</code>
     */
    public boolean hasApplicationPriority() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto application_priority = 13;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto getApplicationPriority() {
      return applicationPriority_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : applicationPriority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto application_priority = 13;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getApplicationPriorityOrBuilder() {
      return applicationPriority_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : applicationPriority_;
    }

    public static final int COLLECTOR_ADDR_FIELD_NUMBER = 14;
    private volatile java.lang.Object collectorAddr_;
    /**
     * <code>optional string collector_addr = 14;</code>
     */
    public boolean hasCollectorAddr() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional string collector_addr = 14;</code>
     */
    public java.lang.String getCollectorAddr() {
      java.lang.Object ref = collectorAddr_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          collectorAddr_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string collector_addr = 14;</code>
     */
    public com.google.protobuf.ByteString
        getCollectorAddrBytes() {
      java.lang.Object ref = collectorAddr_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        collectorAddr_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getAllocatedContainersCount(); i++) {
        if (!getAllocatedContainers(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getNmTokensCount(); i++) {
        if (!getNmTokens(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getIncreasedContainersCount(); i++) {
        if (!getIncreasedContainers(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getDecreasedContainersCount(); i++) {
        if (!getDecreasedContainers(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasAmRmToken()) {
        if (!getAmRmToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, aMCommand_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, responseId_);
      }
      for (int i = 0; i < allocatedContainers_.size(); i++) {
        output.writeMessage(3, allocatedContainers_.get(i));
      }
      for (int i = 0; i < completedContainerStatuses_.size(); i++) {
        output.writeMessage(4, completedContainerStatuses_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(5, getLimit());
      }
      for (int i = 0; i < updatedNodes_.size(); i++) {
        output.writeMessage(6, updatedNodes_.get(i));
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt32(7, numClusterNodes_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(8, getPreempt());
      }
      for (int i = 0; i < nmTokens_.size(); i++) {
        output.writeMessage(9, nmTokens_.get(i));
      }
      for (int i = 0; i < increasedContainers_.size(); i++) {
        output.writeMessage(10, increasedContainers_.get(i));
      }
      for (int i = 0; i < decreasedContainers_.size(); i++) {
        output.writeMessage(11, decreasedContainers_.get(i));
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeMessage(12, getAmRmToken());
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeMessage(13, getApplicationPriority());
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 14, collectorAddr_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, aMCommand_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, responseId_);
      }
      for (int i = 0; i < allocatedContainers_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, allocatedContainers_.get(i));
      }
      for (int i = 0; i < completedContainerStatuses_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, completedContainerStatuses_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getLimit());
      }
      for (int i = 0; i < updatedNodes_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, updatedNodes_.get(i));
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(7, numClusterNodes_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, getPreempt());
      }
      for (int i = 0; i < nmTokens_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, nmTokens_.get(i));
      }
      for (int i = 0; i < increasedContainers_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, increasedContainers_.get(i));
      }
      for (int i = 0; i < decreasedContainers_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(11, decreasedContainers_.get(i));
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(12, getAmRmToken());
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(13, getApplicationPriority());
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(14, collectorAddr_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto) obj;

      boolean result = true;
      result = result && (hasAMCommand() == other.hasAMCommand());
      if (hasAMCommand()) {
        result = result && aMCommand_ == other.aMCommand_;
      }
      result = result && (hasResponseId() == other.hasResponseId());
      if (hasResponseId()) {
        result = result && (getResponseId()
            == other.getResponseId());
      }
      result = result && getAllocatedContainersList()
          .equals(other.getAllocatedContainersList());
      result = result && getCompletedContainerStatusesList()
          .equals(other.getCompletedContainerStatusesList());
      result = result && (hasLimit() == other.hasLimit());
      if (hasLimit()) {
        result = result && getLimit()
            .equals(other.getLimit());
      }
      result = result && getUpdatedNodesList()
          .equals(other.getUpdatedNodesList());
      result = result && (hasNumClusterNodes() == other.hasNumClusterNodes());
      if (hasNumClusterNodes()) {
        result = result && (getNumClusterNodes()
            == other.getNumClusterNodes());
      }
      result = result && (hasPreempt() == other.hasPreempt());
      if (hasPreempt()) {
        result = result && getPreempt()
            .equals(other.getPreempt());
      }
      result = result && getNmTokensList()
          .equals(other.getNmTokensList());
      result = result && getIncreasedContainersList()
          .equals(other.getIncreasedContainersList());
      result = result && getDecreasedContainersList()
          .equals(other.getDecreasedContainersList());
      result = result && (hasAmRmToken() == other.hasAmRmToken());
      if (hasAmRmToken()) {
        result = result && getAmRmToken()
            .equals(other.getAmRmToken());
      }
      result = result && (hasApplicationPriority() == other.hasApplicationPriority());
      if (hasApplicationPriority()) {
        result = result && getApplicationPriority()
            .equals(other.getApplicationPriority());
      }
      result = result && (hasCollectorAddr() == other.hasCollectorAddr());
      if (hasCollectorAddr()) {
        result = result && getCollectorAddr()
            .equals(other.getCollectorAddr());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasAMCommand()) {
        hash = (37 * hash) + A_M_COMMAND_FIELD_NUMBER;
        hash = (53 * hash) + aMCommand_;
      }
      if (hasResponseId()) {
        hash = (37 * hash) + RESPONSE_ID_FIELD_NUMBER;
        hash = (53 * hash) + getResponseId();
      }
      if (getAllocatedContainersCount() > 0) {
        hash = (37 * hash) + ALLOCATED_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getAllocatedContainersList().hashCode();
      }
      if (getCompletedContainerStatusesCount() > 0) {
        hash = (37 * hash) + COMPLETED_CONTAINER_STATUSES_FIELD_NUMBER;
        hash = (53 * hash) + getCompletedContainerStatusesList().hashCode();
      }
      if (hasLimit()) {
        hash = (37 * hash) + LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + getLimit().hashCode();
      }
      if (getUpdatedNodesCount() > 0) {
        hash = (37 * hash) + UPDATED_NODES_FIELD_NUMBER;
        hash = (53 * hash) + getUpdatedNodesList().hashCode();
      }
      if (hasNumClusterNodes()) {
        hash = (37 * hash) + NUM_CLUSTER_NODES_FIELD_NUMBER;
        hash = (53 * hash) + getNumClusterNodes();
      }
      if (hasPreempt()) {
        hash = (37 * hash) + PREEMPT_FIELD_NUMBER;
        hash = (53 * hash) + getPreempt().hashCode();
      }
      if (getNmTokensCount() > 0) {
        hash = (37 * hash) + NM_TOKENS_FIELD_NUMBER;
        hash = (53 * hash) + getNmTokensList().hashCode();
      }
      if (getIncreasedContainersCount() > 0) {
        hash = (37 * hash) + INCREASED_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getIncreasedContainersList().hashCode();
      }
      if (getDecreasedContainersCount() > 0) {
        hash = (37 * hash) + DECREASED_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getDecreasedContainersList().hashCode();
      }
      if (hasAmRmToken()) {
        hash = (37 * hash) + AM_RM_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getAmRmToken().hashCode();
      }
      if (hasApplicationPriority()) {
        hash = (37 * hash) + APPLICATION_PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationPriority().hashCode();
      }
      if (hasCollectorAddr()) {
        hash = (37 * hash) + COLLECTOR_ADDR_FIELD_NUMBER;
        hash = (53 * hash) + getCollectorAddr().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.AllocateResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.AllocateResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_AllocateResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_AllocateResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getAllocatedContainersFieldBuilder();
          getCompletedContainerStatusesFieldBuilder();
          getLimitFieldBuilder();
          getUpdatedNodesFieldBuilder();
          getPreemptFieldBuilder();
          getNmTokensFieldBuilder();
          getIncreasedContainersFieldBuilder();
          getDecreasedContainersFieldBuilder();
          getAmRmTokenFieldBuilder();
          getApplicationPriorityFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        aMCommand_ = 1;
        bitField0_ = (bitField0_ & ~0x00000001);
        responseId_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (allocatedContainersBuilder_ == null) {
          allocatedContainers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          allocatedContainersBuilder_.clear();
        }
        if (completedContainerStatusesBuilder_ == null) {
          completedContainerStatuses_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          completedContainerStatusesBuilder_.clear();
        }
        if (limitBuilder_ == null) {
          limit_ = null;
        } else {
          limitBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        if (updatedNodesBuilder_ == null) {
          updatedNodes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          updatedNodesBuilder_.clear();
        }
        numClusterNodes_ = 0;
        bitField0_ = (bitField0_ & ~0x00000040);
        if (preemptBuilder_ == null) {
          preempt_ = null;
        } else {
          preemptBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000080);
        if (nmTokensBuilder_ == null) {
          nmTokens_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000100);
        } else {
          nmTokensBuilder_.clear();
        }
        if (increasedContainersBuilder_ == null) {
          increasedContainers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000200);
        } else {
          increasedContainersBuilder_.clear();
        }
        if (decreasedContainersBuilder_ == null) {
          decreasedContainers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000400);
        } else {
          decreasedContainersBuilder_.clear();
        }
        if (amRmTokenBuilder_ == null) {
          amRmToken_ = null;
        } else {
          amRmTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000800);
        if (applicationPriorityBuilder_ == null) {
          applicationPriority_ = null;
        } else {
          applicationPriorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00001000);
        collectorAddr_ = "";
        bitField0_ = (bitField0_ & ~0x00002000);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_AllocateResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.aMCommand_ = aMCommand_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.responseId_ = responseId_;
        if (allocatedContainersBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            allocatedContainers_ = java.util.Collections.unmodifiableList(allocatedContainers_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.allocatedContainers_ = allocatedContainers_;
        } else {
          result.allocatedContainers_ = allocatedContainersBuilder_.build();
        }
        if (completedContainerStatusesBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            completedContainerStatuses_ = java.util.Collections.unmodifiableList(completedContainerStatuses_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.completedContainerStatuses_ = completedContainerStatuses_;
        } else {
          result.completedContainerStatuses_ = completedContainerStatusesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000004;
        }
        if (limitBuilder_ == null) {
          result.limit_ = limit_;
        } else {
          result.limit_ = limitBuilder_.build();
        }
        if (updatedNodesBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            updatedNodes_ = java.util.Collections.unmodifiableList(updatedNodes_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.updatedNodes_ = updatedNodes_;
        } else {
          result.updatedNodes_ = updatedNodesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000008;
        }
        result.numClusterNodes_ = numClusterNodes_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000010;
        }
        if (preemptBuilder_ == null) {
          result.preempt_ = preempt_;
        } else {
          result.preempt_ = preemptBuilder_.build();
        }
        if (nmTokensBuilder_ == null) {
          if (((bitField0_ & 0x00000100) == 0x00000100)) {
            nmTokens_ = java.util.Collections.unmodifiableList(nmTokens_);
            bitField0_ = (bitField0_ & ~0x00000100);
          }
          result.nmTokens_ = nmTokens_;
        } else {
          result.nmTokens_ = nmTokensBuilder_.build();
        }
        if (increasedContainersBuilder_ == null) {
          if (((bitField0_ & 0x00000200) == 0x00000200)) {
            increasedContainers_ = java.util.Collections.unmodifiableList(increasedContainers_);
            bitField0_ = (bitField0_ & ~0x00000200);
          }
          result.increasedContainers_ = increasedContainers_;
        } else {
          result.increasedContainers_ = increasedContainersBuilder_.build();
        }
        if (decreasedContainersBuilder_ == null) {
          if (((bitField0_ & 0x00000400) == 0x00000400)) {
            decreasedContainers_ = java.util.Collections.unmodifiableList(decreasedContainers_);
            bitField0_ = (bitField0_ & ~0x00000400);
          }
          result.decreasedContainers_ = decreasedContainers_;
        } else {
          result.decreasedContainers_ = decreasedContainersBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000800) == 0x00000800)) {
          to_bitField0_ |= 0x00000020;
        }
        if (amRmTokenBuilder_ == null) {
          result.amRmToken_ = amRmToken_;
        } else {
          result.amRmToken_ = amRmTokenBuilder_.build();
        }
        if (((from_bitField0_ & 0x00001000) == 0x00001000)) {
          to_bitField0_ |= 0x00000040;
        }
        if (applicationPriorityBuilder_ == null) {
          result.applicationPriority_ = applicationPriority_;
        } else {
          result.applicationPriority_ = applicationPriorityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00002000) == 0x00002000)) {
          to_bitField0_ |= 0x00000080;
        }
        result.collectorAddr_ = collectorAddr_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.getDefaultInstance()) return this;
        if (other.hasAMCommand()) {
          setAMCommand(other.getAMCommand());
        }
        if (other.hasResponseId()) {
          setResponseId(other.getResponseId());
        }
        if (allocatedContainersBuilder_ == null) {
          if (!other.allocatedContainers_.isEmpty()) {
            if (allocatedContainers_.isEmpty()) {
              allocatedContainers_ = other.allocatedContainers_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureAllocatedContainersIsMutable();
              allocatedContainers_.addAll(other.allocatedContainers_);
            }
            onChanged();
          }
        } else {
          if (!other.allocatedContainers_.isEmpty()) {
            if (allocatedContainersBuilder_.isEmpty()) {
              allocatedContainersBuilder_.dispose();
              allocatedContainersBuilder_ = null;
              allocatedContainers_ = other.allocatedContainers_;
              bitField0_ = (bitField0_ & ~0x00000004);
              allocatedContainersBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getAllocatedContainersFieldBuilder() : null;
            } else {
              allocatedContainersBuilder_.addAllMessages(other.allocatedContainers_);
            }
          }
        }
        if (completedContainerStatusesBuilder_ == null) {
          if (!other.completedContainerStatuses_.isEmpty()) {
            if (completedContainerStatuses_.isEmpty()) {
              completedContainerStatuses_ = other.completedContainerStatuses_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureCompletedContainerStatusesIsMutable();
              completedContainerStatuses_.addAll(other.completedContainerStatuses_);
            }
            onChanged();
          }
        } else {
          if (!other.completedContainerStatuses_.isEmpty()) {
            if (completedContainerStatusesBuilder_.isEmpty()) {
              completedContainerStatusesBuilder_.dispose();
              completedContainerStatusesBuilder_ = null;
              completedContainerStatuses_ = other.completedContainerStatuses_;
              bitField0_ = (bitField0_ & ~0x00000008);
              completedContainerStatusesBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getCompletedContainerStatusesFieldBuilder() : null;
            } else {
              completedContainerStatusesBuilder_.addAllMessages(other.completedContainerStatuses_);
            }
          }
        }
        if (other.hasLimit()) {
          mergeLimit(other.getLimit());
        }
        if (updatedNodesBuilder_ == null) {
          if (!other.updatedNodes_.isEmpty()) {
            if (updatedNodes_.isEmpty()) {
              updatedNodes_ = other.updatedNodes_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureUpdatedNodesIsMutable();
              updatedNodes_.addAll(other.updatedNodes_);
            }
            onChanged();
          }
        } else {
          if (!other.updatedNodes_.isEmpty()) {
            if (updatedNodesBuilder_.isEmpty()) {
              updatedNodesBuilder_.dispose();
              updatedNodesBuilder_ = null;
              updatedNodes_ = other.updatedNodes_;
              bitField0_ = (bitField0_ & ~0x00000020);
              updatedNodesBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getUpdatedNodesFieldBuilder() : null;
            } else {
              updatedNodesBuilder_.addAllMessages(other.updatedNodes_);
            }
          }
        }
        if (other.hasNumClusterNodes()) {
          setNumClusterNodes(other.getNumClusterNodes());
        }
        if (other.hasPreempt()) {
          mergePreempt(other.getPreempt());
        }
        if (nmTokensBuilder_ == null) {
          if (!other.nmTokens_.isEmpty()) {
            if (nmTokens_.isEmpty()) {
              nmTokens_ = other.nmTokens_;
              bitField0_ = (bitField0_ & ~0x00000100);
            } else {
              ensureNmTokensIsMutable();
              nmTokens_.addAll(other.nmTokens_);
            }
            onChanged();
          }
        } else {
          if (!other.nmTokens_.isEmpty()) {
            if (nmTokensBuilder_.isEmpty()) {
              nmTokensBuilder_.dispose();
              nmTokensBuilder_ = null;
              nmTokens_ = other.nmTokens_;
              bitField0_ = (bitField0_ & ~0x00000100);
              nmTokensBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getNmTokensFieldBuilder() : null;
            } else {
              nmTokensBuilder_.addAllMessages(other.nmTokens_);
            }
          }
        }
        if (increasedContainersBuilder_ == null) {
          if (!other.increasedContainers_.isEmpty()) {
            if (increasedContainers_.isEmpty()) {
              increasedContainers_ = other.increasedContainers_;
              bitField0_ = (bitField0_ & ~0x00000200);
            } else {
              ensureIncreasedContainersIsMutable();
              increasedContainers_.addAll(other.increasedContainers_);
            }
            onChanged();
          }
        } else {
          if (!other.increasedContainers_.isEmpty()) {
            if (increasedContainersBuilder_.isEmpty()) {
              increasedContainersBuilder_.dispose();
              increasedContainersBuilder_ = null;
              increasedContainers_ = other.increasedContainers_;
              bitField0_ = (bitField0_ & ~0x00000200);
              increasedContainersBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getIncreasedContainersFieldBuilder() : null;
            } else {
              increasedContainersBuilder_.addAllMessages(other.increasedContainers_);
            }
          }
        }
        if (decreasedContainersBuilder_ == null) {
          if (!other.decreasedContainers_.isEmpty()) {
            if (decreasedContainers_.isEmpty()) {
              decreasedContainers_ = other.decreasedContainers_;
              bitField0_ = (bitField0_ & ~0x00000400);
            } else {
              ensureDecreasedContainersIsMutable();
              decreasedContainers_.addAll(other.decreasedContainers_);
            }
            onChanged();
          }
        } else {
          if (!other.decreasedContainers_.isEmpty()) {
            if (decreasedContainersBuilder_.isEmpty()) {
              decreasedContainersBuilder_.dispose();
              decreasedContainersBuilder_ = null;
              decreasedContainers_ = other.decreasedContainers_;
              bitField0_ = (bitField0_ & ~0x00000400);
              decreasedContainersBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getDecreasedContainersFieldBuilder() : null;
            } else {
              decreasedContainersBuilder_.addAllMessages(other.decreasedContainers_);
            }
          }
        }
        if (other.hasAmRmToken()) {
          mergeAmRmToken(other.getAmRmToken());
        }
        if (other.hasApplicationPriority()) {
          mergeApplicationPriority(other.getApplicationPriority());
        }
        if (other.hasCollectorAddr()) {
          bitField0_ |= 0x00002000;
          collectorAddr_ = other.collectorAddr_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getAllocatedContainersCount(); i++) {
          if (!getAllocatedContainers(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getNmTokensCount(); i++) {
          if (!getNmTokens(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getIncreasedContainersCount(); i++) {
          if (!getIncreasedContainers(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getDecreasedContainersCount(); i++) {
          if (!getDecreasedContainers(i).isInitialized()) {
            return false;
          }
        }
        if (hasAmRmToken()) {
          if (!getAmRmToken().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int aMCommand_ = 1;
      /**
       * <code>optional .hadoop.yarn.AMCommandProto a_m_command = 1;</code>
       */
      public boolean hasAMCommand() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.AMCommandProto a_m_command = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.AMCommandProto getAMCommand() {
        org.spiderdt.hadoop.yarn.proto.YarnProtos.AMCommandProto result = org.spiderdt.hadoop.yarn.proto.YarnProtos.AMCommandProto.valueOf(aMCommand_);
        return result == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.AMCommandProto.AM_RESYNC : result;
      }
      /**
       * <code>optional .hadoop.yarn.AMCommandProto a_m_command = 1;</code>
       */
      public Builder setAMCommand(org.spiderdt.hadoop.yarn.proto.YarnProtos.AMCommandProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        aMCommand_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.AMCommandProto a_m_command = 1;</code>
       */
      public Builder clearAMCommand() {
        bitField0_ = (bitField0_ & ~0x00000001);
        aMCommand_ = 1;
        onChanged();
        return this;
      }

      private int responseId_ ;
      /**
       * <code>optional int32 response_id = 2;</code>
       */
      public boolean hasResponseId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 response_id = 2;</code>
       */
      public int getResponseId() {
        return responseId_;
      }
      /**
       * <code>optional int32 response_id = 2;</code>
       */
      public Builder setResponseId(int value) {
        bitField0_ |= 0x00000002;
        responseId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 response_id = 2;</code>
       */
      public Builder clearResponseId() {
        bitField0_ = (bitField0_ & ~0x00000002);
        responseId_ = 0;
        onChanged();
        return this;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> allocatedContainers_ =
        java.util.Collections.emptyList();
      private void ensureAllocatedContainersIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          allocatedContainers_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto>(allocatedContainers_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> allocatedContainersBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> getAllocatedContainersList() {
        if (allocatedContainersBuilder_ == null) {
          return java.util.Collections.unmodifiableList(allocatedContainers_);
        } else {
          return allocatedContainersBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public int getAllocatedContainersCount() {
        if (allocatedContainersBuilder_ == null) {
          return allocatedContainers_.size();
        } else {
          return allocatedContainersBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto getAllocatedContainers(int index) {
        if (allocatedContainersBuilder_ == null) {
          return allocatedContainers_.get(index);
        } else {
          return allocatedContainersBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public Builder setAllocatedContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (allocatedContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAllocatedContainersIsMutable();
          allocatedContainers_.set(index, value);
          onChanged();
        } else {
          allocatedContainersBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public Builder setAllocatedContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (allocatedContainersBuilder_ == null) {
          ensureAllocatedContainersIsMutable();
          allocatedContainers_.set(index, builderForValue.build());
          onChanged();
        } else {
          allocatedContainersBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public Builder addAllocatedContainers(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (allocatedContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAllocatedContainersIsMutable();
          allocatedContainers_.add(value);
          onChanged();
        } else {
          allocatedContainersBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public Builder addAllocatedContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (allocatedContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAllocatedContainersIsMutable();
          allocatedContainers_.add(index, value);
          onChanged();
        } else {
          allocatedContainersBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public Builder addAllocatedContainers(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (allocatedContainersBuilder_ == null) {
          ensureAllocatedContainersIsMutable();
          allocatedContainers_.add(builderForValue.build());
          onChanged();
        } else {
          allocatedContainersBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public Builder addAllocatedContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (allocatedContainersBuilder_ == null) {
          ensureAllocatedContainersIsMutable();
          allocatedContainers_.add(index, builderForValue.build());
          onChanged();
        } else {
          allocatedContainersBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public Builder addAllAllocatedContainers(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> values) {
        if (allocatedContainersBuilder_ == null) {
          ensureAllocatedContainersIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, allocatedContainers_);
          onChanged();
        } else {
          allocatedContainersBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public Builder clearAllocatedContainers() {
        if (allocatedContainersBuilder_ == null) {
          allocatedContainers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          allocatedContainersBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public Builder removeAllocatedContainers(int index) {
        if (allocatedContainersBuilder_ == null) {
          ensureAllocatedContainersIsMutable();
          allocatedContainers_.remove(index);
          onChanged();
        } else {
          allocatedContainersBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder getAllocatedContainersBuilder(
          int index) {
        return getAllocatedContainersFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getAllocatedContainersOrBuilder(
          int index) {
        if (allocatedContainersBuilder_ == null) {
          return allocatedContainers_.get(index);  } else {
          return allocatedContainersBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
           getAllocatedContainersOrBuilderList() {
        if (allocatedContainersBuilder_ != null) {
          return allocatedContainersBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(allocatedContainers_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder addAllocatedContainersBuilder() {
        return getAllocatedContainersFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder addAllocatedContainersBuilder(
          int index) {
        return getAllocatedContainersFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 3;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder> 
           getAllocatedContainersBuilderList() {
        return getAllocatedContainersFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
          getAllocatedContainersFieldBuilder() {
        if (allocatedContainersBuilder_ == null) {
          allocatedContainersBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder>(
                  allocatedContainers_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          allocatedContainers_ = null;
        }
        return allocatedContainersBuilder_;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> completedContainerStatuses_ =
        java.util.Collections.emptyList();
      private void ensureCompletedContainerStatusesIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          completedContainerStatuses_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto>(completedContainerStatuses_);
          bitField0_ |= 0x00000008;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> completedContainerStatusesBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> getCompletedContainerStatusesList() {
        if (completedContainerStatusesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(completedContainerStatuses_);
        } else {
          return completedContainerStatusesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public int getCompletedContainerStatusesCount() {
        if (completedContainerStatusesBuilder_ == null) {
          return completedContainerStatuses_.size();
        } else {
          return completedContainerStatusesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getCompletedContainerStatuses(int index) {
        if (completedContainerStatusesBuilder_ == null) {
          return completedContainerStatuses_.get(index);
        } else {
          return completedContainerStatusesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public Builder setCompletedContainerStatuses(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto value) {
        if (completedContainerStatusesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCompletedContainerStatusesIsMutable();
          completedContainerStatuses_.set(index, value);
          onChanged();
        } else {
          completedContainerStatusesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public Builder setCompletedContainerStatuses(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder builderForValue) {
        if (completedContainerStatusesBuilder_ == null) {
          ensureCompletedContainerStatusesIsMutable();
          completedContainerStatuses_.set(index, builderForValue.build());
          onChanged();
        } else {
          completedContainerStatusesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public Builder addCompletedContainerStatuses(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto value) {
        if (completedContainerStatusesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCompletedContainerStatusesIsMutable();
          completedContainerStatuses_.add(value);
          onChanged();
        } else {
          completedContainerStatusesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public Builder addCompletedContainerStatuses(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto value) {
        if (completedContainerStatusesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCompletedContainerStatusesIsMutable();
          completedContainerStatuses_.add(index, value);
          onChanged();
        } else {
          completedContainerStatusesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public Builder addCompletedContainerStatuses(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder builderForValue) {
        if (completedContainerStatusesBuilder_ == null) {
          ensureCompletedContainerStatusesIsMutable();
          completedContainerStatuses_.add(builderForValue.build());
          onChanged();
        } else {
          completedContainerStatusesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public Builder addCompletedContainerStatuses(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder builderForValue) {
        if (completedContainerStatusesBuilder_ == null) {
          ensureCompletedContainerStatusesIsMutable();
          completedContainerStatuses_.add(index, builderForValue.build());
          onChanged();
        } else {
          completedContainerStatusesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public Builder addAllCompletedContainerStatuses(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> values) {
        if (completedContainerStatusesBuilder_ == null) {
          ensureCompletedContainerStatusesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, completedContainerStatuses_);
          onChanged();
        } else {
          completedContainerStatusesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public Builder clearCompletedContainerStatuses() {
        if (completedContainerStatusesBuilder_ == null) {
          completedContainerStatuses_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          completedContainerStatusesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public Builder removeCompletedContainerStatuses(int index) {
        if (completedContainerStatusesBuilder_ == null) {
          ensureCompletedContainerStatusesIsMutable();
          completedContainerStatuses_.remove(index);
          onChanged();
        } else {
          completedContainerStatusesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder getCompletedContainerStatusesBuilder(
          int index) {
        return getCompletedContainerStatusesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder getCompletedContainerStatusesOrBuilder(
          int index) {
        if (completedContainerStatusesBuilder_ == null) {
          return completedContainerStatuses_.get(index);  } else {
          return completedContainerStatusesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> 
           getCompletedContainerStatusesOrBuilderList() {
        if (completedContainerStatusesBuilder_ != null) {
          return completedContainerStatusesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(completedContainerStatuses_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder addCompletedContainerStatusesBuilder() {
        return getCompletedContainerStatusesFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder addCompletedContainerStatusesBuilder(
          int index) {
        return getCompletedContainerStatusesFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder> 
           getCompletedContainerStatusesBuilderList() {
        return getCompletedContainerStatusesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> 
          getCompletedContainerStatusesFieldBuilder() {
        if (completedContainerStatusesBuilder_ == null) {
          completedContainerStatusesBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder>(
                  completedContainerStatuses_,
                  ((bitField0_ & 0x00000008) == 0x00000008),
                  getParentForChildren(),
                  isClean());
          completedContainerStatuses_ = null;
        }
        return completedContainerStatusesBuilder_;
      }

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto limit_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> limitBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto limit = 5;</code>
       */
      public boolean hasLimit() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto limit = 5;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto getLimit() {
        if (limitBuilder_ == null) {
          return limit_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : limit_;
        } else {
          return limitBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto limit = 5;</code>
       */
      public Builder setLimit(org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (limitBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          limit_ = value;
          onChanged();
        } else {
          limitBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto limit = 5;</code>
       */
      public Builder setLimit(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (limitBuilder_ == null) {
          limit_ = builderForValue.build();
          onChanged();
        } else {
          limitBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto limit = 5;</code>
       */
      public Builder mergeLimit(org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (limitBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              limit_ != null &&
              limit_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            limit_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(limit_).mergeFrom(value).buildPartial();
          } else {
            limit_ = value;
          }
          onChanged();
        } else {
          limitBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto limit = 5;</code>
       */
      public Builder clearLimit() {
        if (limitBuilder_ == null) {
          limit_ = null;
          onChanged();
        } else {
          limitBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto limit = 5;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getLimitBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getLimitFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto limit = 5;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getLimitOrBuilder() {
        if (limitBuilder_ != null) {
          return limitBuilder_.getMessageOrBuilder();
        } else {
          return limit_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : limit_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto limit = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getLimitFieldBuilder() {
        if (limitBuilder_ == null) {
          limitBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getLimit(),
                  getParentForChildren(),
                  isClean());
          limit_ = null;
        }
        return limitBuilder_;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto> updatedNodes_ =
        java.util.Collections.emptyList();
      private void ensureUpdatedNodesIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          updatedNodes_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto>(updatedNodes_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder> updatedNodesBuilder_;

      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto> getUpdatedNodesList() {
        if (updatedNodesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(updatedNodes_);
        } else {
          return updatedNodesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public int getUpdatedNodesCount() {
        if (updatedNodesBuilder_ == null) {
          return updatedNodes_.size();
        } else {
          return updatedNodesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto getUpdatedNodes(int index) {
        if (updatedNodesBuilder_ == null) {
          return updatedNodes_.get(index);
        } else {
          return updatedNodesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public Builder setUpdatedNodes(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto value) {
        if (updatedNodesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureUpdatedNodesIsMutable();
          updatedNodes_.set(index, value);
          onChanged();
        } else {
          updatedNodesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public Builder setUpdatedNodes(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder builderForValue) {
        if (updatedNodesBuilder_ == null) {
          ensureUpdatedNodesIsMutable();
          updatedNodes_.set(index, builderForValue.build());
          onChanged();
        } else {
          updatedNodesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public Builder addUpdatedNodes(org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto value) {
        if (updatedNodesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureUpdatedNodesIsMutable();
          updatedNodes_.add(value);
          onChanged();
        } else {
          updatedNodesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public Builder addUpdatedNodes(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto value) {
        if (updatedNodesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureUpdatedNodesIsMutable();
          updatedNodes_.add(index, value);
          onChanged();
        } else {
          updatedNodesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public Builder addUpdatedNodes(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder builderForValue) {
        if (updatedNodesBuilder_ == null) {
          ensureUpdatedNodesIsMutable();
          updatedNodes_.add(builderForValue.build());
          onChanged();
        } else {
          updatedNodesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public Builder addUpdatedNodes(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder builderForValue) {
        if (updatedNodesBuilder_ == null) {
          ensureUpdatedNodesIsMutable();
          updatedNodes_.add(index, builderForValue.build());
          onChanged();
        } else {
          updatedNodesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public Builder addAllUpdatedNodes(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto> values) {
        if (updatedNodesBuilder_ == null) {
          ensureUpdatedNodesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, updatedNodes_);
          onChanged();
        } else {
          updatedNodesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public Builder clearUpdatedNodes() {
        if (updatedNodesBuilder_ == null) {
          updatedNodes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          updatedNodesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public Builder removeUpdatedNodes(int index) {
        if (updatedNodesBuilder_ == null) {
          ensureUpdatedNodesIsMutable();
          updatedNodes_.remove(index);
          onChanged();
        } else {
          updatedNodesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder getUpdatedNodesBuilder(
          int index) {
        return getUpdatedNodesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder getUpdatedNodesOrBuilder(
          int index) {
        if (updatedNodesBuilder_ == null) {
          return updatedNodes_.get(index);  } else {
          return updatedNodesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder> 
           getUpdatedNodesOrBuilderList() {
        if (updatedNodesBuilder_ != null) {
          return updatedNodesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(updatedNodes_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder addUpdatedNodesBuilder() {
        return getUpdatedNodesFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder addUpdatedNodesBuilder(
          int index) {
        return getUpdatedNodesFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder> 
           getUpdatedNodesBuilderList() {
        return getUpdatedNodesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder> 
          getUpdatedNodesFieldBuilder() {
        if (updatedNodesBuilder_ == null) {
          updatedNodesBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder>(
                  updatedNodes_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          updatedNodes_ = null;
        }
        return updatedNodesBuilder_;
      }

      private int numClusterNodes_ ;
      /**
       * <code>optional int32 num_cluster_nodes = 7;</code>
       */
      public boolean hasNumClusterNodes() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional int32 num_cluster_nodes = 7;</code>
       */
      public int getNumClusterNodes() {
        return numClusterNodes_;
      }
      /**
       * <code>optional int32 num_cluster_nodes = 7;</code>
       */
      public Builder setNumClusterNodes(int value) {
        bitField0_ |= 0x00000040;
        numClusterNodes_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_cluster_nodes = 7;</code>
       */
      public Builder clearNumClusterNodes() {
        bitField0_ = (bitField0_ & ~0x00000040);
        numClusterNodes_ = 0;
        onChanged();
        return this;
      }

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto preempt_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProtoOrBuilder> preemptBuilder_;
      /**
       * <code>optional .hadoop.yarn.PreemptionMessageProto preempt = 8;</code>
       */
      public boolean hasPreempt() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionMessageProto preempt = 8;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto getPreempt() {
        if (preemptBuilder_ == null) {
          return preempt_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.getDefaultInstance() : preempt_;
        } else {
          return preemptBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionMessageProto preempt = 8;</code>
       */
      public Builder setPreempt(org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto value) {
        if (preemptBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          preempt_ = value;
          onChanged();
        } else {
          preemptBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000080;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionMessageProto preempt = 8;</code>
       */
      public Builder setPreempt(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.Builder builderForValue) {
        if (preemptBuilder_ == null) {
          preempt_ = builderForValue.build();
          onChanged();
        } else {
          preemptBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000080;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionMessageProto preempt = 8;</code>
       */
      public Builder mergePreempt(org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto value) {
        if (preemptBuilder_ == null) {
          if (((bitField0_ & 0x00000080) == 0x00000080) &&
              preempt_ != null &&
              preempt_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.getDefaultInstance()) {
            preempt_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.newBuilder(preempt_).mergeFrom(value).buildPartial();
          } else {
            preempt_ = value;
          }
          onChanged();
        } else {
          preemptBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000080;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionMessageProto preempt = 8;</code>
       */
      public Builder clearPreempt() {
        if (preemptBuilder_ == null) {
          preempt_ = null;
          onChanged();
        } else {
          preemptBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionMessageProto preempt = 8;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.Builder getPreemptBuilder() {
        bitField0_ |= 0x00000080;
        onChanged();
        return getPreemptFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionMessageProto preempt = 8;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProtoOrBuilder getPreemptOrBuilder() {
        if (preemptBuilder_ != null) {
          return preemptBuilder_.getMessageOrBuilder();
        } else {
          return preempt_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.getDefaultInstance() : preempt_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionMessageProto preempt = 8;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProtoOrBuilder> 
          getPreemptFieldBuilder() {
        if (preemptBuilder_ == null) {
          preemptBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.PreemptionMessageProtoOrBuilder>(
                  getPreempt(),
                  getParentForChildren(),
                  isClean());
          preempt_ = null;
        }
        return preemptBuilder_;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto> nmTokens_ =
        java.util.Collections.emptyList();
      private void ensureNmTokensIsMutable() {
        if (!((bitField0_ & 0x00000100) == 0x00000100)) {
          nmTokens_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto>(nmTokens_);
          bitField0_ |= 0x00000100;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder> nmTokensBuilder_;

      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto> getNmTokensList() {
        if (nmTokensBuilder_ == null) {
          return java.util.Collections.unmodifiableList(nmTokens_);
        } else {
          return nmTokensBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public int getNmTokensCount() {
        if (nmTokensBuilder_ == null) {
          return nmTokens_.size();
        } else {
          return nmTokensBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto getNmTokens(int index) {
        if (nmTokensBuilder_ == null) {
          return nmTokens_.get(index);
        } else {
          return nmTokensBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public Builder setNmTokens(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto value) {
        if (nmTokensBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNmTokensIsMutable();
          nmTokens_.set(index, value);
          onChanged();
        } else {
          nmTokensBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public Builder setNmTokens(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder builderForValue) {
        if (nmTokensBuilder_ == null) {
          ensureNmTokensIsMutable();
          nmTokens_.set(index, builderForValue.build());
          onChanged();
        } else {
          nmTokensBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public Builder addNmTokens(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto value) {
        if (nmTokensBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNmTokensIsMutable();
          nmTokens_.add(value);
          onChanged();
        } else {
          nmTokensBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public Builder addNmTokens(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto value) {
        if (nmTokensBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNmTokensIsMutable();
          nmTokens_.add(index, value);
          onChanged();
        } else {
          nmTokensBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public Builder addNmTokens(
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder builderForValue) {
        if (nmTokensBuilder_ == null) {
          ensureNmTokensIsMutable();
          nmTokens_.add(builderForValue.build());
          onChanged();
        } else {
          nmTokensBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public Builder addNmTokens(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder builderForValue) {
        if (nmTokensBuilder_ == null) {
          ensureNmTokensIsMutable();
          nmTokens_.add(index, builderForValue.build());
          onChanged();
        } else {
          nmTokensBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public Builder addAllNmTokens(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto> values) {
        if (nmTokensBuilder_ == null) {
          ensureNmTokensIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, nmTokens_);
          onChanged();
        } else {
          nmTokensBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public Builder clearNmTokens() {
        if (nmTokensBuilder_ == null) {
          nmTokens_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000100);
          onChanged();
        } else {
          nmTokensBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public Builder removeNmTokens(int index) {
        if (nmTokensBuilder_ == null) {
          ensureNmTokensIsMutable();
          nmTokens_.remove(index);
          onChanged();
        } else {
          nmTokensBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder getNmTokensBuilder(
          int index) {
        return getNmTokensFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder getNmTokensOrBuilder(
          int index) {
        if (nmTokensBuilder_ == null) {
          return nmTokens_.get(index);  } else {
          return nmTokensBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder> 
           getNmTokensOrBuilderList() {
        if (nmTokensBuilder_ != null) {
          return nmTokensBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(nmTokens_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder addNmTokensBuilder() {
        return getNmTokensFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder addNmTokensBuilder(
          int index) {
        return getNmTokensFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder> 
           getNmTokensBuilderList() {
        return getNmTokensFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder> 
          getNmTokensFieldBuilder() {
        if (nmTokensBuilder_ == null) {
          nmTokensBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.NMTokenProtoOrBuilder>(
                  nmTokens_,
                  ((bitField0_ & 0x00000100) == 0x00000100),
                  getParentForChildren(),
                  isClean());
          nmTokens_ = null;
        }
        return nmTokensBuilder_;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> increasedContainers_ =
        java.util.Collections.emptyList();
      private void ensureIncreasedContainersIsMutable() {
        if (!((bitField0_ & 0x00000200) == 0x00000200)) {
          increasedContainers_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto>(increasedContainers_);
          bitField0_ |= 0x00000200;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> increasedContainersBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> getIncreasedContainersList() {
        if (increasedContainersBuilder_ == null) {
          return java.util.Collections.unmodifiableList(increasedContainers_);
        } else {
          return increasedContainersBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public int getIncreasedContainersCount() {
        if (increasedContainersBuilder_ == null) {
          return increasedContainers_.size();
        } else {
          return increasedContainersBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto getIncreasedContainers(int index) {
        if (increasedContainersBuilder_ == null) {
          return increasedContainers_.get(index);
        } else {
          return increasedContainersBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public Builder setIncreasedContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (increasedContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureIncreasedContainersIsMutable();
          increasedContainers_.set(index, value);
          onChanged();
        } else {
          increasedContainersBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public Builder setIncreasedContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (increasedContainersBuilder_ == null) {
          ensureIncreasedContainersIsMutable();
          increasedContainers_.set(index, builderForValue.build());
          onChanged();
        } else {
          increasedContainersBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public Builder addIncreasedContainers(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (increasedContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureIncreasedContainersIsMutable();
          increasedContainers_.add(value);
          onChanged();
        } else {
          increasedContainersBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public Builder addIncreasedContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (increasedContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureIncreasedContainersIsMutable();
          increasedContainers_.add(index, value);
          onChanged();
        } else {
          increasedContainersBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public Builder addIncreasedContainers(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (increasedContainersBuilder_ == null) {
          ensureIncreasedContainersIsMutable();
          increasedContainers_.add(builderForValue.build());
          onChanged();
        } else {
          increasedContainersBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public Builder addIncreasedContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (increasedContainersBuilder_ == null) {
          ensureIncreasedContainersIsMutable();
          increasedContainers_.add(index, builderForValue.build());
          onChanged();
        } else {
          increasedContainersBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public Builder addAllIncreasedContainers(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> values) {
        if (increasedContainersBuilder_ == null) {
          ensureIncreasedContainersIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, increasedContainers_);
          onChanged();
        } else {
          increasedContainersBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public Builder clearIncreasedContainers() {
        if (increasedContainersBuilder_ == null) {
          increasedContainers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000200);
          onChanged();
        } else {
          increasedContainersBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public Builder removeIncreasedContainers(int index) {
        if (increasedContainersBuilder_ == null) {
          ensureIncreasedContainersIsMutable();
          increasedContainers_.remove(index);
          onChanged();
        } else {
          increasedContainersBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder getIncreasedContainersBuilder(
          int index) {
        return getIncreasedContainersFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getIncreasedContainersOrBuilder(
          int index) {
        if (increasedContainersBuilder_ == null) {
          return increasedContainers_.get(index);  } else {
          return increasedContainersBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
           getIncreasedContainersOrBuilderList() {
        if (increasedContainersBuilder_ != null) {
          return increasedContainersBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(increasedContainers_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder addIncreasedContainersBuilder() {
        return getIncreasedContainersFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder addIncreasedContainersBuilder(
          int index) {
        return getIncreasedContainersFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 10;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder> 
           getIncreasedContainersBuilderList() {
        return getIncreasedContainersFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
          getIncreasedContainersFieldBuilder() {
        if (increasedContainersBuilder_ == null) {
          increasedContainersBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder>(
                  increasedContainers_,
                  ((bitField0_ & 0x00000200) == 0x00000200),
                  getParentForChildren(),
                  isClean());
          increasedContainers_ = null;
        }
        return increasedContainersBuilder_;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> decreasedContainers_ =
        java.util.Collections.emptyList();
      private void ensureDecreasedContainersIsMutable() {
        if (!((bitField0_ & 0x00000400) == 0x00000400)) {
          decreasedContainers_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto>(decreasedContainers_);
          bitField0_ |= 0x00000400;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> decreasedContainersBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> getDecreasedContainersList() {
        if (decreasedContainersBuilder_ == null) {
          return java.util.Collections.unmodifiableList(decreasedContainers_);
        } else {
          return decreasedContainersBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public int getDecreasedContainersCount() {
        if (decreasedContainersBuilder_ == null) {
          return decreasedContainers_.size();
        } else {
          return decreasedContainersBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto getDecreasedContainers(int index) {
        if (decreasedContainersBuilder_ == null) {
          return decreasedContainers_.get(index);
        } else {
          return decreasedContainersBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public Builder setDecreasedContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (decreasedContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDecreasedContainersIsMutable();
          decreasedContainers_.set(index, value);
          onChanged();
        } else {
          decreasedContainersBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public Builder setDecreasedContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (decreasedContainersBuilder_ == null) {
          ensureDecreasedContainersIsMutable();
          decreasedContainers_.set(index, builderForValue.build());
          onChanged();
        } else {
          decreasedContainersBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public Builder addDecreasedContainers(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (decreasedContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDecreasedContainersIsMutable();
          decreasedContainers_.add(value);
          onChanged();
        } else {
          decreasedContainersBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public Builder addDecreasedContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (decreasedContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDecreasedContainersIsMutable();
          decreasedContainers_.add(index, value);
          onChanged();
        } else {
          decreasedContainersBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public Builder addDecreasedContainers(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (decreasedContainersBuilder_ == null) {
          ensureDecreasedContainersIsMutable();
          decreasedContainers_.add(builderForValue.build());
          onChanged();
        } else {
          decreasedContainersBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public Builder addDecreasedContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (decreasedContainersBuilder_ == null) {
          ensureDecreasedContainersIsMutable();
          decreasedContainers_.add(index, builderForValue.build());
          onChanged();
        } else {
          decreasedContainersBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public Builder addAllDecreasedContainers(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto> values) {
        if (decreasedContainersBuilder_ == null) {
          ensureDecreasedContainersIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, decreasedContainers_);
          onChanged();
        } else {
          decreasedContainersBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public Builder clearDecreasedContainers() {
        if (decreasedContainersBuilder_ == null) {
          decreasedContainers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000400);
          onChanged();
        } else {
          decreasedContainersBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public Builder removeDecreasedContainers(int index) {
        if (decreasedContainersBuilder_ == null) {
          ensureDecreasedContainersIsMutable();
          decreasedContainers_.remove(index);
          onChanged();
        } else {
          decreasedContainersBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder getDecreasedContainersBuilder(
          int index) {
        return getDecreasedContainersFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getDecreasedContainersOrBuilder(
          int index) {
        if (decreasedContainersBuilder_ == null) {
          return decreasedContainers_.get(index);  } else {
          return decreasedContainersBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
           getDecreasedContainersOrBuilderList() {
        if (decreasedContainersBuilder_ != null) {
          return decreasedContainersBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(decreasedContainers_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder addDecreasedContainersBuilder() {
        return getDecreasedContainersFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder addDecreasedContainersBuilder(
          int index) {
        return getDecreasedContainersFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto decreased_containers = 11;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder> 
           getDecreasedContainersBuilderList() {
        return getDecreasedContainersFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
          getDecreasedContainersFieldBuilder() {
        if (decreasedContainersBuilder_ == null) {
          decreasedContainersBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder>(
                  decreasedContainers_,
                  ((bitField0_ & 0x00000400) == 0x00000400),
                  getParentForChildren(),
                  isClean());
          decreasedContainers_ = null;
        }
        return decreasedContainersBuilder_;
      }

      private org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto amRmToken_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> amRmTokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 12;</code>
       */
      public boolean hasAmRmToken() {
        return ((bitField0_ & 0x00000800) == 0x00000800);
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 12;</code>
       */
      public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto getAmRmToken() {
        if (amRmTokenBuilder_ == null) {
          return amRmToken_ == null ? org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : amRmToken_;
        } else {
          return amRmTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 12;</code>
       */
      public Builder setAmRmToken(org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (amRmTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          amRmToken_ = value;
          onChanged();
        } else {
          amRmTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000800;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 12;</code>
       */
      public Builder setAmRmToken(
          org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (amRmTokenBuilder_ == null) {
          amRmToken_ = builderForValue.build();
          onChanged();
        } else {
          amRmTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000800;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 12;</code>
       */
      public Builder mergeAmRmToken(org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (amRmTokenBuilder_ == null) {
          if (((bitField0_ & 0x00000800) == 0x00000800) &&
              amRmToken_ != null &&
              amRmToken_ != org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            amRmToken_ =
              org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(amRmToken_).mergeFrom(value).buildPartial();
          } else {
            amRmToken_ = value;
          }
          onChanged();
        } else {
          amRmTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000800;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 12;</code>
       */
      public Builder clearAmRmToken() {
        if (amRmTokenBuilder_ == null) {
          amRmToken_ = null;
          onChanged();
        } else {
          amRmTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000800);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 12;</code>
       */
      public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder getAmRmTokenBuilder() {
        bitField0_ |= 0x00000800;
        onChanged();
        return getAmRmTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 12;</code>
       */
      public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getAmRmTokenOrBuilder() {
        if (amRmTokenBuilder_ != null) {
          return amRmTokenBuilder_.getMessageOrBuilder();
        } else {
          return amRmToken_ == null ?
              org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : amRmToken_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 12;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getAmRmTokenFieldBuilder() {
        if (amRmTokenBuilder_ == null) {
          amRmTokenBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  getAmRmToken(),
                  getParentForChildren(),
                  isClean());
          amRmToken_ = null;
        }
        return amRmTokenBuilder_;
      }

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto applicationPriority_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> applicationPriorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto application_priority = 13;</code>
       */
      public boolean hasApplicationPriority() {
        return ((bitField0_ & 0x00001000) == 0x00001000);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto application_priority = 13;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto getApplicationPriority() {
        if (applicationPriorityBuilder_ == null) {
          return applicationPriority_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : applicationPriority_;
        } else {
          return applicationPriorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto application_priority = 13;</code>
       */
      public Builder setApplicationPriority(org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (applicationPriorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationPriority_ = value;
          onChanged();
        } else {
          applicationPriorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00001000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto application_priority = 13;</code>
       */
      public Builder setApplicationPriority(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (applicationPriorityBuilder_ == null) {
          applicationPriority_ = builderForValue.build();
          onChanged();
        } else {
          applicationPriorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00001000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto application_priority = 13;</code>
       */
      public Builder mergeApplicationPriority(org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (applicationPriorityBuilder_ == null) {
          if (((bitField0_ & 0x00001000) == 0x00001000) &&
              applicationPriority_ != null &&
              applicationPriority_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            applicationPriority_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(applicationPriority_).mergeFrom(value).buildPartial();
          } else {
            applicationPriority_ = value;
          }
          onChanged();
        } else {
          applicationPriorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00001000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto application_priority = 13;</code>
       */
      public Builder clearApplicationPriority() {
        if (applicationPriorityBuilder_ == null) {
          applicationPriority_ = null;
          onChanged();
        } else {
          applicationPriorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00001000);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto application_priority = 13;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getApplicationPriorityBuilder() {
        bitField0_ |= 0x00001000;
        onChanged();
        return getApplicationPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto application_priority = 13;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getApplicationPriorityOrBuilder() {
        if (applicationPriorityBuilder_ != null) {
          return applicationPriorityBuilder_.getMessageOrBuilder();
        } else {
          return applicationPriority_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : applicationPriority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto application_priority = 13;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getApplicationPriorityFieldBuilder() {
        if (applicationPriorityBuilder_ == null) {
          applicationPriorityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  getApplicationPriority(),
                  getParentForChildren(),
                  isClean());
          applicationPriority_ = null;
        }
        return applicationPriorityBuilder_;
      }

      private java.lang.Object collectorAddr_ = "";
      /**
       * <code>optional string collector_addr = 14;</code>
       */
      public boolean hasCollectorAddr() {
        return ((bitField0_ & 0x00002000) == 0x00002000);
      }
      /**
       * <code>optional string collector_addr = 14;</code>
       */
      public java.lang.String getCollectorAddr() {
        java.lang.Object ref = collectorAddr_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            collectorAddr_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string collector_addr = 14;</code>
       */
      public com.google.protobuf.ByteString
          getCollectorAddrBytes() {
        java.lang.Object ref = collectorAddr_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          collectorAddr_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string collector_addr = 14;</code>
       */
      public Builder setCollectorAddr(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00002000;
        collectorAddr_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string collector_addr = 14;</code>
       */
      public Builder clearCollectorAddr() {
        bitField0_ = (bitField0_ & ~0x00002000);
        collectorAddr_ = getDefaultInstance().getCollectorAddr();
        onChanged();
        return this;
      }
      /**
       * <code>optional string collector_addr = 14;</code>
       */
      public Builder setCollectorAddrBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00002000;
        collectorAddr_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.AllocateResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.AllocateResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<AllocateResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<AllocateResponseProto>() {
      public AllocateResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new AllocateResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<AllocateResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<AllocateResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetNewApplicationRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetNewApplicationRequestProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetNewApplicationRequestProto}
   */
  public  static final class GetNewApplicationRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetNewApplicationRequestProto)
      GetNewApplicationRequestProtoOrBuilder {
    // Use GetNewApplicationRequestProto.newBuilder() to construct.
    private GetNewApplicationRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetNewApplicationRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetNewApplicationRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewApplicationRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewApplicationRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetNewApplicationRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetNewApplicationRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewApplicationRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewApplicationRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewApplicationRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetNewApplicationRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetNewApplicationRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetNewApplicationRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetNewApplicationRequestProto>() {
      public GetNewApplicationRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetNewApplicationRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetNewApplicationRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetNewApplicationRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetNewApplicationResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetNewApplicationResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();

    /**
     * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 2;</code>
     */
    boolean hasMaximumCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto getMaximumCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMaximumCapabilityOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetNewApplicationResponseProto}
   */
  public  static final class GetNewApplicationResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetNewApplicationResponseProto)
      GetNewApplicationResponseProtoOrBuilder {
    // Use GetNewApplicationResponseProto.newBuilder() to construct.
    private GetNewApplicationResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetNewApplicationResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetNewApplicationResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = maximumCapability_.toBuilder();
              }
              maximumCapability_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(maximumCapability_);
                maximumCapability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewApplicationResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewApplicationResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATION_ID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }

    public static final int MAXIMUMCAPABILITY_FIELD_NUMBER = 2;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto maximumCapability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 2;</code>
     */
    public boolean hasMaximumCapability() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto getMaximumCapability() {
      return maximumCapability_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : maximumCapability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMaximumCapabilityOrBuilder() {
      return maximumCapability_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : maximumCapability_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getMaximumCapability());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getMaximumCapability());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasMaximumCapability() == other.hasMaximumCapability());
      if (hasMaximumCapability()) {
        result = result && getMaximumCapability()
            .equals(other.getMaximumCapability());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasMaximumCapability()) {
        hash = (37 * hash) + MAXIMUMCAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getMaximumCapability().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetNewApplicationResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetNewApplicationResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewApplicationResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewApplicationResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
          getMaximumCapabilityFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (maximumCapabilityBuilder_ == null) {
          maximumCapability_ = null;
        } else {
          maximumCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewApplicationResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (maximumCapabilityBuilder_ == null) {
          result.maximumCapability_ = maximumCapability_;
        } else {
          result.maximumCapability_ = maximumCapabilityBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasMaximumCapability()) {
          mergeMaximumCapability(other.getMaximumCapability());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder mergeApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != null &&
              applicationId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  getApplicationId(),
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto maximumCapability_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> maximumCapabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 2;</code>
       */
      public boolean hasMaximumCapability() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto getMaximumCapability() {
        if (maximumCapabilityBuilder_ == null) {
          return maximumCapability_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : maximumCapability_;
        } else {
          return maximumCapabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 2;</code>
       */
      public Builder setMaximumCapability(org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (maximumCapabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          maximumCapability_ = value;
          onChanged();
        } else {
          maximumCapabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 2;</code>
       */
      public Builder setMaximumCapability(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (maximumCapabilityBuilder_ == null) {
          maximumCapability_ = builderForValue.build();
          onChanged();
        } else {
          maximumCapabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 2;</code>
       */
      public Builder mergeMaximumCapability(org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (maximumCapabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              maximumCapability_ != null &&
              maximumCapability_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            maximumCapability_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(maximumCapability_).mergeFrom(value).buildPartial();
          } else {
            maximumCapability_ = value;
          }
          onChanged();
        } else {
          maximumCapabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 2;</code>
       */
      public Builder clearMaximumCapability() {
        if (maximumCapabilityBuilder_ == null) {
          maximumCapability_ = null;
          onChanged();
        } else {
          maximumCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getMaximumCapabilityBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getMaximumCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMaximumCapabilityOrBuilder() {
        if (maximumCapabilityBuilder_ != null) {
          return maximumCapabilityBuilder_.getMessageOrBuilder();
        } else {
          return maximumCapability_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : maximumCapability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto maximumCapability = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getMaximumCapabilityFieldBuilder() {
        if (maximumCapabilityBuilder_ == null) {
          maximumCapabilityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getMaximumCapability(),
                  getParentForChildren(),
                  isClean());
          maximumCapability_ = null;
        }
        return maximumCapabilityBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetNewApplicationResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetNewApplicationResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetNewApplicationResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetNewApplicationResponseProto>() {
      public GetNewApplicationResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetNewApplicationResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetNewApplicationResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetNewApplicationResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetApplicationReportRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetApplicationReportRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetApplicationReportRequestProto}
   */
  public  static final class GetApplicationReportRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetApplicationReportRequestProto)
      GetApplicationReportRequestProtoOrBuilder {
    // Use GetApplicationReportRequestProto.newBuilder() to construct.
    private GetApplicationReportRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetApplicationReportRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetApplicationReportRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationReportRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationReportRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATION_ID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationId());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationId());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetApplicationReportRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetApplicationReportRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationReportRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationReportRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationReportRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder mergeApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != null &&
              applicationId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  getApplicationId(),
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetApplicationReportRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetApplicationReportRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetApplicationReportRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetApplicationReportRequestProto>() {
      public GetApplicationReportRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetApplicationReportRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetApplicationReportRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetApplicationReportRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetApplicationReportResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetApplicationReportResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationReportProto application_report = 1;</code>
     */
    boolean hasApplicationReport();
    /**
     * <code>optional .hadoop.yarn.ApplicationReportProto application_report = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplicationReport();
    /**
     * <code>optional .hadoop.yarn.ApplicationReportProto application_report = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationReportOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetApplicationReportResponseProto}
   */
  public  static final class GetApplicationReportResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetApplicationReportResponseProto)
      GetApplicationReportResponseProtoOrBuilder {
    // Use GetApplicationReportResponseProto.newBuilder() to construct.
    private GetApplicationReportResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetApplicationReportResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetApplicationReportResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationReport_.toBuilder();
              }
              applicationReport_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationReport_);
                applicationReport_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationReportResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationReportResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATION_REPORT_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto applicationReport_;
    /**
     * <code>optional .hadoop.yarn.ApplicationReportProto application_report = 1;</code>
     */
    public boolean hasApplicationReport() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationReportProto application_report = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplicationReport() {
      return applicationReport_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance() : applicationReport_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationReportProto application_report = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationReportOrBuilder() {
      return applicationReport_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance() : applicationReport_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasApplicationReport()) {
        if (!getApplicationReport().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationReport());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationReport());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto) obj;

      boolean result = true;
      result = result && (hasApplicationReport() == other.hasApplicationReport());
      if (hasApplicationReport()) {
        result = result && getApplicationReport()
            .equals(other.getApplicationReport());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationReport()) {
        hash = (37 * hash) + APPLICATION_REPORT_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationReport().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetApplicationReportResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetApplicationReportResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationReportResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationReportResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationReportFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationReportBuilder_ == null) {
          applicationReport_ = null;
        } else {
          applicationReportBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationReportResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationReportBuilder_ == null) {
          result.applicationReport_ = applicationReport_;
        } else {
          result.applicationReport_ = applicationReportBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto.getDefaultInstance()) return this;
        if (other.hasApplicationReport()) {
          mergeApplicationReport(other.getApplicationReport());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (hasApplicationReport()) {
          if (!getApplicationReport().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto applicationReport_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> applicationReportBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationReportProto application_report = 1;</code>
       */
      public boolean hasApplicationReport() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationReportProto application_report = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplicationReport() {
        if (applicationReportBuilder_ == null) {
          return applicationReport_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance() : applicationReport_;
        } else {
          return applicationReportBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationReportProto application_report = 1;</code>
       */
      public Builder setApplicationReport(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationReportBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationReport_ = value;
          onChanged();
        } else {
          applicationReportBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationReportProto application_report = 1;</code>
       */
      public Builder setApplicationReport(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationReportBuilder_ == null) {
          applicationReport_ = builderForValue.build();
          onChanged();
        } else {
          applicationReportBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationReportProto application_report = 1;</code>
       */
      public Builder mergeApplicationReport(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationReportBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationReport_ != null &&
              applicationReport_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance()) {
            applicationReport_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.newBuilder(applicationReport_).mergeFrom(value).buildPartial();
          } else {
            applicationReport_ = value;
          }
          onChanged();
        } else {
          applicationReportBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationReportProto application_report = 1;</code>
       */
      public Builder clearApplicationReport() {
        if (applicationReportBuilder_ == null) {
          applicationReport_ = null;
          onChanged();
        } else {
          applicationReportBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationReportProto application_report = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder getApplicationReportBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationReportFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationReportProto application_report = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationReportOrBuilder() {
        if (applicationReportBuilder_ != null) {
          return applicationReportBuilder_.getMessageOrBuilder();
        } else {
          return applicationReport_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance() : applicationReport_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationReportProto application_report = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
          getApplicationReportFieldBuilder() {
        if (applicationReportBuilder_ == null) {
          applicationReportBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder>(
                  getApplicationReport(),
                  getParentForChildren(),
                  isClean());
          applicationReport_ = null;
        }
        return applicationReportBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetApplicationReportResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetApplicationReportResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetApplicationReportResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetApplicationReportResponseProto>() {
      public GetApplicationReportResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetApplicationReportResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetApplicationReportResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetApplicationReportResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SubmitApplicationRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.SubmitApplicationRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;</code>
     */
    boolean hasApplicationSubmissionContext();
    /**
     * <code>optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto getApplicationSubmissionContext();
    /**
     * <code>optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder getApplicationSubmissionContextOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.SubmitApplicationRequestProto}
   */
  public  static final class SubmitApplicationRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.SubmitApplicationRequestProto)
      SubmitApplicationRequestProtoOrBuilder {
    // Use SubmitApplicationRequestProto.newBuilder() to construct.
    private SubmitApplicationRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SubmitApplicationRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SubmitApplicationRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationSubmissionContext_.toBuilder();
              }
              applicationSubmissionContext_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationSubmissionContext_);
                applicationSubmissionContext_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SubmitApplicationRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SubmitApplicationRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATION_SUBMISSION_CONTEXT_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto applicationSubmissionContext_;
    /**
     * <code>optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;</code>
     */
    public boolean hasApplicationSubmissionContext() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto getApplicationSubmissionContext() {
      return applicationSubmissionContext_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance() : applicationSubmissionContext_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder getApplicationSubmissionContextOrBuilder() {
      return applicationSubmissionContext_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance() : applicationSubmissionContext_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationSubmissionContext());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationSubmissionContext());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto) obj;

      boolean result = true;
      result = result && (hasApplicationSubmissionContext() == other.hasApplicationSubmissionContext());
      if (hasApplicationSubmissionContext()) {
        result = result && getApplicationSubmissionContext()
            .equals(other.getApplicationSubmissionContext());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationSubmissionContext()) {
        hash = (37 * hash) + APPLICATION_SUBMISSION_CONTEXT_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationSubmissionContext().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.SubmitApplicationRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.SubmitApplicationRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SubmitApplicationRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SubmitApplicationRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationSubmissionContextFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationSubmissionContextBuilder_ == null) {
          applicationSubmissionContext_ = null;
        } else {
          applicationSubmissionContextBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SubmitApplicationRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationSubmissionContextBuilder_ == null) {
          result.applicationSubmissionContext_ = applicationSubmissionContext_;
        } else {
          result.applicationSubmissionContext_ = applicationSubmissionContextBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationSubmissionContext()) {
          mergeApplicationSubmissionContext(other.getApplicationSubmissionContext());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto applicationSubmissionContext_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder> applicationSubmissionContextBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;</code>
       */
      public boolean hasApplicationSubmissionContext() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto getApplicationSubmissionContext() {
        if (applicationSubmissionContextBuilder_ == null) {
          return applicationSubmissionContext_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance() : applicationSubmissionContext_;
        } else {
          return applicationSubmissionContextBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;</code>
       */
      public Builder setApplicationSubmissionContext(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto value) {
        if (applicationSubmissionContextBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationSubmissionContext_ = value;
          onChanged();
        } else {
          applicationSubmissionContextBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;</code>
       */
      public Builder setApplicationSubmissionContext(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder builderForValue) {
        if (applicationSubmissionContextBuilder_ == null) {
          applicationSubmissionContext_ = builderForValue.build();
          onChanged();
        } else {
          applicationSubmissionContextBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;</code>
       */
      public Builder mergeApplicationSubmissionContext(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto value) {
        if (applicationSubmissionContextBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationSubmissionContext_ != null &&
              applicationSubmissionContext_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance()) {
            applicationSubmissionContext_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.newBuilder(applicationSubmissionContext_).mergeFrom(value).buildPartial();
          } else {
            applicationSubmissionContext_ = value;
          }
          onChanged();
        } else {
          applicationSubmissionContextBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;</code>
       */
      public Builder clearApplicationSubmissionContext() {
        if (applicationSubmissionContextBuilder_ == null) {
          applicationSubmissionContext_ = null;
          onChanged();
        } else {
          applicationSubmissionContextBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder getApplicationSubmissionContextBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationSubmissionContextFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder getApplicationSubmissionContextOrBuilder() {
        if (applicationSubmissionContextBuilder_ != null) {
          return applicationSubmissionContextBuilder_.getMessageOrBuilder();
        } else {
          return applicationSubmissionContext_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance() : applicationSubmissionContext_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder> 
          getApplicationSubmissionContextFieldBuilder() {
        if (applicationSubmissionContextBuilder_ == null) {
          applicationSubmissionContextBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder>(
                  getApplicationSubmissionContext(),
                  getParentForChildren(),
                  isClean());
          applicationSubmissionContext_ = null;
        }
        return applicationSubmissionContextBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.SubmitApplicationRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.SubmitApplicationRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<SubmitApplicationRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<SubmitApplicationRequestProto>() {
      public SubmitApplicationRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new SubmitApplicationRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<SubmitApplicationRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<SubmitApplicationRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SubmitApplicationResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.SubmitApplicationResponseProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.SubmitApplicationResponseProto}
   */
  public  static final class SubmitApplicationResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.SubmitApplicationResponseProto)
      SubmitApplicationResponseProtoOrBuilder {
    // Use SubmitApplicationResponseProto.newBuilder() to construct.
    private SubmitApplicationResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SubmitApplicationResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SubmitApplicationResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SubmitApplicationResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SubmitApplicationResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.SubmitApplicationResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.SubmitApplicationResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SubmitApplicationResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SubmitApplicationResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SubmitApplicationResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.SubmitApplicationResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.SubmitApplicationResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<SubmitApplicationResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<SubmitApplicationResponseProto>() {
      public SubmitApplicationResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new SubmitApplicationResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<SubmitApplicationResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<SubmitApplicationResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FailApplicationAttemptRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.FailApplicationAttemptRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    boolean hasApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.FailApplicationAttemptRequestProto}
   */
  public  static final class FailApplicationAttemptRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.FailApplicationAttemptRequestProto)
      FailApplicationAttemptRequestProtoOrBuilder {
    // Use FailApplicationAttemptRequestProto.newBuilder() to construct.
    private FailApplicationAttemptRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FailApplicationAttemptRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private FailApplicationAttemptRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationAttemptId_.toBuilder();
              }
              applicationAttemptId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationAttemptId_);
                applicationAttemptId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FailApplicationAttemptRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FailApplicationAttemptRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATION_ATTEMPT_ID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    public boolean hasApplicationAttemptId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
      return applicationAttemptId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
      return applicationAttemptId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationAttemptId());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationAttemptId());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto) obj;

      boolean result = true;
      result = result && (hasApplicationAttemptId() == other.hasApplicationAttemptId());
      if (hasApplicationAttemptId()) {
        result = result && getApplicationAttemptId()
            .equals(other.getApplicationAttemptId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationAttemptId()) {
        hash = (37 * hash) + APPLICATION_ATTEMPT_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationAttemptId().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.FailApplicationAttemptRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.FailApplicationAttemptRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FailApplicationAttemptRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FailApplicationAttemptRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationAttemptIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = null;
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FailApplicationAttemptRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationAttemptIdBuilder_ == null) {
          result.applicationAttemptId_ = applicationAttemptId_;
        } else {
          result.applicationAttemptId_ = applicationAttemptIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationAttemptId()) {
          mergeApplicationAttemptId(other.getApplicationAttemptId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> applicationAttemptIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public boolean hasApplicationAttemptId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          return applicationAttemptId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
        } else {
          return applicationAttemptIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder setApplicationAttemptId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationAttemptId_ = value;
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder setApplicationAttemptId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder builderForValue) {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = builderForValue.build();
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder mergeApplicationAttemptId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationAttemptId_ != null &&
              applicationAttemptId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) {
            applicationAttemptId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder(applicationAttemptId_).mergeFrom(value).buildPartial();
          } else {
            applicationAttemptId_ = value;
          }
          onChanged();
        } else {
          applicationAttemptIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder clearApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = null;
          onChanged();
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder getApplicationAttemptIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationAttemptIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
        if (applicationAttemptIdBuilder_ != null) {
          return applicationAttemptIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationAttemptId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> 
          getApplicationAttemptIdFieldBuilder() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder>(
                  getApplicationAttemptId(),
                  getParentForChildren(),
                  isClean());
          applicationAttemptId_ = null;
        }
        return applicationAttemptIdBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.FailApplicationAttemptRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.FailApplicationAttemptRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<FailApplicationAttemptRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<FailApplicationAttemptRequestProto>() {
      public FailApplicationAttemptRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new FailApplicationAttemptRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<FailApplicationAttemptRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<FailApplicationAttemptRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FailApplicationAttemptResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.FailApplicationAttemptResponseProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.FailApplicationAttemptResponseProto}
   */
  public  static final class FailApplicationAttemptResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.FailApplicationAttemptResponseProto)
      FailApplicationAttemptResponseProtoOrBuilder {
    // Use FailApplicationAttemptResponseProto.newBuilder() to construct.
    private FailApplicationAttemptResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FailApplicationAttemptResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private FailApplicationAttemptResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FailApplicationAttemptResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FailApplicationAttemptResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.FailApplicationAttemptResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.FailApplicationAttemptResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FailApplicationAttemptResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FailApplicationAttemptResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_FailApplicationAttemptResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.FailApplicationAttemptResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.FailApplicationAttemptResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<FailApplicationAttemptResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<FailApplicationAttemptResponseProto>() {
      public FailApplicationAttemptResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new FailApplicationAttemptResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<FailApplicationAttemptResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<FailApplicationAttemptResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.FailApplicationAttemptResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface KillApplicationRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.KillApplicationRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.KillApplicationRequestProto}
   */
  public  static final class KillApplicationRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.KillApplicationRequestProto)
      KillApplicationRequestProtoOrBuilder {
    // Use KillApplicationRequestProto.newBuilder() to construct.
    private KillApplicationRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private KillApplicationRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private KillApplicationRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_KillApplicationRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_KillApplicationRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATION_ID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationId());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationId());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.KillApplicationRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.KillApplicationRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_KillApplicationRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_KillApplicationRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_KillApplicationRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder mergeApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != null &&
              applicationId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  getApplicationId(),
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.KillApplicationRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.KillApplicationRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<KillApplicationRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<KillApplicationRequestProto>() {
      public KillApplicationRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new KillApplicationRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<KillApplicationRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<KillApplicationRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface KillApplicationResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.KillApplicationResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional bool is_kill_completed = 1 [default = false];</code>
     */
    boolean hasIsKillCompleted();
    /**
     * <code>optional bool is_kill_completed = 1 [default = false];</code>
     */
    boolean getIsKillCompleted();
  }
  /**
   * Protobuf type {@code hadoop.yarn.KillApplicationResponseProto}
   */
  public  static final class KillApplicationResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.KillApplicationResponseProto)
      KillApplicationResponseProtoOrBuilder {
    // Use KillApplicationResponseProto.newBuilder() to construct.
    private KillApplicationResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private KillApplicationResponseProto() {
      isKillCompleted_ = false;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private KillApplicationResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              isKillCompleted_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_KillApplicationResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_KillApplicationResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto.Builder.class);
    }

    private int bitField0_;
    public static final int IS_KILL_COMPLETED_FIELD_NUMBER = 1;
    private boolean isKillCompleted_;
    /**
     * <code>optional bool is_kill_completed = 1 [default = false];</code>
     */
    public boolean hasIsKillCompleted() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bool is_kill_completed = 1 [default = false];</code>
     */
    public boolean getIsKillCompleted() {
      return isKillCompleted_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBool(1, isKillCompleted_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, isKillCompleted_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto) obj;

      boolean result = true;
      result = result && (hasIsKillCompleted() == other.hasIsKillCompleted());
      if (hasIsKillCompleted()) {
        result = result && (getIsKillCompleted()
            == other.getIsKillCompleted());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasIsKillCompleted()) {
        hash = (37 * hash) + IS_KILL_COMPLETED_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getIsKillCompleted());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.KillApplicationResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.KillApplicationResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_KillApplicationResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_KillApplicationResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        isKillCompleted_ = false;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_KillApplicationResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.isKillCompleted_ = isKillCompleted_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto.getDefaultInstance()) return this;
        if (other.hasIsKillCompleted()) {
          setIsKillCompleted(other.getIsKillCompleted());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private boolean isKillCompleted_ ;
      /**
       * <code>optional bool is_kill_completed = 1 [default = false];</code>
       */
      public boolean hasIsKillCompleted() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional bool is_kill_completed = 1 [default = false];</code>
       */
      public boolean getIsKillCompleted() {
        return isKillCompleted_;
      }
      /**
       * <code>optional bool is_kill_completed = 1 [default = false];</code>
       */
      public Builder setIsKillCompleted(boolean value) {
        bitField0_ |= 0x00000001;
        isKillCompleted_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool is_kill_completed = 1 [default = false];</code>
       */
      public Builder clearIsKillCompleted() {
        bitField0_ = (bitField0_ & ~0x00000001);
        isKillCompleted_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.KillApplicationResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.KillApplicationResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<KillApplicationResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<KillApplicationResponseProto>() {
      public KillApplicationResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new KillApplicationResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<KillApplicationResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<KillApplicationResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetClusterMetricsRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetClusterMetricsRequestProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetClusterMetricsRequestProto}
   */
  public  static final class GetClusterMetricsRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetClusterMetricsRequestProto)
      GetClusterMetricsRequestProtoOrBuilder {
    // Use GetClusterMetricsRequestProto.newBuilder() to construct.
    private GetClusterMetricsRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetClusterMetricsRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetClusterMetricsRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterMetricsRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterMetricsRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetClusterMetricsRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetClusterMetricsRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterMetricsRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterMetricsRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterMetricsRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetClusterMetricsRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetClusterMetricsRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetClusterMetricsRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetClusterMetricsRequestProto>() {
      public GetClusterMetricsRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetClusterMetricsRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetClusterMetricsRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetClusterMetricsRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetClusterMetricsResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetClusterMetricsResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;</code>
     */
    boolean hasClusterMetrics();
    /**
     * <code>optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto getClusterMetrics();
    /**
     * <code>optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProtoOrBuilder getClusterMetricsOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetClusterMetricsResponseProto}
   */
  public  static final class GetClusterMetricsResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetClusterMetricsResponseProto)
      GetClusterMetricsResponseProtoOrBuilder {
    // Use GetClusterMetricsResponseProto.newBuilder() to construct.
    private GetClusterMetricsResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetClusterMetricsResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetClusterMetricsResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = clusterMetrics_.toBuilder();
              }
              clusterMetrics_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(clusterMetrics_);
                clusterMetrics_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterMetricsResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterMetricsResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto.Builder.class);
    }

    private int bitField0_;
    public static final int CLUSTER_METRICS_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto clusterMetrics_;
    /**
     * <code>optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;</code>
     */
    public boolean hasClusterMetrics() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto getClusterMetrics() {
      return clusterMetrics_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance() : clusterMetrics_;
    }
    /**
     * <code>optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProtoOrBuilder getClusterMetricsOrBuilder() {
      return clusterMetrics_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance() : clusterMetrics_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getClusterMetrics());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getClusterMetrics());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto) obj;

      boolean result = true;
      result = result && (hasClusterMetrics() == other.hasClusterMetrics());
      if (hasClusterMetrics()) {
        result = result && getClusterMetrics()
            .equals(other.getClusterMetrics());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasClusterMetrics()) {
        hash = (37 * hash) + CLUSTER_METRICS_FIELD_NUMBER;
        hash = (53 * hash) + getClusterMetrics().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetClusterMetricsResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetClusterMetricsResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterMetricsResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterMetricsResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getClusterMetricsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (clusterMetricsBuilder_ == null) {
          clusterMetrics_ = null;
        } else {
          clusterMetricsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterMetricsResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (clusterMetricsBuilder_ == null) {
          result.clusterMetrics_ = clusterMetrics_;
        } else {
          result.clusterMetrics_ = clusterMetricsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto.getDefaultInstance()) return this;
        if (other.hasClusterMetrics()) {
          mergeClusterMetrics(other.getClusterMetrics());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto clusterMetrics_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProtoOrBuilder> clusterMetricsBuilder_;
      /**
       * <code>optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;</code>
       */
      public boolean hasClusterMetrics() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto getClusterMetrics() {
        if (clusterMetricsBuilder_ == null) {
          return clusterMetrics_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance() : clusterMetrics_;
        } else {
          return clusterMetricsBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;</code>
       */
      public Builder setClusterMetrics(org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto value) {
        if (clusterMetricsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          clusterMetrics_ = value;
          onChanged();
        } else {
          clusterMetricsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;</code>
       */
      public Builder setClusterMetrics(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder builderForValue) {
        if (clusterMetricsBuilder_ == null) {
          clusterMetrics_ = builderForValue.build();
          onChanged();
        } else {
          clusterMetricsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;</code>
       */
      public Builder mergeClusterMetrics(org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto value) {
        if (clusterMetricsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              clusterMetrics_ != null &&
              clusterMetrics_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance()) {
            clusterMetrics_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.newBuilder(clusterMetrics_).mergeFrom(value).buildPartial();
          } else {
            clusterMetrics_ = value;
          }
          onChanged();
        } else {
          clusterMetricsBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;</code>
       */
      public Builder clearClusterMetrics() {
        if (clusterMetricsBuilder_ == null) {
          clusterMetrics_ = null;
          onChanged();
        } else {
          clusterMetricsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder getClusterMetricsBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getClusterMetricsFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProtoOrBuilder getClusterMetricsOrBuilder() {
        if (clusterMetricsBuilder_ != null) {
          return clusterMetricsBuilder_.getMessageOrBuilder();
        } else {
          return clusterMetrics_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance() : clusterMetrics_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProtoOrBuilder> 
          getClusterMetricsFieldBuilder() {
        if (clusterMetricsBuilder_ == null) {
          clusterMetricsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProtoOrBuilder>(
                  getClusterMetrics(),
                  getParentForChildren(),
                  isClean());
          clusterMetrics_ = null;
        }
        return clusterMetricsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetClusterMetricsResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetClusterMetricsResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetClusterMetricsResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetClusterMetricsResponseProto>() {
      public GetClusterMetricsResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetClusterMetricsResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetClusterMetricsResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetClusterMetricsResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MoveApplicationAcrossQueuesRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.MoveApplicationAcrossQueuesRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>required .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>required .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();

    /**
     * <code>required string target_queue = 2;</code>
     */
    boolean hasTargetQueue();
    /**
     * <code>required string target_queue = 2;</code>
     */
    java.lang.String getTargetQueue();
    /**
     * <code>required string target_queue = 2;</code>
     */
    com.google.protobuf.ByteString
        getTargetQueueBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.MoveApplicationAcrossQueuesRequestProto}
   */
  public  static final class MoveApplicationAcrossQueuesRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.MoveApplicationAcrossQueuesRequestProto)
      MoveApplicationAcrossQueuesRequestProtoOrBuilder {
    // Use MoveApplicationAcrossQueuesRequestProto.newBuilder() to construct.
    private MoveApplicationAcrossQueuesRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MoveApplicationAcrossQueuesRequestProto() {
      targetQueue_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private MoveApplicationAcrossQueuesRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              targetQueue_ = bs;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_MoveApplicationAcrossQueuesRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_MoveApplicationAcrossQueuesRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATION_ID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>required .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }
    /**
     * <code>required .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }

    public static final int TARGET_QUEUE_FIELD_NUMBER = 2;
    private volatile java.lang.Object targetQueue_;
    /**
     * <code>required string target_queue = 2;</code>
     */
    public boolean hasTargetQueue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required string target_queue = 2;</code>
     */
    public java.lang.String getTargetQueue() {
      java.lang.Object ref = targetQueue_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          targetQueue_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string target_queue = 2;</code>
     */
    public com.google.protobuf.ByteString
        getTargetQueueBytes() {
      java.lang.Object ref = targetQueue_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        targetQueue_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasApplicationId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTargetQueue()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, targetQueue_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, targetQueue_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasTargetQueue() == other.hasTargetQueue());
      if (hasTargetQueue()) {
        result = result && getTargetQueue()
            .equals(other.getTargetQueue());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasTargetQueue()) {
        hash = (37 * hash) + TARGET_QUEUE_FIELD_NUMBER;
        hash = (53 * hash) + getTargetQueue().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.MoveApplicationAcrossQueuesRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.MoveApplicationAcrossQueuesRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_MoveApplicationAcrossQueuesRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_MoveApplicationAcrossQueuesRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        targetQueue_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_MoveApplicationAcrossQueuesRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.targetQueue_ = targetQueue_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasTargetQueue()) {
          bitField0_ |= 0x00000002;
          targetQueue_ = other.targetQueue_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasApplicationId()) {
          return false;
        }
        if (!hasTargetQueue()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder mergeApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != null &&
              applicationId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        }
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  getApplicationId(),
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }

      private java.lang.Object targetQueue_ = "";
      /**
       * <code>required string target_queue = 2;</code>
       */
      public boolean hasTargetQueue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required string target_queue = 2;</code>
       */
      public java.lang.String getTargetQueue() {
        java.lang.Object ref = targetQueue_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            targetQueue_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string target_queue = 2;</code>
       */
      public com.google.protobuf.ByteString
          getTargetQueueBytes() {
        java.lang.Object ref = targetQueue_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          targetQueue_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string target_queue = 2;</code>
       */
      public Builder setTargetQueue(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        targetQueue_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string target_queue = 2;</code>
       */
      public Builder clearTargetQueue() {
        bitField0_ = (bitField0_ & ~0x00000002);
        targetQueue_ = getDefaultInstance().getTargetQueue();
        onChanged();
        return this;
      }
      /**
       * <code>required string target_queue = 2;</code>
       */
      public Builder setTargetQueueBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        targetQueue_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.MoveApplicationAcrossQueuesRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.MoveApplicationAcrossQueuesRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<MoveApplicationAcrossQueuesRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<MoveApplicationAcrossQueuesRequestProto>() {
      public MoveApplicationAcrossQueuesRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new MoveApplicationAcrossQueuesRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<MoveApplicationAcrossQueuesRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<MoveApplicationAcrossQueuesRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MoveApplicationAcrossQueuesResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.MoveApplicationAcrossQueuesResponseProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.MoveApplicationAcrossQueuesResponseProto}
   */
  public  static final class MoveApplicationAcrossQueuesResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.MoveApplicationAcrossQueuesResponseProto)
      MoveApplicationAcrossQueuesResponseProtoOrBuilder {
    // Use MoveApplicationAcrossQueuesResponseProto.newBuilder() to construct.
    private MoveApplicationAcrossQueuesResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MoveApplicationAcrossQueuesResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private MoveApplicationAcrossQueuesResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_MoveApplicationAcrossQueuesResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_MoveApplicationAcrossQueuesResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.MoveApplicationAcrossQueuesResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.MoveApplicationAcrossQueuesResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_MoveApplicationAcrossQueuesResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_MoveApplicationAcrossQueuesResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_MoveApplicationAcrossQueuesResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.MoveApplicationAcrossQueuesResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.MoveApplicationAcrossQueuesResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<MoveApplicationAcrossQueuesResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<MoveApplicationAcrossQueuesResponseProto>() {
      public MoveApplicationAcrossQueuesResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new MoveApplicationAcrossQueuesResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<MoveApplicationAcrossQueuesResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<MoveApplicationAcrossQueuesResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.MoveApplicationAcrossQueuesResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetApplicationsRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetApplicationsRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated string application_types = 1;</code>
     */
    java.util.List<java.lang.String>
        getApplicationTypesList();
    /**
     * <code>repeated string application_types = 1;</code>
     */
    int getApplicationTypesCount();
    /**
     * <code>repeated string application_types = 1;</code>
     */
    java.lang.String getApplicationTypes(int index);
    /**
     * <code>repeated string application_types = 1;</code>
     */
    com.google.protobuf.ByteString
        getApplicationTypesBytes(int index);

    /**
     * <code>repeated .hadoop.yarn.YarnApplicationStateProto application_states = 2;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto> getApplicationStatesList();
    /**
     * <code>repeated .hadoop.yarn.YarnApplicationStateProto application_states = 2;</code>
     */
    int getApplicationStatesCount();
    /**
     * <code>repeated .hadoop.yarn.YarnApplicationStateProto application_states = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto getApplicationStates(int index);

    /**
     * <code>repeated string users = 3;</code>
     */
    java.util.List<java.lang.String>
        getUsersList();
    /**
     * <code>repeated string users = 3;</code>
     */
    int getUsersCount();
    /**
     * <code>repeated string users = 3;</code>
     */
    java.lang.String getUsers(int index);
    /**
     * <code>repeated string users = 3;</code>
     */
    com.google.protobuf.ByteString
        getUsersBytes(int index);

    /**
     * <code>repeated string queues = 4;</code>
     */
    java.util.List<java.lang.String>
        getQueuesList();
    /**
     * <code>repeated string queues = 4;</code>
     */
    int getQueuesCount();
    /**
     * <code>repeated string queues = 4;</code>
     */
    java.lang.String getQueues(int index);
    /**
     * <code>repeated string queues = 4;</code>
     */
    com.google.protobuf.ByteString
        getQueuesBytes(int index);

    /**
     * <code>optional int64 limit = 5;</code>
     */
    boolean hasLimit();
    /**
     * <code>optional int64 limit = 5;</code>
     */
    long getLimit();

    /**
     * <code>optional int64 start_begin = 6;</code>
     */
    boolean hasStartBegin();
    /**
     * <code>optional int64 start_begin = 6;</code>
     */
    long getStartBegin();

    /**
     * <code>optional int64 start_end = 7;</code>
     */
    boolean hasStartEnd();
    /**
     * <code>optional int64 start_end = 7;</code>
     */
    long getStartEnd();

    /**
     * <code>optional int64 finish_begin = 8;</code>
     */
    boolean hasFinishBegin();
    /**
     * <code>optional int64 finish_begin = 8;</code>
     */
    long getFinishBegin();

    /**
     * <code>optional int64 finish_end = 9;</code>
     */
    boolean hasFinishEnd();
    /**
     * <code>optional int64 finish_end = 9;</code>
     */
    long getFinishEnd();

    /**
     * <code>repeated string applicationTags = 10;</code>
     */
    java.util.List<java.lang.String>
        getApplicationTagsList();
    /**
     * <code>repeated string applicationTags = 10;</code>
     */
    int getApplicationTagsCount();
    /**
     * <code>repeated string applicationTags = 10;</code>
     */
    java.lang.String getApplicationTags(int index);
    /**
     * <code>repeated string applicationTags = 10;</code>
     */
    com.google.protobuf.ByteString
        getApplicationTagsBytes(int index);

    /**
     * <code>optional .hadoop.yarn.ApplicationsRequestScopeProto scope = 11 [default = ALL];</code>
     */
    boolean hasScope();
    /**
     * <code>optional .hadoop.yarn.ApplicationsRequestScopeProto scope = 11 [default = ALL];</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ApplicationsRequestScopeProto getScope();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetApplicationsRequestProto}
   */
  public  static final class GetApplicationsRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetApplicationsRequestProto)
      GetApplicationsRequestProtoOrBuilder {
    // Use GetApplicationsRequestProto.newBuilder() to construct.
    private GetApplicationsRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetApplicationsRequestProto() {
      applicationTypes_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      applicationStates_ = java.util.Collections.emptyList();
      users_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      queues_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      limit_ = 0L;
      startBegin_ = 0L;
      startEnd_ = 0L;
      finishBegin_ = 0L;
      finishEnd_ = 0L;
      applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      scope_ = 0;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetApplicationsRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                applicationTypes_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000001;
              }
              applicationTypes_.add(bs);
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto value = org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                  applicationStates_ = new java.util.ArrayList<java.lang.Integer>();
                  mutable_bitField0_ |= 0x00000002;
                }
                applicationStates_.add(rawValue);
              }
              break;
            }
            case 18: {
              int length = input.readRawVarint32();
              int oldLimit = input.pushLimit(length);
              while(input.getBytesUntilLimit() > 0) {
                int rawValue = input.readEnum();
                org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto value = org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.valueOf(rawValue);
                if (value == null) {
                  unknownFields.mergeVarintField(2, rawValue);
                } else {
                  if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                    applicationStates_ = new java.util.ArrayList<java.lang.Integer>();
                    mutable_bitField0_ |= 0x00000002;
                  }
                  applicationStates_.add(rawValue);
                }
              }
              input.popLimit(oldLimit);
              break;
            }
            case 26: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                users_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000004;
              }
              users_.add(bs);
              break;
            }
            case 34: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                queues_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000008;
              }
              queues_.add(bs);
              break;
            }
            case 40: {
              bitField0_ |= 0x00000001;
              limit_ = input.readInt64();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000002;
              startBegin_ = input.readInt64();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000004;
              startEnd_ = input.readInt64();
              break;
            }
            case 64: {
              bitField0_ |= 0x00000008;
              finishBegin_ = input.readInt64();
              break;
            }
            case 72: {
              bitField0_ |= 0x00000010;
              finishEnd_ = input.readInt64();
              break;
            }
            case 82: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000200) == 0x00000200)) {
                applicationTags_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000200;
              }
              applicationTags_.add(bs);
              break;
            }
            case 88: {
              int rawValue = input.readEnum();
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ApplicationsRequestScopeProto value = org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ApplicationsRequestScopeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(11, rawValue);
              } else {
                bitField0_ |= 0x00000020;
                scope_ = rawValue;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          applicationTypes_ = applicationTypes_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          applicationStates_ = java.util.Collections.unmodifiableList(applicationStates_);
        }
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          users_ = users_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          queues_ = queues_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000200) == 0x00000200)) {
          applicationTags_ = applicationTags_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationsRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationsRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATION_TYPES_FIELD_NUMBER = 1;
    private com.google.protobuf.LazyStringList applicationTypes_;
    /**
     * <code>repeated string application_types = 1;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getApplicationTypesList() {
      return applicationTypes_;
    }
    /**
     * <code>repeated string application_types = 1;</code>
     */
    public int getApplicationTypesCount() {
      return applicationTypes_.size();
    }
    /**
     * <code>repeated string application_types = 1;</code>
     */
    public java.lang.String getApplicationTypes(int index) {
      return applicationTypes_.get(index);
    }
    /**
     * <code>repeated string application_types = 1;</code>
     */
    public com.google.protobuf.ByteString
        getApplicationTypesBytes(int index) {
      return applicationTypes_.getByteString(index);
    }

    public static final int APPLICATION_STATES_FIELD_NUMBER = 2;
    private java.util.List<java.lang.Integer> applicationStates_;
    private static final com.google.protobuf.Internal.ListAdapter.Converter<
        java.lang.Integer, org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto> applicationStates_converter_ =
            new com.google.protobuf.Internal.ListAdapter.Converter<
                java.lang.Integer, org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto>() {
              public org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto convert(java.lang.Integer from) {
                org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto result = org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.valueOf(from);
                return result == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.NEW : result;
              }
            };
    /**
     * <code>repeated .hadoop.yarn.YarnApplicationStateProto application_states = 2;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto> getApplicationStatesList() {
      return new com.google.protobuf.Internal.ListAdapter<
          java.lang.Integer, org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto>(applicationStates_, applicationStates_converter_);
    }
    /**
     * <code>repeated .hadoop.yarn.YarnApplicationStateProto application_states = 2;</code>
     */
    public int getApplicationStatesCount() {
      return applicationStates_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.YarnApplicationStateProto application_states = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto getApplicationStates(int index) {
      return applicationStates_converter_.convert(applicationStates_.get(index));
    }

    public static final int USERS_FIELD_NUMBER = 3;
    private com.google.protobuf.LazyStringList users_;
    /**
     * <code>repeated string users = 3;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getUsersList() {
      return users_;
    }
    /**
     * <code>repeated string users = 3;</code>
     */
    public int getUsersCount() {
      return users_.size();
    }
    /**
     * <code>repeated string users = 3;</code>
     */
    public java.lang.String getUsers(int index) {
      return users_.get(index);
    }
    /**
     * <code>repeated string users = 3;</code>
     */
    public com.google.protobuf.ByteString
        getUsersBytes(int index) {
      return users_.getByteString(index);
    }

    public static final int QUEUES_FIELD_NUMBER = 4;
    private com.google.protobuf.LazyStringList queues_;
    /**
     * <code>repeated string queues = 4;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getQueuesList() {
      return queues_;
    }
    /**
     * <code>repeated string queues = 4;</code>
     */
    public int getQueuesCount() {
      return queues_.size();
    }
    /**
     * <code>repeated string queues = 4;</code>
     */
    public java.lang.String getQueues(int index) {
      return queues_.get(index);
    }
    /**
     * <code>repeated string queues = 4;</code>
     */
    public com.google.protobuf.ByteString
        getQueuesBytes(int index) {
      return queues_.getByteString(index);
    }

    public static final int LIMIT_FIELD_NUMBER = 5;
    private long limit_;
    /**
     * <code>optional int64 limit = 5;</code>
     */
    public boolean hasLimit() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int64 limit = 5;</code>
     */
    public long getLimit() {
      return limit_;
    }

    public static final int START_BEGIN_FIELD_NUMBER = 6;
    private long startBegin_;
    /**
     * <code>optional int64 start_begin = 6;</code>
     */
    public boolean hasStartBegin() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 start_begin = 6;</code>
     */
    public long getStartBegin() {
      return startBegin_;
    }

    public static final int START_END_FIELD_NUMBER = 7;
    private long startEnd_;
    /**
     * <code>optional int64 start_end = 7;</code>
     */
    public boolean hasStartEnd() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int64 start_end = 7;</code>
     */
    public long getStartEnd() {
      return startEnd_;
    }

    public static final int FINISH_BEGIN_FIELD_NUMBER = 8;
    private long finishBegin_;
    /**
     * <code>optional int64 finish_begin = 8;</code>
     */
    public boolean hasFinishBegin() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional int64 finish_begin = 8;</code>
     */
    public long getFinishBegin() {
      return finishBegin_;
    }

    public static final int FINISH_END_FIELD_NUMBER = 9;
    private long finishEnd_;
    /**
     * <code>optional int64 finish_end = 9;</code>
     */
    public boolean hasFinishEnd() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional int64 finish_end = 9;</code>
     */
    public long getFinishEnd() {
      return finishEnd_;
    }

    public static final int APPLICATIONTAGS_FIELD_NUMBER = 10;
    private com.google.protobuf.LazyStringList applicationTags_;
    /**
     * <code>repeated string applicationTags = 10;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getApplicationTagsList() {
      return applicationTags_;
    }
    /**
     * <code>repeated string applicationTags = 10;</code>
     */
    public int getApplicationTagsCount() {
      return applicationTags_.size();
    }
    /**
     * <code>repeated string applicationTags = 10;</code>
     */
    public java.lang.String getApplicationTags(int index) {
      return applicationTags_.get(index);
    }
    /**
     * <code>repeated string applicationTags = 10;</code>
     */
    public com.google.protobuf.ByteString
        getApplicationTagsBytes(int index) {
      return applicationTags_.getByteString(index);
    }

    public static final int SCOPE_FIELD_NUMBER = 11;
    private int scope_;
    /**
     * <code>optional .hadoop.yarn.ApplicationsRequestScopeProto scope = 11 [default = ALL];</code>
     */
    public boolean hasScope() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationsRequestScopeProto scope = 11 [default = ALL];</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ApplicationsRequestScopeProto getScope() {
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ApplicationsRequestScopeProto result = org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ApplicationsRequestScopeProto.valueOf(scope_);
      return result == null ? org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ApplicationsRequestScopeProto.ALL : result;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < applicationTypes_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, applicationTypes_.getRaw(i));
      }
      for (int i = 0; i < applicationStates_.size(); i++) {
        output.writeEnum(2, applicationStates_.get(i));
      }
      for (int i = 0; i < users_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, users_.getRaw(i));
      }
      for (int i = 0; i < queues_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, queues_.getRaw(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt64(5, limit_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(6, startBegin_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt64(7, startEnd_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt64(8, finishBegin_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeInt64(9, finishEnd_);
      }
      for (int i = 0; i < applicationTags_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 10, applicationTags_.getRaw(i));
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeEnum(11, scope_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < applicationTypes_.size(); i++) {
          dataSize += computeStringSizeNoTag(applicationTypes_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getApplicationTypesList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < applicationStates_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeEnumSizeNoTag(applicationStates_.get(i));
        }
        size += dataSize;
        size += 1 * applicationStates_.size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < users_.size(); i++) {
          dataSize += computeStringSizeNoTag(users_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getUsersList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < queues_.size(); i++) {
          dataSize += computeStringSizeNoTag(queues_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getQueuesList().size();
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(5, limit_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(6, startBegin_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(7, startEnd_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(8, finishBegin_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(9, finishEnd_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < applicationTags_.size(); i++) {
          dataSize += computeStringSizeNoTag(applicationTags_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getApplicationTagsList().size();
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(11, scope_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto) obj;

      boolean result = true;
      result = result && getApplicationTypesList()
          .equals(other.getApplicationTypesList());
      result = result && applicationStates_.equals(other.applicationStates_);
      result = result && getUsersList()
          .equals(other.getUsersList());
      result = result && getQueuesList()
          .equals(other.getQueuesList());
      result = result && (hasLimit() == other.hasLimit());
      if (hasLimit()) {
        result = result && (getLimit()
            == other.getLimit());
      }
      result = result && (hasStartBegin() == other.hasStartBegin());
      if (hasStartBegin()) {
        result = result && (getStartBegin()
            == other.getStartBegin());
      }
      result = result && (hasStartEnd() == other.hasStartEnd());
      if (hasStartEnd()) {
        result = result && (getStartEnd()
            == other.getStartEnd());
      }
      result = result && (hasFinishBegin() == other.hasFinishBegin());
      if (hasFinishBegin()) {
        result = result && (getFinishBegin()
            == other.getFinishBegin());
      }
      result = result && (hasFinishEnd() == other.hasFinishEnd());
      if (hasFinishEnd()) {
        result = result && (getFinishEnd()
            == other.getFinishEnd());
      }
      result = result && getApplicationTagsList()
          .equals(other.getApplicationTagsList());
      result = result && (hasScope() == other.hasScope());
      if (hasScope()) {
        result = result && scope_ == other.scope_;
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getApplicationTypesCount() > 0) {
        hash = (37 * hash) + APPLICATION_TYPES_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationTypesList().hashCode();
      }
      if (getApplicationStatesCount() > 0) {
        hash = (37 * hash) + APPLICATION_STATES_FIELD_NUMBER;
        hash = (53 * hash) + applicationStates_.hashCode();
      }
      if (getUsersCount() > 0) {
        hash = (37 * hash) + USERS_FIELD_NUMBER;
        hash = (53 * hash) + getUsersList().hashCode();
      }
      if (getQueuesCount() > 0) {
        hash = (37 * hash) + QUEUES_FIELD_NUMBER;
        hash = (53 * hash) + getQueuesList().hashCode();
      }
      if (hasLimit()) {
        hash = (37 * hash) + LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getLimit());
      }
      if (hasStartBegin()) {
        hash = (37 * hash) + START_BEGIN_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getStartBegin());
      }
      if (hasStartEnd()) {
        hash = (37 * hash) + START_END_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getStartEnd());
      }
      if (hasFinishBegin()) {
        hash = (37 * hash) + FINISH_BEGIN_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getFinishBegin());
      }
      if (hasFinishEnd()) {
        hash = (37 * hash) + FINISH_END_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getFinishEnd());
      }
      if (getApplicationTagsCount() > 0) {
        hash = (37 * hash) + APPLICATIONTAGS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationTagsList().hashCode();
      }
      if (hasScope()) {
        hash = (37 * hash) + SCOPE_FIELD_NUMBER;
        hash = (53 * hash) + scope_;
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetApplicationsRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetApplicationsRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationsRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationsRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        applicationTypes_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        applicationStates_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        users_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        queues_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        limit_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000010);
        startBegin_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000020);
        startEnd_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000040);
        finishBegin_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000080);
        finishEnd_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000100);
        applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000200);
        scope_ = 0;
        bitField0_ = (bitField0_ & ~0x00000400);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationsRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          applicationTypes_ = applicationTypes_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.applicationTypes_ = applicationTypes_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          applicationStates_ = java.util.Collections.unmodifiableList(applicationStates_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.applicationStates_ = applicationStates_;
        if (((bitField0_ & 0x00000004) == 0x00000004)) {
          users_ = users_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000004);
        }
        result.users_ = users_;
        if (((bitField0_ & 0x00000008) == 0x00000008)) {
          queues_ = queues_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000008);
        }
        result.queues_ = queues_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000001;
        }
        result.limit_ = limit_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000002;
        }
        result.startBegin_ = startBegin_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000004;
        }
        result.startEnd_ = startEnd_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000008;
        }
        result.finishBegin_ = finishBegin_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000010;
        }
        result.finishEnd_ = finishEnd_;
        if (((bitField0_ & 0x00000200) == 0x00000200)) {
          applicationTags_ = applicationTags_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000200);
        }
        result.applicationTags_ = applicationTags_;
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000020;
        }
        result.scope_ = scope_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto.getDefaultInstance()) return this;
        if (!other.applicationTypes_.isEmpty()) {
          if (applicationTypes_.isEmpty()) {
            applicationTypes_ = other.applicationTypes_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureApplicationTypesIsMutable();
            applicationTypes_.addAll(other.applicationTypes_);
          }
          onChanged();
        }
        if (!other.applicationStates_.isEmpty()) {
          if (applicationStates_.isEmpty()) {
            applicationStates_ = other.applicationStates_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureApplicationStatesIsMutable();
            applicationStates_.addAll(other.applicationStates_);
          }
          onChanged();
        }
        if (!other.users_.isEmpty()) {
          if (users_.isEmpty()) {
            users_ = other.users_;
            bitField0_ = (bitField0_ & ~0x00000004);
          } else {
            ensureUsersIsMutable();
            users_.addAll(other.users_);
          }
          onChanged();
        }
        if (!other.queues_.isEmpty()) {
          if (queues_.isEmpty()) {
            queues_ = other.queues_;
            bitField0_ = (bitField0_ & ~0x00000008);
          } else {
            ensureQueuesIsMutable();
            queues_.addAll(other.queues_);
          }
          onChanged();
        }
        if (other.hasLimit()) {
          setLimit(other.getLimit());
        }
        if (other.hasStartBegin()) {
          setStartBegin(other.getStartBegin());
        }
        if (other.hasStartEnd()) {
          setStartEnd(other.getStartEnd());
        }
        if (other.hasFinishBegin()) {
          setFinishBegin(other.getFinishBegin());
        }
        if (other.hasFinishEnd()) {
          setFinishEnd(other.getFinishEnd());
        }
        if (!other.applicationTags_.isEmpty()) {
          if (applicationTags_.isEmpty()) {
            applicationTags_ = other.applicationTags_;
            bitField0_ = (bitField0_ & ~0x00000200);
          } else {
            ensureApplicationTagsIsMutable();
            applicationTags_.addAll(other.applicationTags_);
          }
          onChanged();
        }
        if (other.hasScope()) {
          setScope(other.getScope());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private com.google.protobuf.LazyStringList applicationTypes_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureApplicationTypesIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          applicationTypes_ = new com.google.protobuf.LazyStringArrayList(applicationTypes_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <code>repeated string application_types = 1;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getApplicationTypesList() {
        return applicationTypes_.getUnmodifiableView();
      }
      /**
       * <code>repeated string application_types = 1;</code>
       */
      public int getApplicationTypesCount() {
        return applicationTypes_.size();
      }
      /**
       * <code>repeated string application_types = 1;</code>
       */
      public java.lang.String getApplicationTypes(int index) {
        return applicationTypes_.get(index);
      }
      /**
       * <code>repeated string application_types = 1;</code>
       */
      public com.google.protobuf.ByteString
          getApplicationTypesBytes(int index) {
        return applicationTypes_.getByteString(index);
      }
      /**
       * <code>repeated string application_types = 1;</code>
       */
      public Builder setApplicationTypes(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTypesIsMutable();
        applicationTypes_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string application_types = 1;</code>
       */
      public Builder addApplicationTypes(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTypesIsMutable();
        applicationTypes_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string application_types = 1;</code>
       */
      public Builder addAllApplicationTypes(
          java.lang.Iterable<java.lang.String> values) {
        ensureApplicationTypesIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, applicationTypes_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string application_types = 1;</code>
       */
      public Builder clearApplicationTypes() {
        applicationTypes_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string application_types = 1;</code>
       */
      public Builder addApplicationTypesBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTypesIsMutable();
        applicationTypes_.add(value);
        onChanged();
        return this;
      }

      private java.util.List<java.lang.Integer> applicationStates_ =
        java.util.Collections.emptyList();
      private void ensureApplicationStatesIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          applicationStates_ = new java.util.ArrayList<java.lang.Integer>(applicationStates_);
          bitField0_ |= 0x00000002;
        }
      }
      /**
       * <code>repeated .hadoop.yarn.YarnApplicationStateProto application_states = 2;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto> getApplicationStatesList() {
        return new com.google.protobuf.Internal.ListAdapter<
            java.lang.Integer, org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto>(applicationStates_, applicationStates_converter_);
      }
      /**
       * <code>repeated .hadoop.yarn.YarnApplicationStateProto application_states = 2;</code>
       */
      public int getApplicationStatesCount() {
        return applicationStates_.size();
      }
      /**
       * <code>repeated .hadoop.yarn.YarnApplicationStateProto application_states = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto getApplicationStates(int index) {
        return applicationStates_converter_.convert(applicationStates_.get(index));
      }
      /**
       * <code>repeated .hadoop.yarn.YarnApplicationStateProto application_states = 2;</code>
       */
      public Builder setApplicationStates(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureApplicationStatesIsMutable();
        applicationStates_.set(index, value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.YarnApplicationStateProto application_states = 2;</code>
       */
      public Builder addApplicationStates(org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureApplicationStatesIsMutable();
        applicationStates_.add(value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.YarnApplicationStateProto application_states = 2;</code>
       */
      public Builder addAllApplicationStates(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto> values) {
        ensureApplicationStatesIsMutable();
        for (org.spiderdt.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto value : values) {
          applicationStates_.add(value.getNumber());
        }
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.YarnApplicationStateProto application_states = 2;</code>
       */
      public Builder clearApplicationStates() {
        applicationStates_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList users_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureUsersIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          users_ = new com.google.protobuf.LazyStringArrayList(users_);
          bitField0_ |= 0x00000004;
         }
      }
      /**
       * <code>repeated string users = 3;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getUsersList() {
        return users_.getUnmodifiableView();
      }
      /**
       * <code>repeated string users = 3;</code>
       */
      public int getUsersCount() {
        return users_.size();
      }
      /**
       * <code>repeated string users = 3;</code>
       */
      public java.lang.String getUsers(int index) {
        return users_.get(index);
      }
      /**
       * <code>repeated string users = 3;</code>
       */
      public com.google.protobuf.ByteString
          getUsersBytes(int index) {
        return users_.getByteString(index);
      }
      /**
       * <code>repeated string users = 3;</code>
       */
      public Builder setUsers(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureUsersIsMutable();
        users_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string users = 3;</code>
       */
      public Builder addUsers(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureUsersIsMutable();
        users_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string users = 3;</code>
       */
      public Builder addAllUsers(
          java.lang.Iterable<java.lang.String> values) {
        ensureUsersIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, users_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string users = 3;</code>
       */
      public Builder clearUsers() {
        users_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string users = 3;</code>
       */
      public Builder addUsersBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureUsersIsMutable();
        users_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList queues_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureQueuesIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          queues_ = new com.google.protobuf.LazyStringArrayList(queues_);
          bitField0_ |= 0x00000008;
         }
      }
      /**
       * <code>repeated string queues = 4;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getQueuesList() {
        return queues_.getUnmodifiableView();
      }
      /**
       * <code>repeated string queues = 4;</code>
       */
      public int getQueuesCount() {
        return queues_.size();
      }
      /**
       * <code>repeated string queues = 4;</code>
       */
      public java.lang.String getQueues(int index) {
        return queues_.get(index);
      }
      /**
       * <code>repeated string queues = 4;</code>
       */
      public com.google.protobuf.ByteString
          getQueuesBytes(int index) {
        return queues_.getByteString(index);
      }
      /**
       * <code>repeated string queues = 4;</code>
       */
      public Builder setQueues(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureQueuesIsMutable();
        queues_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string queues = 4;</code>
       */
      public Builder addQueues(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureQueuesIsMutable();
        queues_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string queues = 4;</code>
       */
      public Builder addAllQueues(
          java.lang.Iterable<java.lang.String> values) {
        ensureQueuesIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, queues_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string queues = 4;</code>
       */
      public Builder clearQueues() {
        queues_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string queues = 4;</code>
       */
      public Builder addQueuesBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureQueuesIsMutable();
        queues_.add(value);
        onChanged();
        return this;
      }

      private long limit_ ;
      /**
       * <code>optional int64 limit = 5;</code>
       */
      public boolean hasLimit() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional int64 limit = 5;</code>
       */
      public long getLimit() {
        return limit_;
      }
      /**
       * <code>optional int64 limit = 5;</code>
       */
      public Builder setLimit(long value) {
        bitField0_ |= 0x00000010;
        limit_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 limit = 5;</code>
       */
      public Builder clearLimit() {
        bitField0_ = (bitField0_ & ~0x00000010);
        limit_ = 0L;
        onChanged();
        return this;
      }

      private long startBegin_ ;
      /**
       * <code>optional int64 start_begin = 6;</code>
       */
      public boolean hasStartBegin() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional int64 start_begin = 6;</code>
       */
      public long getStartBegin() {
        return startBegin_;
      }
      /**
       * <code>optional int64 start_begin = 6;</code>
       */
      public Builder setStartBegin(long value) {
        bitField0_ |= 0x00000020;
        startBegin_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 start_begin = 6;</code>
       */
      public Builder clearStartBegin() {
        bitField0_ = (bitField0_ & ~0x00000020);
        startBegin_ = 0L;
        onChanged();
        return this;
      }

      private long startEnd_ ;
      /**
       * <code>optional int64 start_end = 7;</code>
       */
      public boolean hasStartEnd() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional int64 start_end = 7;</code>
       */
      public long getStartEnd() {
        return startEnd_;
      }
      /**
       * <code>optional int64 start_end = 7;</code>
       */
      public Builder setStartEnd(long value) {
        bitField0_ |= 0x00000040;
        startEnd_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 start_end = 7;</code>
       */
      public Builder clearStartEnd() {
        bitField0_ = (bitField0_ & ~0x00000040);
        startEnd_ = 0L;
        onChanged();
        return this;
      }

      private long finishBegin_ ;
      /**
       * <code>optional int64 finish_begin = 8;</code>
       */
      public boolean hasFinishBegin() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional int64 finish_begin = 8;</code>
       */
      public long getFinishBegin() {
        return finishBegin_;
      }
      /**
       * <code>optional int64 finish_begin = 8;</code>
       */
      public Builder setFinishBegin(long value) {
        bitField0_ |= 0x00000080;
        finishBegin_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 finish_begin = 8;</code>
       */
      public Builder clearFinishBegin() {
        bitField0_ = (bitField0_ & ~0x00000080);
        finishBegin_ = 0L;
        onChanged();
        return this;
      }

      private long finishEnd_ ;
      /**
       * <code>optional int64 finish_end = 9;</code>
       */
      public boolean hasFinishEnd() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional int64 finish_end = 9;</code>
       */
      public long getFinishEnd() {
        return finishEnd_;
      }
      /**
       * <code>optional int64 finish_end = 9;</code>
       */
      public Builder setFinishEnd(long value) {
        bitField0_ |= 0x00000100;
        finishEnd_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 finish_end = 9;</code>
       */
      public Builder clearFinishEnd() {
        bitField0_ = (bitField0_ & ~0x00000100);
        finishEnd_ = 0L;
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureApplicationTagsIsMutable() {
        if (!((bitField0_ & 0x00000200) == 0x00000200)) {
          applicationTags_ = new com.google.protobuf.LazyStringArrayList(applicationTags_);
          bitField0_ |= 0x00000200;
         }
      }
      /**
       * <code>repeated string applicationTags = 10;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getApplicationTagsList() {
        return applicationTags_.getUnmodifiableView();
      }
      /**
       * <code>repeated string applicationTags = 10;</code>
       */
      public int getApplicationTagsCount() {
        return applicationTags_.size();
      }
      /**
       * <code>repeated string applicationTags = 10;</code>
       */
      public java.lang.String getApplicationTags(int index) {
        return applicationTags_.get(index);
      }
      /**
       * <code>repeated string applicationTags = 10;</code>
       */
      public com.google.protobuf.ByteString
          getApplicationTagsBytes(int index) {
        return applicationTags_.getByteString(index);
      }
      /**
       * <code>repeated string applicationTags = 10;</code>
       */
      public Builder setApplicationTags(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTagsIsMutable();
        applicationTags_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 10;</code>
       */
      public Builder addApplicationTags(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTagsIsMutable();
        applicationTags_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 10;</code>
       */
      public Builder addAllApplicationTags(
          java.lang.Iterable<java.lang.String> values) {
        ensureApplicationTagsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, applicationTags_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 10;</code>
       */
      public Builder clearApplicationTags() {
        applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000200);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 10;</code>
       */
      public Builder addApplicationTagsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTagsIsMutable();
        applicationTags_.add(value);
        onChanged();
        return this;
      }

      private int scope_ = 0;
      /**
       * <code>optional .hadoop.yarn.ApplicationsRequestScopeProto scope = 11 [default = ALL];</code>
       */
      public boolean hasScope() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationsRequestScopeProto scope = 11 [default = ALL];</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ApplicationsRequestScopeProto getScope() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ApplicationsRequestScopeProto result = org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ApplicationsRequestScopeProto.valueOf(scope_);
        return result == null ? org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ApplicationsRequestScopeProto.ALL : result;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationsRequestScopeProto scope = 11 [default = ALL];</code>
       */
      public Builder setScope(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ApplicationsRequestScopeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000400;
        scope_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationsRequestScopeProto scope = 11 [default = ALL];</code>
       */
      public Builder clearScope() {
        bitField0_ = (bitField0_ & ~0x00000400);
        scope_ = 0;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetApplicationsRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetApplicationsRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetApplicationsRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetApplicationsRequestProto>() {
      public GetApplicationsRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetApplicationsRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetApplicationsRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetApplicationsRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetApplicationsResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetApplicationsResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> 
        getApplicationsList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplications(int index);
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
     */
    int getApplicationsCount();
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
        getApplicationsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetApplicationsResponseProto}
   */
  public  static final class GetApplicationsResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetApplicationsResponseProto)
      GetApplicationsResponseProtoOrBuilder {
    // Use GetApplicationsResponseProto.newBuilder() to construct.
    private GetApplicationsResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetApplicationsResponseProto() {
      applications_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetApplicationsResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                applications_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              applications_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          applications_ = java.util.Collections.unmodifiableList(applications_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationsResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationsResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto.Builder.class);
    }

    public static final int APPLICATIONS_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> applications_;
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> getApplicationsList() {
      return applications_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
        getApplicationsOrBuilderList() {
      return applications_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
     */
    public int getApplicationsCount() {
      return applications_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplications(int index) {
      return applications_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationsOrBuilder(
        int index) {
      return applications_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getApplicationsCount(); i++) {
        if (!getApplications(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < applications_.size(); i++) {
        output.writeMessage(1, applications_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < applications_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applications_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto) obj;

      boolean result = true;
      result = result && getApplicationsList()
          .equals(other.getApplicationsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getApplicationsCount() > 0) {
        hash = (37 * hash) + APPLICATIONS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetApplicationsResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetApplicationsResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationsResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationsResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationsBuilder_ == null) {
          applications_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          applicationsBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationsResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (applicationsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            applications_ = java.util.Collections.unmodifiableList(applications_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.applications_ = applications_;
        } else {
          result.applications_ = applicationsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto.getDefaultInstance()) return this;
        if (applicationsBuilder_ == null) {
          if (!other.applications_.isEmpty()) {
            if (applications_.isEmpty()) {
              applications_ = other.applications_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureApplicationsIsMutable();
              applications_.addAll(other.applications_);
            }
            onChanged();
          }
        } else {
          if (!other.applications_.isEmpty()) {
            if (applicationsBuilder_.isEmpty()) {
              applicationsBuilder_.dispose();
              applicationsBuilder_ = null;
              applications_ = other.applications_;
              bitField0_ = (bitField0_ & ~0x00000001);
              applicationsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getApplicationsFieldBuilder() : null;
            } else {
              applicationsBuilder_.addAllMessages(other.applications_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getApplicationsCount(); i++) {
          if (!getApplications(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> applications_ =
        java.util.Collections.emptyList();
      private void ensureApplicationsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          applications_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto>(applications_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> applicationsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> getApplicationsList() {
        if (applicationsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(applications_);
        } else {
          return applicationsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public int getApplicationsCount() {
        if (applicationsBuilder_ == null) {
          return applications_.size();
        } else {
          return applicationsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplications(int index) {
        if (applicationsBuilder_ == null) {
          return applications_.get(index);
        } else {
          return applicationsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public Builder setApplications(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsIsMutable();
          applications_.set(index, value);
          onChanged();
        } else {
          applicationsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public Builder setApplications(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.set(index, builderForValue.build());
          onChanged();
        } else {
          applicationsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public Builder addApplications(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsIsMutable();
          applications_.add(value);
          onChanged();
        } else {
          applicationsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public Builder addApplications(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsIsMutable();
          applications_.add(index, value);
          onChanged();
        } else {
          applicationsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public Builder addApplications(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.add(builderForValue.build());
          onChanged();
        } else {
          applicationsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public Builder addApplications(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.add(index, builderForValue.build());
          onChanged();
        } else {
          applicationsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public Builder addAllApplications(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> values) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, applications_);
          onChanged();
        } else {
          applicationsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public Builder clearApplications() {
        if (applicationsBuilder_ == null) {
          applications_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          applicationsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public Builder removeApplications(int index) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.remove(index);
          onChanged();
        } else {
          applicationsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder getApplicationsBuilder(
          int index) {
        return getApplicationsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationsOrBuilder(
          int index) {
        if (applicationsBuilder_ == null) {
          return applications_.get(index);  } else {
          return applicationsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
           getApplicationsOrBuilderList() {
        if (applicationsBuilder_ != null) {
          return applicationsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(applications_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder addApplicationsBuilder() {
        return getApplicationsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder addApplicationsBuilder(
          int index) {
        return getApplicationsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder> 
           getApplicationsBuilderList() {
        return getApplicationsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
          getApplicationsFieldBuilder() {
        if (applicationsBuilder_ == null) {
          applicationsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder>(
                  applications_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          applications_ = null;
        }
        return applicationsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetApplicationsResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetApplicationsResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetApplicationsResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetApplicationsResponseProto>() {
      public GetApplicationsResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetApplicationsResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetApplicationsResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetApplicationsResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationsResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetClusterNodesRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetClusterNodesRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.NodeStateProto nodeStates = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto> getNodeStatesList();
    /**
     * <code>repeated .hadoop.yarn.NodeStateProto nodeStates = 1;</code>
     */
    int getNodeStatesCount();
    /**
     * <code>repeated .hadoop.yarn.NodeStateProto nodeStates = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto getNodeStates(int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetClusterNodesRequestProto}
   */
  public  static final class GetClusterNodesRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetClusterNodesRequestProto)
      GetClusterNodesRequestProtoOrBuilder {
    // Use GetClusterNodesRequestProto.newBuilder() to construct.
    private GetClusterNodesRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetClusterNodesRequestProto() {
      nodeStates_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetClusterNodesRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto value = org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                  nodeStates_ = new java.util.ArrayList<java.lang.Integer>();
                  mutable_bitField0_ |= 0x00000001;
                }
                nodeStates_.add(rawValue);
              }
              break;
            }
            case 10: {
              int length = input.readRawVarint32();
              int oldLimit = input.pushLimit(length);
              while(input.getBytesUntilLimit() > 0) {
                int rawValue = input.readEnum();
                org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto value = org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto.valueOf(rawValue);
                if (value == null) {
                  unknownFields.mergeVarintField(1, rawValue);
                } else {
                  if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                    nodeStates_ = new java.util.ArrayList<java.lang.Integer>();
                    mutable_bitField0_ |= 0x00000001;
                  }
                  nodeStates_.add(rawValue);
                }
              }
              input.popLimit(oldLimit);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          nodeStates_ = java.util.Collections.unmodifiableList(nodeStates_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodesRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodesRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto.Builder.class);
    }

    public static final int NODESTATES_FIELD_NUMBER = 1;
    private java.util.List<java.lang.Integer> nodeStates_;
    private static final com.google.protobuf.Internal.ListAdapter.Converter<
        java.lang.Integer, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto> nodeStates_converter_ =
            new com.google.protobuf.Internal.ListAdapter.Converter<
                java.lang.Integer, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto>() {
              public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto convert(java.lang.Integer from) {
                org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto result = org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto.valueOf(from);
                return result == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto.NS_NEW : result;
              }
            };
    /**
     * <code>repeated .hadoop.yarn.NodeStateProto nodeStates = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto> getNodeStatesList() {
      return new com.google.protobuf.Internal.ListAdapter<
          java.lang.Integer, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto>(nodeStates_, nodeStates_converter_);
    }
    /**
     * <code>repeated .hadoop.yarn.NodeStateProto nodeStates = 1;</code>
     */
    public int getNodeStatesCount() {
      return nodeStates_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.NodeStateProto nodeStates = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto getNodeStates(int index) {
      return nodeStates_converter_.convert(nodeStates_.get(index));
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < nodeStates_.size(); i++) {
        output.writeEnum(1, nodeStates_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < nodeStates_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeEnumSizeNoTag(nodeStates_.get(i));
        }
        size += dataSize;
        size += 1 * nodeStates_.size();
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto) obj;

      boolean result = true;
      result = result && nodeStates_.equals(other.nodeStates_);
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getNodeStatesCount() > 0) {
        hash = (37 * hash) + NODESTATES_FIELD_NUMBER;
        hash = (53 * hash) + nodeStates_.hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetClusterNodesRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetClusterNodesRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodesRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodesRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        nodeStates_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodesRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto(this);
        int from_bitField0_ = bitField0_;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          nodeStates_ = java.util.Collections.unmodifiableList(nodeStates_);
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.nodeStates_ = nodeStates_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto.getDefaultInstance()) return this;
        if (!other.nodeStates_.isEmpty()) {
          if (nodeStates_.isEmpty()) {
            nodeStates_ = other.nodeStates_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureNodeStatesIsMutable();
            nodeStates_.addAll(other.nodeStates_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<java.lang.Integer> nodeStates_ =
        java.util.Collections.emptyList();
      private void ensureNodeStatesIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          nodeStates_ = new java.util.ArrayList<java.lang.Integer>(nodeStates_);
          bitField0_ |= 0x00000001;
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeStateProto nodeStates = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto> getNodeStatesList() {
        return new com.google.protobuf.Internal.ListAdapter<
            java.lang.Integer, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto>(nodeStates_, nodeStates_converter_);
      }
      /**
       * <code>repeated .hadoop.yarn.NodeStateProto nodeStates = 1;</code>
       */
      public int getNodeStatesCount() {
        return nodeStates_.size();
      }
      /**
       * <code>repeated .hadoop.yarn.NodeStateProto nodeStates = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto getNodeStates(int index) {
        return nodeStates_converter_.convert(nodeStates_.get(index));
      }
      /**
       * <code>repeated .hadoop.yarn.NodeStateProto nodeStates = 1;</code>
       */
      public Builder setNodeStates(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureNodeStatesIsMutable();
        nodeStates_.set(index, value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeStateProto nodeStates = 1;</code>
       */
      public Builder addNodeStates(org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureNodeStatesIsMutable();
        nodeStates_.add(value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeStateProto nodeStates = 1;</code>
       */
      public Builder addAllNodeStates(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto> values) {
        ensureNodeStatesIsMutable();
        for (org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeStateProto value : values) {
          nodeStates_.add(value.getNumber());
        }
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeStateProto nodeStates = 1;</code>
       */
      public Builder clearNodeStates() {
        nodeStates_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetClusterNodesRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetClusterNodesRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetClusterNodesRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetClusterNodesRequestProto>() {
      public GetClusterNodesRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetClusterNodesRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetClusterNodesRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetClusterNodesRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetClusterNodesResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetClusterNodesResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto> 
        getNodeReportsList();
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto getNodeReports(int index);
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
     */
    int getNodeReportsCount();
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder> 
        getNodeReportsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder getNodeReportsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetClusterNodesResponseProto}
   */
  public  static final class GetClusterNodesResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetClusterNodesResponseProto)
      GetClusterNodesResponseProtoOrBuilder {
    // Use GetClusterNodesResponseProto.newBuilder() to construct.
    private GetClusterNodesResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetClusterNodesResponseProto() {
      nodeReports_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetClusterNodesResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                nodeReports_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              nodeReports_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          nodeReports_ = java.util.Collections.unmodifiableList(nodeReports_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodesResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodesResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto.Builder.class);
    }

    public static final int NODEREPORTS_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto> nodeReports_;
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto> getNodeReportsList() {
      return nodeReports_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder> 
        getNodeReportsOrBuilderList() {
      return nodeReports_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
     */
    public int getNodeReportsCount() {
      return nodeReports_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto getNodeReports(int index) {
      return nodeReports_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder getNodeReportsOrBuilder(
        int index) {
      return nodeReports_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < nodeReports_.size(); i++) {
        output.writeMessage(1, nodeReports_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < nodeReports_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, nodeReports_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto) obj;

      boolean result = true;
      result = result && getNodeReportsList()
          .equals(other.getNodeReportsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getNodeReportsCount() > 0) {
        hash = (37 * hash) + NODEREPORTS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeReportsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetClusterNodesResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetClusterNodesResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodesResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodesResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNodeReportsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (nodeReportsBuilder_ == null) {
          nodeReports_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          nodeReportsBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodesResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (nodeReportsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            nodeReports_ = java.util.Collections.unmodifiableList(nodeReports_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.nodeReports_ = nodeReports_;
        } else {
          result.nodeReports_ = nodeReportsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto.getDefaultInstance()) return this;
        if (nodeReportsBuilder_ == null) {
          if (!other.nodeReports_.isEmpty()) {
            if (nodeReports_.isEmpty()) {
              nodeReports_ = other.nodeReports_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureNodeReportsIsMutable();
              nodeReports_.addAll(other.nodeReports_);
            }
            onChanged();
          }
        } else {
          if (!other.nodeReports_.isEmpty()) {
            if (nodeReportsBuilder_.isEmpty()) {
              nodeReportsBuilder_.dispose();
              nodeReportsBuilder_ = null;
              nodeReports_ = other.nodeReports_;
              bitField0_ = (bitField0_ & ~0x00000001);
              nodeReportsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getNodeReportsFieldBuilder() : null;
            } else {
              nodeReportsBuilder_.addAllMessages(other.nodeReports_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto> nodeReports_ =
        java.util.Collections.emptyList();
      private void ensureNodeReportsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          nodeReports_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto>(nodeReports_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder> nodeReportsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto> getNodeReportsList() {
        if (nodeReportsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(nodeReports_);
        } else {
          return nodeReportsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public int getNodeReportsCount() {
        if (nodeReportsBuilder_ == null) {
          return nodeReports_.size();
        } else {
          return nodeReportsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto getNodeReports(int index) {
        if (nodeReportsBuilder_ == null) {
          return nodeReports_.get(index);
        } else {
          return nodeReportsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public Builder setNodeReports(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto value) {
        if (nodeReportsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeReportsIsMutable();
          nodeReports_.set(index, value);
          onChanged();
        } else {
          nodeReportsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public Builder setNodeReports(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder builderForValue) {
        if (nodeReportsBuilder_ == null) {
          ensureNodeReportsIsMutable();
          nodeReports_.set(index, builderForValue.build());
          onChanged();
        } else {
          nodeReportsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public Builder addNodeReports(org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto value) {
        if (nodeReportsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeReportsIsMutable();
          nodeReports_.add(value);
          onChanged();
        } else {
          nodeReportsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public Builder addNodeReports(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto value) {
        if (nodeReportsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeReportsIsMutable();
          nodeReports_.add(index, value);
          onChanged();
        } else {
          nodeReportsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public Builder addNodeReports(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder builderForValue) {
        if (nodeReportsBuilder_ == null) {
          ensureNodeReportsIsMutable();
          nodeReports_.add(builderForValue.build());
          onChanged();
        } else {
          nodeReportsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public Builder addNodeReports(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder builderForValue) {
        if (nodeReportsBuilder_ == null) {
          ensureNodeReportsIsMutable();
          nodeReports_.add(index, builderForValue.build());
          onChanged();
        } else {
          nodeReportsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public Builder addAllNodeReports(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto> values) {
        if (nodeReportsBuilder_ == null) {
          ensureNodeReportsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, nodeReports_);
          onChanged();
        } else {
          nodeReportsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public Builder clearNodeReports() {
        if (nodeReportsBuilder_ == null) {
          nodeReports_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          nodeReportsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public Builder removeNodeReports(int index) {
        if (nodeReportsBuilder_ == null) {
          ensureNodeReportsIsMutable();
          nodeReports_.remove(index);
          onChanged();
        } else {
          nodeReportsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder getNodeReportsBuilder(
          int index) {
        return getNodeReportsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder getNodeReportsOrBuilder(
          int index) {
        if (nodeReportsBuilder_ == null) {
          return nodeReports_.get(index);  } else {
          return nodeReportsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder> 
           getNodeReportsOrBuilderList() {
        if (nodeReportsBuilder_ != null) {
          return nodeReportsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(nodeReports_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder addNodeReportsBuilder() {
        return getNodeReportsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder addNodeReportsBuilder(
          int index) {
        return getNodeReportsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeReportProto nodeReports = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder> 
           getNodeReportsBuilderList() {
        return getNodeReportsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder> 
          getNodeReportsFieldBuilder() {
        if (nodeReportsBuilder_ == null) {
          nodeReportsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder>(
                  nodeReports_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          nodeReports_ = null;
        }
        return nodeReportsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetClusterNodesResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetClusterNodesResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetClusterNodesResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetClusterNodesResponseProto>() {
      public GetClusterNodesResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetClusterNodesResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetClusterNodesResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetClusterNodesResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetQueueInfoRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetQueueInfoRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string queueName = 1;</code>
     */
    boolean hasQueueName();
    /**
     * <code>optional string queueName = 1;</code>
     */
    java.lang.String getQueueName();
    /**
     * <code>optional string queueName = 1;</code>
     */
    com.google.protobuf.ByteString
        getQueueNameBytes();

    /**
     * <code>optional bool includeApplications = 2;</code>
     */
    boolean hasIncludeApplications();
    /**
     * <code>optional bool includeApplications = 2;</code>
     */
    boolean getIncludeApplications();

    /**
     * <code>optional bool includeChildQueues = 3;</code>
     */
    boolean hasIncludeChildQueues();
    /**
     * <code>optional bool includeChildQueues = 3;</code>
     */
    boolean getIncludeChildQueues();

    /**
     * <code>optional bool recursive = 4;</code>
     */
    boolean hasRecursive();
    /**
     * <code>optional bool recursive = 4;</code>
     */
    boolean getRecursive();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetQueueInfoRequestProto}
   */
  public  static final class GetQueueInfoRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetQueueInfoRequestProto)
      GetQueueInfoRequestProtoOrBuilder {
    // Use GetQueueInfoRequestProto.newBuilder() to construct.
    private GetQueueInfoRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetQueueInfoRequestProto() {
      queueName_ = "";
      includeApplications_ = false;
      includeChildQueues_ = false;
      recursive_ = false;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetQueueInfoRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              queueName_ = bs;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              includeApplications_ = input.readBool();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              includeChildQueues_ = input.readBool();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              recursive_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueInfoRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueInfoRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int QUEUENAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object queueName_;
    /**
     * <code>optional string queueName = 1;</code>
     */
    public boolean hasQueueName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string queueName = 1;</code>
     */
    public java.lang.String getQueueName() {
      java.lang.Object ref = queueName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queueName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queueName = 1;</code>
     */
    public com.google.protobuf.ByteString
        getQueueNameBytes() {
      java.lang.Object ref = queueName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queueName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int INCLUDEAPPLICATIONS_FIELD_NUMBER = 2;
    private boolean includeApplications_;
    /**
     * <code>optional bool includeApplications = 2;</code>
     */
    public boolean hasIncludeApplications() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bool includeApplications = 2;</code>
     */
    public boolean getIncludeApplications() {
      return includeApplications_;
    }

    public static final int INCLUDECHILDQUEUES_FIELD_NUMBER = 3;
    private boolean includeChildQueues_;
    /**
     * <code>optional bool includeChildQueues = 3;</code>
     */
    public boolean hasIncludeChildQueues() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional bool includeChildQueues = 3;</code>
     */
    public boolean getIncludeChildQueues() {
      return includeChildQueues_;
    }

    public static final int RECURSIVE_FIELD_NUMBER = 4;
    private boolean recursive_;
    /**
     * <code>optional bool recursive = 4;</code>
     */
    public boolean hasRecursive() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional bool recursive = 4;</code>
     */
    public boolean getRecursive() {
      return recursive_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, queueName_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, includeApplications_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(3, includeChildQueues_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBool(4, recursive_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, queueName_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, includeApplications_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, includeChildQueues_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, recursive_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto) obj;

      boolean result = true;
      result = result && (hasQueueName() == other.hasQueueName());
      if (hasQueueName()) {
        result = result && getQueueName()
            .equals(other.getQueueName());
      }
      result = result && (hasIncludeApplications() == other.hasIncludeApplications());
      if (hasIncludeApplications()) {
        result = result && (getIncludeApplications()
            == other.getIncludeApplications());
      }
      result = result && (hasIncludeChildQueues() == other.hasIncludeChildQueues());
      if (hasIncludeChildQueues()) {
        result = result && (getIncludeChildQueues()
            == other.getIncludeChildQueues());
      }
      result = result && (hasRecursive() == other.hasRecursive());
      if (hasRecursive()) {
        result = result && (getRecursive()
            == other.getRecursive());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasQueueName()) {
        hash = (37 * hash) + QUEUENAME_FIELD_NUMBER;
        hash = (53 * hash) + getQueueName().hashCode();
      }
      if (hasIncludeApplications()) {
        hash = (37 * hash) + INCLUDEAPPLICATIONS_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getIncludeApplications());
      }
      if (hasIncludeChildQueues()) {
        hash = (37 * hash) + INCLUDECHILDQUEUES_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getIncludeChildQueues());
      }
      if (hasRecursive()) {
        hash = (37 * hash) + RECURSIVE_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getRecursive());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetQueueInfoRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetQueueInfoRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueInfoRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueInfoRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        queueName_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        includeApplications_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        includeChildQueues_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        recursive_ = false;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueInfoRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.queueName_ = queueName_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.includeApplications_ = includeApplications_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.includeChildQueues_ = includeChildQueues_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.recursive_ = recursive_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto.getDefaultInstance()) return this;
        if (other.hasQueueName()) {
          bitField0_ |= 0x00000001;
          queueName_ = other.queueName_;
          onChanged();
        }
        if (other.hasIncludeApplications()) {
          setIncludeApplications(other.getIncludeApplications());
        }
        if (other.hasIncludeChildQueues()) {
          setIncludeChildQueues(other.getIncludeChildQueues());
        }
        if (other.hasRecursive()) {
          setRecursive(other.getRecursive());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object queueName_ = "";
      /**
       * <code>optional string queueName = 1;</code>
       */
      public boolean hasQueueName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public java.lang.String getQueueName() {
        java.lang.Object ref = queueName_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            queueName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public com.google.protobuf.ByteString
          getQueueNameBytes() {
        java.lang.Object ref = queueName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queueName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder setQueueName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder clearQueueName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        queueName_ = getDefaultInstance().getQueueName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder setQueueNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
        return this;
      }

      private boolean includeApplications_ ;
      /**
       * <code>optional bool includeApplications = 2;</code>
       */
      public boolean hasIncludeApplications() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bool includeApplications = 2;</code>
       */
      public boolean getIncludeApplications() {
        return includeApplications_;
      }
      /**
       * <code>optional bool includeApplications = 2;</code>
       */
      public Builder setIncludeApplications(boolean value) {
        bitField0_ |= 0x00000002;
        includeApplications_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool includeApplications = 2;</code>
       */
      public Builder clearIncludeApplications() {
        bitField0_ = (bitField0_ & ~0x00000002);
        includeApplications_ = false;
        onChanged();
        return this;
      }

      private boolean includeChildQueues_ ;
      /**
       * <code>optional bool includeChildQueues = 3;</code>
       */
      public boolean hasIncludeChildQueues() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional bool includeChildQueues = 3;</code>
       */
      public boolean getIncludeChildQueues() {
        return includeChildQueues_;
      }
      /**
       * <code>optional bool includeChildQueues = 3;</code>
       */
      public Builder setIncludeChildQueues(boolean value) {
        bitField0_ |= 0x00000004;
        includeChildQueues_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool includeChildQueues = 3;</code>
       */
      public Builder clearIncludeChildQueues() {
        bitField0_ = (bitField0_ & ~0x00000004);
        includeChildQueues_ = false;
        onChanged();
        return this;
      }

      private boolean recursive_ ;
      /**
       * <code>optional bool recursive = 4;</code>
       */
      public boolean hasRecursive() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional bool recursive = 4;</code>
       */
      public boolean getRecursive() {
        return recursive_;
      }
      /**
       * <code>optional bool recursive = 4;</code>
       */
      public Builder setRecursive(boolean value) {
        bitField0_ |= 0x00000008;
        recursive_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool recursive = 4;</code>
       */
      public Builder clearRecursive() {
        bitField0_ = (bitField0_ & ~0x00000008);
        recursive_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetQueueInfoRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetQueueInfoRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetQueueInfoRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetQueueInfoRequestProto>() {
      public GetQueueInfoRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetQueueInfoRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetQueueInfoRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetQueueInfoRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetQueueInfoResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetQueueInfoResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.QueueInfoProto queueInfo = 1;</code>
     */
    boolean hasQueueInfo();
    /**
     * <code>optional .hadoop.yarn.QueueInfoProto queueInfo = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto getQueueInfo();
    /**
     * <code>optional .hadoop.yarn.QueueInfoProto queueInfo = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder getQueueInfoOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetQueueInfoResponseProto}
   */
  public  static final class GetQueueInfoResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetQueueInfoResponseProto)
      GetQueueInfoResponseProtoOrBuilder {
    // Use GetQueueInfoResponseProto.newBuilder() to construct.
    private GetQueueInfoResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetQueueInfoResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetQueueInfoResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = queueInfo_.toBuilder();
              }
              queueInfo_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(queueInfo_);
                queueInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueInfoResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueInfoResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto.Builder.class);
    }

    private int bitField0_;
    public static final int QUEUEINFO_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto queueInfo_;
    /**
     * <code>optional .hadoop.yarn.QueueInfoProto queueInfo = 1;</code>
     */
    public boolean hasQueueInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.QueueInfoProto queueInfo = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto getQueueInfo() {
      return queueInfo_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance() : queueInfo_;
    }
    /**
     * <code>optional .hadoop.yarn.QueueInfoProto queueInfo = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder getQueueInfoOrBuilder() {
      return queueInfo_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance() : queueInfo_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasQueueInfo()) {
        if (!getQueueInfo().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getQueueInfo());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getQueueInfo());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto) obj;

      boolean result = true;
      result = result && (hasQueueInfo() == other.hasQueueInfo());
      if (hasQueueInfo()) {
        result = result && getQueueInfo()
            .equals(other.getQueueInfo());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasQueueInfo()) {
        hash = (37 * hash) + QUEUEINFO_FIELD_NUMBER;
        hash = (53 * hash) + getQueueInfo().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetQueueInfoResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetQueueInfoResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueInfoResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueInfoResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getQueueInfoFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (queueInfoBuilder_ == null) {
          queueInfo_ = null;
        } else {
          queueInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueInfoResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (queueInfoBuilder_ == null) {
          result.queueInfo_ = queueInfo_;
        } else {
          result.queueInfo_ = queueInfoBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto.getDefaultInstance()) return this;
        if (other.hasQueueInfo()) {
          mergeQueueInfo(other.getQueueInfo());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (hasQueueInfo()) {
          if (!getQueueInfo().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto queueInfo_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> queueInfoBuilder_;
      /**
       * <code>optional .hadoop.yarn.QueueInfoProto queueInfo = 1;</code>
       */
      public boolean hasQueueInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.QueueInfoProto queueInfo = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto getQueueInfo() {
        if (queueInfoBuilder_ == null) {
          return queueInfo_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance() : queueInfo_;
        } else {
          return queueInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.QueueInfoProto queueInfo = 1;</code>
       */
      public Builder setQueueInfo(org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto value) {
        if (queueInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          queueInfo_ = value;
          onChanged();
        } else {
          queueInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.QueueInfoProto queueInfo = 1;</code>
       */
      public Builder setQueueInfo(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder builderForValue) {
        if (queueInfoBuilder_ == null) {
          queueInfo_ = builderForValue.build();
          onChanged();
        } else {
          queueInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.QueueInfoProto queueInfo = 1;</code>
       */
      public Builder mergeQueueInfo(org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto value) {
        if (queueInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              queueInfo_ != null &&
              queueInfo_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance()) {
            queueInfo_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto.newBuilder(queueInfo_).mergeFrom(value).buildPartial();
          } else {
            queueInfo_ = value;
          }
          onChanged();
        } else {
          queueInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.QueueInfoProto queueInfo = 1;</code>
       */
      public Builder clearQueueInfo() {
        if (queueInfoBuilder_ == null) {
          queueInfo_ = null;
          onChanged();
        } else {
          queueInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.QueueInfoProto queueInfo = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder getQueueInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getQueueInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.QueueInfoProto queueInfo = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder getQueueInfoOrBuilder() {
        if (queueInfoBuilder_ != null) {
          return queueInfoBuilder_.getMessageOrBuilder();
        } else {
          return queueInfo_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance() : queueInfo_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.QueueInfoProto queueInfo = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> 
          getQueueInfoFieldBuilder() {
        if (queueInfoBuilder_ == null) {
          queueInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder>(
                  getQueueInfo(),
                  getParentForChildren(),
                  isClean());
          queueInfo_ = null;
        }
        return queueInfoBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetQueueInfoResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetQueueInfoResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetQueueInfoResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetQueueInfoResponseProto>() {
      public GetQueueInfoResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetQueueInfoResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetQueueInfoResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetQueueInfoResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetQueueUserAclsInfoRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetQueueUserAclsInfoRequestProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetQueueUserAclsInfoRequestProto}
   */
  public  static final class GetQueueUserAclsInfoRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetQueueUserAclsInfoRequestProto)
      GetQueueUserAclsInfoRequestProtoOrBuilder {
    // Use GetQueueUserAclsInfoRequestProto.newBuilder() to construct.
    private GetQueueUserAclsInfoRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetQueueUserAclsInfoRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetQueueUserAclsInfoRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueUserAclsInfoRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueUserAclsInfoRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetQueueUserAclsInfoRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetQueueUserAclsInfoRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueUserAclsInfoRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueUserAclsInfoRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueUserAclsInfoRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetQueueUserAclsInfoRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetQueueUserAclsInfoRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetQueueUserAclsInfoRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetQueueUserAclsInfoRequestProto>() {
      public GetQueueUserAclsInfoRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetQueueUserAclsInfoRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetQueueUserAclsInfoRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetQueueUserAclsInfoRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetQueueUserAclsInfoResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetQueueUserAclsInfoResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto> 
        getQueueUserAclsList();
    /**
     * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto getQueueUserAcls(int index);
    /**
     * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
     */
    int getQueueUserAclsCount();
    /**
     * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder> 
        getQueueUserAclsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder getQueueUserAclsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetQueueUserAclsInfoResponseProto}
   */
  public  static final class GetQueueUserAclsInfoResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetQueueUserAclsInfoResponseProto)
      GetQueueUserAclsInfoResponseProtoOrBuilder {
    // Use GetQueueUserAclsInfoResponseProto.newBuilder() to construct.
    private GetQueueUserAclsInfoResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetQueueUserAclsInfoResponseProto() {
      queueUserAcls_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetQueueUserAclsInfoResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                queueUserAcls_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              queueUserAcls_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          queueUserAcls_ = java.util.Collections.unmodifiableList(queueUserAcls_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueUserAclsInfoResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueUserAclsInfoResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto.Builder.class);
    }

    public static final int QUEUEUSERACLS_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto> queueUserAcls_;
    /**
     * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto> getQueueUserAclsList() {
      return queueUserAcls_;
    }
    /**
     * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder> 
        getQueueUserAclsOrBuilderList() {
      return queueUserAcls_;
    }
    /**
     * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
     */
    public int getQueueUserAclsCount() {
      return queueUserAcls_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto getQueueUserAcls(int index) {
      return queueUserAcls_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder getQueueUserAclsOrBuilder(
        int index) {
      return queueUserAcls_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < queueUserAcls_.size(); i++) {
        output.writeMessage(1, queueUserAcls_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < queueUserAcls_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, queueUserAcls_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto) obj;

      boolean result = true;
      result = result && getQueueUserAclsList()
          .equals(other.getQueueUserAclsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getQueueUserAclsCount() > 0) {
        hash = (37 * hash) + QUEUEUSERACLS_FIELD_NUMBER;
        hash = (53 * hash) + getQueueUserAclsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetQueueUserAclsInfoResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetQueueUserAclsInfoResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueUserAclsInfoResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueUserAclsInfoResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getQueueUserAclsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (queueUserAclsBuilder_ == null) {
          queueUserAcls_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          queueUserAclsBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetQueueUserAclsInfoResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (queueUserAclsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            queueUserAcls_ = java.util.Collections.unmodifiableList(queueUserAcls_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.queueUserAcls_ = queueUserAcls_;
        } else {
          result.queueUserAcls_ = queueUserAclsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto.getDefaultInstance()) return this;
        if (queueUserAclsBuilder_ == null) {
          if (!other.queueUserAcls_.isEmpty()) {
            if (queueUserAcls_.isEmpty()) {
              queueUserAcls_ = other.queueUserAcls_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureQueueUserAclsIsMutable();
              queueUserAcls_.addAll(other.queueUserAcls_);
            }
            onChanged();
          }
        } else {
          if (!other.queueUserAcls_.isEmpty()) {
            if (queueUserAclsBuilder_.isEmpty()) {
              queueUserAclsBuilder_.dispose();
              queueUserAclsBuilder_ = null;
              queueUserAcls_ = other.queueUserAcls_;
              bitField0_ = (bitField0_ & ~0x00000001);
              queueUserAclsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getQueueUserAclsFieldBuilder() : null;
            } else {
              queueUserAclsBuilder_.addAllMessages(other.queueUserAcls_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto> queueUserAcls_ =
        java.util.Collections.emptyList();
      private void ensureQueueUserAclsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          queueUserAcls_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto>(queueUserAcls_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder> queueUserAclsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto> getQueueUserAclsList() {
        if (queueUserAclsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(queueUserAcls_);
        } else {
          return queueUserAclsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public int getQueueUserAclsCount() {
        if (queueUserAclsBuilder_ == null) {
          return queueUserAcls_.size();
        } else {
          return queueUserAclsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto getQueueUserAcls(int index) {
        if (queueUserAclsBuilder_ == null) {
          return queueUserAcls_.get(index);
        } else {
          return queueUserAclsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public Builder setQueueUserAcls(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto value) {
        if (queueUserAclsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureQueueUserAclsIsMutable();
          queueUserAcls_.set(index, value);
          onChanged();
        } else {
          queueUserAclsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public Builder setQueueUserAcls(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder builderForValue) {
        if (queueUserAclsBuilder_ == null) {
          ensureQueueUserAclsIsMutable();
          queueUserAcls_.set(index, builderForValue.build());
          onChanged();
        } else {
          queueUserAclsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public Builder addQueueUserAcls(org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto value) {
        if (queueUserAclsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureQueueUserAclsIsMutable();
          queueUserAcls_.add(value);
          onChanged();
        } else {
          queueUserAclsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public Builder addQueueUserAcls(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto value) {
        if (queueUserAclsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureQueueUserAclsIsMutable();
          queueUserAcls_.add(index, value);
          onChanged();
        } else {
          queueUserAclsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public Builder addQueueUserAcls(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder builderForValue) {
        if (queueUserAclsBuilder_ == null) {
          ensureQueueUserAclsIsMutable();
          queueUserAcls_.add(builderForValue.build());
          onChanged();
        } else {
          queueUserAclsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public Builder addQueueUserAcls(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder builderForValue) {
        if (queueUserAclsBuilder_ == null) {
          ensureQueueUserAclsIsMutable();
          queueUserAcls_.add(index, builderForValue.build());
          onChanged();
        } else {
          queueUserAclsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public Builder addAllQueueUserAcls(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto> values) {
        if (queueUserAclsBuilder_ == null) {
          ensureQueueUserAclsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, queueUserAcls_);
          onChanged();
        } else {
          queueUserAclsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public Builder clearQueueUserAcls() {
        if (queueUserAclsBuilder_ == null) {
          queueUserAcls_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          queueUserAclsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public Builder removeQueueUserAcls(int index) {
        if (queueUserAclsBuilder_ == null) {
          ensureQueueUserAclsIsMutable();
          queueUserAcls_.remove(index);
          onChanged();
        } else {
          queueUserAclsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder getQueueUserAclsBuilder(
          int index) {
        return getQueueUserAclsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder getQueueUserAclsOrBuilder(
          int index) {
        if (queueUserAclsBuilder_ == null) {
          return queueUserAcls_.get(index);  } else {
          return queueUserAclsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder> 
           getQueueUserAclsOrBuilderList() {
        if (queueUserAclsBuilder_ != null) {
          return queueUserAclsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(queueUserAcls_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder addQueueUserAclsBuilder() {
        return getQueueUserAclsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder addQueueUserAclsBuilder(
          int index) {
        return getQueueUserAclsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder> 
           getQueueUserAclsBuilderList() {
        return getQueueUserAclsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder> 
          getQueueUserAclsFieldBuilder() {
        if (queueUserAclsBuilder_ == null) {
          queueUserAclsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder>(
                  queueUserAcls_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          queueUserAcls_ = null;
        }
        return queueUserAclsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetQueueUserAclsInfoResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetQueueUserAclsInfoResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetQueueUserAclsInfoResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetQueueUserAclsInfoResponseProto>() {
      public GetQueueUserAclsInfoResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetQueueUserAclsInfoResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetQueueUserAclsInfoResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetQueueUserAclsInfoResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetNodesToLabelsRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetNodesToLabelsRequestProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetNodesToLabelsRequestProto}
   */
  public  static final class GetNodesToLabelsRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetNodesToLabelsRequestProto)
      GetNodesToLabelsRequestProtoOrBuilder {
    // Use GetNodesToLabelsRequestProto.newBuilder() to construct.
    private GetNodesToLabelsRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetNodesToLabelsRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetNodesToLabelsRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNodesToLabelsRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNodesToLabelsRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetNodesToLabelsRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetNodesToLabelsRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNodesToLabelsRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNodesToLabelsRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNodesToLabelsRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetNodesToLabelsRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetNodesToLabelsRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetNodesToLabelsRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetNodesToLabelsRequestProto>() {
      public GetNodesToLabelsRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetNodesToLabelsRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetNodesToLabelsRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetNodesToLabelsRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetNodesToLabelsResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetNodesToLabelsResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto> 
        getNodeToLabelsList();
    /**
     * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto getNodeToLabels(int index);
    /**
     * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
     */
    int getNodeToLabelsCount();
    /**
     * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProtoOrBuilder> 
        getNodeToLabelsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProtoOrBuilder getNodeToLabelsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetNodesToLabelsResponseProto}
   */
  public  static final class GetNodesToLabelsResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetNodesToLabelsResponseProto)
      GetNodesToLabelsResponseProtoOrBuilder {
    // Use GetNodesToLabelsResponseProto.newBuilder() to construct.
    private GetNodesToLabelsResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetNodesToLabelsResponseProto() {
      nodeToLabels_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetNodesToLabelsResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                nodeToLabels_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              nodeToLabels_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          nodeToLabels_ = java.util.Collections.unmodifiableList(nodeToLabels_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNodesToLabelsResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNodesToLabelsResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto.Builder.class);
    }

    public static final int NODETOLABELS_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto> nodeToLabels_;
    /**
     * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto> getNodeToLabelsList() {
      return nodeToLabels_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProtoOrBuilder> 
        getNodeToLabelsOrBuilderList() {
      return nodeToLabels_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
     */
    public int getNodeToLabelsCount() {
      return nodeToLabels_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto getNodeToLabels(int index) {
      return nodeToLabels_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProtoOrBuilder getNodeToLabelsOrBuilder(
        int index) {
      return nodeToLabels_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < nodeToLabels_.size(); i++) {
        output.writeMessage(1, nodeToLabels_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < nodeToLabels_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, nodeToLabels_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto) obj;

      boolean result = true;
      result = result && getNodeToLabelsList()
          .equals(other.getNodeToLabelsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getNodeToLabelsCount() > 0) {
        hash = (37 * hash) + NODETOLABELS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeToLabelsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetNodesToLabelsResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetNodesToLabelsResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNodesToLabelsResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNodesToLabelsResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNodeToLabelsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (nodeToLabelsBuilder_ == null) {
          nodeToLabels_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          nodeToLabelsBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNodesToLabelsResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (nodeToLabelsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            nodeToLabels_ = java.util.Collections.unmodifiableList(nodeToLabels_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.nodeToLabels_ = nodeToLabels_;
        } else {
          result.nodeToLabels_ = nodeToLabelsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto.getDefaultInstance()) return this;
        if (nodeToLabelsBuilder_ == null) {
          if (!other.nodeToLabels_.isEmpty()) {
            if (nodeToLabels_.isEmpty()) {
              nodeToLabels_ = other.nodeToLabels_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureNodeToLabelsIsMutable();
              nodeToLabels_.addAll(other.nodeToLabels_);
            }
            onChanged();
          }
        } else {
          if (!other.nodeToLabels_.isEmpty()) {
            if (nodeToLabelsBuilder_.isEmpty()) {
              nodeToLabelsBuilder_.dispose();
              nodeToLabelsBuilder_ = null;
              nodeToLabels_ = other.nodeToLabels_;
              bitField0_ = (bitField0_ & ~0x00000001);
              nodeToLabelsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getNodeToLabelsFieldBuilder() : null;
            } else {
              nodeToLabelsBuilder_.addAllMessages(other.nodeToLabels_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto> nodeToLabels_ =
        java.util.Collections.emptyList();
      private void ensureNodeToLabelsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          nodeToLabels_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto>(nodeToLabels_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProtoOrBuilder> nodeToLabelsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto> getNodeToLabelsList() {
        if (nodeToLabelsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(nodeToLabels_);
        } else {
          return nodeToLabelsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public int getNodeToLabelsCount() {
        if (nodeToLabelsBuilder_ == null) {
          return nodeToLabels_.size();
        } else {
          return nodeToLabelsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto getNodeToLabels(int index) {
        if (nodeToLabelsBuilder_ == null) {
          return nodeToLabels_.get(index);
        } else {
          return nodeToLabelsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public Builder setNodeToLabels(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto value) {
        if (nodeToLabelsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeToLabelsIsMutable();
          nodeToLabels_.set(index, value);
          onChanged();
        } else {
          nodeToLabelsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public Builder setNodeToLabels(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto.Builder builderForValue) {
        if (nodeToLabelsBuilder_ == null) {
          ensureNodeToLabelsIsMutable();
          nodeToLabels_.set(index, builderForValue.build());
          onChanged();
        } else {
          nodeToLabelsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public Builder addNodeToLabels(org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto value) {
        if (nodeToLabelsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeToLabelsIsMutable();
          nodeToLabels_.add(value);
          onChanged();
        } else {
          nodeToLabelsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public Builder addNodeToLabels(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto value) {
        if (nodeToLabelsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeToLabelsIsMutable();
          nodeToLabels_.add(index, value);
          onChanged();
        } else {
          nodeToLabelsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public Builder addNodeToLabels(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto.Builder builderForValue) {
        if (nodeToLabelsBuilder_ == null) {
          ensureNodeToLabelsIsMutable();
          nodeToLabels_.add(builderForValue.build());
          onChanged();
        } else {
          nodeToLabelsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public Builder addNodeToLabels(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto.Builder builderForValue) {
        if (nodeToLabelsBuilder_ == null) {
          ensureNodeToLabelsIsMutable();
          nodeToLabels_.add(index, builderForValue.build());
          onChanged();
        } else {
          nodeToLabelsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public Builder addAllNodeToLabels(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto> values) {
        if (nodeToLabelsBuilder_ == null) {
          ensureNodeToLabelsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, nodeToLabels_);
          onChanged();
        } else {
          nodeToLabelsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public Builder clearNodeToLabels() {
        if (nodeToLabelsBuilder_ == null) {
          nodeToLabels_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          nodeToLabelsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public Builder removeNodeToLabels(int index) {
        if (nodeToLabelsBuilder_ == null) {
          ensureNodeToLabelsIsMutable();
          nodeToLabels_.remove(index);
          onChanged();
        } else {
          nodeToLabelsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto.Builder getNodeToLabelsBuilder(
          int index) {
        return getNodeToLabelsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProtoOrBuilder getNodeToLabelsOrBuilder(
          int index) {
        if (nodeToLabelsBuilder_ == null) {
          return nodeToLabels_.get(index);  } else {
          return nodeToLabelsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProtoOrBuilder> 
           getNodeToLabelsOrBuilderList() {
        if (nodeToLabelsBuilder_ != null) {
          return nodeToLabelsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(nodeToLabels_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto.Builder addNodeToLabelsBuilder() {
        return getNodeToLabelsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto.Builder addNodeToLabelsBuilder(
          int index) {
        return getNodeToLabelsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdToLabelsInfoProto nodeToLabels = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto.Builder> 
           getNodeToLabelsBuilderList() {
        return getNodeToLabelsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProtoOrBuilder> 
          getNodeToLabelsFieldBuilder() {
        if (nodeToLabelsBuilder_ == null) {
          nodeToLabelsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsInfoProtoOrBuilder>(
                  nodeToLabels_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          nodeToLabels_ = null;
        }
        return nodeToLabelsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetNodesToLabelsResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetNodesToLabelsResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetNodesToLabelsResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetNodesToLabelsResponseProto>() {
      public GetNodesToLabelsResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetNodesToLabelsResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetNodesToLabelsResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetNodesToLabelsResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNodesToLabelsResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetLabelsToNodesRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetLabelsToNodesRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated string nodeLabels = 1;</code>
     */
    java.util.List<java.lang.String>
        getNodeLabelsList();
    /**
     * <code>repeated string nodeLabels = 1;</code>
     */
    int getNodeLabelsCount();
    /**
     * <code>repeated string nodeLabels = 1;</code>
     */
    java.lang.String getNodeLabels(int index);
    /**
     * <code>repeated string nodeLabels = 1;</code>
     */
    com.google.protobuf.ByteString
        getNodeLabelsBytes(int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetLabelsToNodesRequestProto}
   */
  public  static final class GetLabelsToNodesRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetLabelsToNodesRequestProto)
      GetLabelsToNodesRequestProtoOrBuilder {
    // Use GetLabelsToNodesRequestProto.newBuilder() to construct.
    private GetLabelsToNodesRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetLabelsToNodesRequestProto() {
      nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetLabelsToNodesRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                nodeLabels_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000001;
              }
              nodeLabels_.add(bs);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          nodeLabels_ = nodeLabels_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetLabelsToNodesRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetLabelsToNodesRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto.Builder.class);
    }

    public static final int NODELABELS_FIELD_NUMBER = 1;
    private com.google.protobuf.LazyStringList nodeLabels_;
    /**
     * <code>repeated string nodeLabels = 1;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getNodeLabelsList() {
      return nodeLabels_;
    }
    /**
     * <code>repeated string nodeLabels = 1;</code>
     */
    public int getNodeLabelsCount() {
      return nodeLabels_.size();
    }
    /**
     * <code>repeated string nodeLabels = 1;</code>
     */
    public java.lang.String getNodeLabels(int index) {
      return nodeLabels_.get(index);
    }
    /**
     * <code>repeated string nodeLabels = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNodeLabelsBytes(int index) {
      return nodeLabels_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < nodeLabels_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, nodeLabels_.getRaw(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < nodeLabels_.size(); i++) {
          dataSize += computeStringSizeNoTag(nodeLabels_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getNodeLabelsList().size();
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto) obj;

      boolean result = true;
      result = result && getNodeLabelsList()
          .equals(other.getNodeLabelsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getNodeLabelsCount() > 0) {
        hash = (37 * hash) + NODELABELS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeLabelsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetLabelsToNodesRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetLabelsToNodesRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetLabelsToNodesRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetLabelsToNodesRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetLabelsToNodesRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto(this);
        int from_bitField0_ = bitField0_;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          nodeLabels_ = nodeLabels_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.nodeLabels_ = nodeLabels_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto.getDefaultInstance()) return this;
        if (!other.nodeLabels_.isEmpty()) {
          if (nodeLabels_.isEmpty()) {
            nodeLabels_ = other.nodeLabels_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureNodeLabelsIsMutable();
            nodeLabels_.addAll(other.nodeLabels_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private com.google.protobuf.LazyStringList nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureNodeLabelsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          nodeLabels_ = new com.google.protobuf.LazyStringArrayList(nodeLabels_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <code>repeated string nodeLabels = 1;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getNodeLabelsList() {
        return nodeLabels_.getUnmodifiableView();
      }
      /**
       * <code>repeated string nodeLabels = 1;</code>
       */
      public int getNodeLabelsCount() {
        return nodeLabels_.size();
      }
      /**
       * <code>repeated string nodeLabels = 1;</code>
       */
      public java.lang.String getNodeLabels(int index) {
        return nodeLabels_.get(index);
      }
      /**
       * <code>repeated string nodeLabels = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNodeLabelsBytes(int index) {
        return nodeLabels_.getByteString(index);
      }
      /**
       * <code>repeated string nodeLabels = 1;</code>
       */
      public Builder setNodeLabels(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureNodeLabelsIsMutable();
        nodeLabels_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string nodeLabels = 1;</code>
       */
      public Builder addNodeLabels(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureNodeLabelsIsMutable();
        nodeLabels_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string nodeLabels = 1;</code>
       */
      public Builder addAllNodeLabels(
          java.lang.Iterable<java.lang.String> values) {
        ensureNodeLabelsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, nodeLabels_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string nodeLabels = 1;</code>
       */
      public Builder clearNodeLabels() {
        nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string nodeLabels = 1;</code>
       */
      public Builder addNodeLabelsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureNodeLabelsIsMutable();
        nodeLabels_.add(value);
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetLabelsToNodesRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetLabelsToNodesRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetLabelsToNodesRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetLabelsToNodesRequestProto>() {
      public GetLabelsToNodesRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetLabelsToNodesRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetLabelsToNodesRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetLabelsToNodesRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetLabelsToNodesResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetLabelsToNodesResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto> 
        getLabelsToNodesList();
    /**
     * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto getLabelsToNodes(int index);
    /**
     * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
     */
    int getLabelsToNodesCount();
    /**
     * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProtoOrBuilder> 
        getLabelsToNodesOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProtoOrBuilder getLabelsToNodesOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetLabelsToNodesResponseProto}
   */
  public  static final class GetLabelsToNodesResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetLabelsToNodesResponseProto)
      GetLabelsToNodesResponseProtoOrBuilder {
    // Use GetLabelsToNodesResponseProto.newBuilder() to construct.
    private GetLabelsToNodesResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetLabelsToNodesResponseProto() {
      labelsToNodes_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetLabelsToNodesResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                labelsToNodes_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              labelsToNodes_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          labelsToNodes_ = java.util.Collections.unmodifiableList(labelsToNodes_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetLabelsToNodesResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetLabelsToNodesResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto.Builder.class);
    }

    public static final int LABELSTONODES_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto> labelsToNodes_;
    /**
     * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto> getLabelsToNodesList() {
      return labelsToNodes_;
    }
    /**
     * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProtoOrBuilder> 
        getLabelsToNodesOrBuilderList() {
      return labelsToNodes_;
    }
    /**
     * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
     */
    public int getLabelsToNodesCount() {
      return labelsToNodes_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto getLabelsToNodes(int index) {
      return labelsToNodes_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProtoOrBuilder getLabelsToNodesOrBuilder(
        int index) {
      return labelsToNodes_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < labelsToNodes_.size(); i++) {
        output.writeMessage(1, labelsToNodes_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < labelsToNodes_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, labelsToNodes_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto) obj;

      boolean result = true;
      result = result && getLabelsToNodesList()
          .equals(other.getLabelsToNodesList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getLabelsToNodesCount() > 0) {
        hash = (37 * hash) + LABELSTONODES_FIELD_NUMBER;
        hash = (53 * hash) + getLabelsToNodesList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetLabelsToNodesResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetLabelsToNodesResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetLabelsToNodesResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetLabelsToNodesResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getLabelsToNodesFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (labelsToNodesBuilder_ == null) {
          labelsToNodes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          labelsToNodesBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetLabelsToNodesResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (labelsToNodesBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            labelsToNodes_ = java.util.Collections.unmodifiableList(labelsToNodes_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.labelsToNodes_ = labelsToNodes_;
        } else {
          result.labelsToNodes_ = labelsToNodesBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto.getDefaultInstance()) return this;
        if (labelsToNodesBuilder_ == null) {
          if (!other.labelsToNodes_.isEmpty()) {
            if (labelsToNodes_.isEmpty()) {
              labelsToNodes_ = other.labelsToNodes_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureLabelsToNodesIsMutable();
              labelsToNodes_.addAll(other.labelsToNodes_);
            }
            onChanged();
          }
        } else {
          if (!other.labelsToNodes_.isEmpty()) {
            if (labelsToNodesBuilder_.isEmpty()) {
              labelsToNodesBuilder_.dispose();
              labelsToNodesBuilder_ = null;
              labelsToNodes_ = other.labelsToNodes_;
              bitField0_ = (bitField0_ & ~0x00000001);
              labelsToNodesBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getLabelsToNodesFieldBuilder() : null;
            } else {
              labelsToNodesBuilder_.addAllMessages(other.labelsToNodes_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto> labelsToNodes_ =
        java.util.Collections.emptyList();
      private void ensureLabelsToNodesIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          labelsToNodes_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto>(labelsToNodes_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProtoOrBuilder> labelsToNodesBuilder_;

      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto> getLabelsToNodesList() {
        if (labelsToNodesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(labelsToNodes_);
        } else {
          return labelsToNodesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public int getLabelsToNodesCount() {
        if (labelsToNodesBuilder_ == null) {
          return labelsToNodes_.size();
        } else {
          return labelsToNodesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto getLabelsToNodes(int index) {
        if (labelsToNodesBuilder_ == null) {
          return labelsToNodes_.get(index);
        } else {
          return labelsToNodesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public Builder setLabelsToNodes(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto value) {
        if (labelsToNodesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLabelsToNodesIsMutable();
          labelsToNodes_.set(index, value);
          onChanged();
        } else {
          labelsToNodesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public Builder setLabelsToNodes(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.Builder builderForValue) {
        if (labelsToNodesBuilder_ == null) {
          ensureLabelsToNodesIsMutable();
          labelsToNodes_.set(index, builderForValue.build());
          onChanged();
        } else {
          labelsToNodesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public Builder addLabelsToNodes(org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto value) {
        if (labelsToNodesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLabelsToNodesIsMutable();
          labelsToNodes_.add(value);
          onChanged();
        } else {
          labelsToNodesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public Builder addLabelsToNodes(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto value) {
        if (labelsToNodesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLabelsToNodesIsMutable();
          labelsToNodes_.add(index, value);
          onChanged();
        } else {
          labelsToNodesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public Builder addLabelsToNodes(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.Builder builderForValue) {
        if (labelsToNodesBuilder_ == null) {
          ensureLabelsToNodesIsMutable();
          labelsToNodes_.add(builderForValue.build());
          onChanged();
        } else {
          labelsToNodesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public Builder addLabelsToNodes(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.Builder builderForValue) {
        if (labelsToNodesBuilder_ == null) {
          ensureLabelsToNodesIsMutable();
          labelsToNodes_.add(index, builderForValue.build());
          onChanged();
        } else {
          labelsToNodesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public Builder addAllLabelsToNodes(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto> values) {
        if (labelsToNodesBuilder_ == null) {
          ensureLabelsToNodesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, labelsToNodes_);
          onChanged();
        } else {
          labelsToNodesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public Builder clearLabelsToNodes() {
        if (labelsToNodesBuilder_ == null) {
          labelsToNodes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          labelsToNodesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public Builder removeLabelsToNodes(int index) {
        if (labelsToNodesBuilder_ == null) {
          ensureLabelsToNodesIsMutable();
          labelsToNodes_.remove(index);
          onChanged();
        } else {
          labelsToNodesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.Builder getLabelsToNodesBuilder(
          int index) {
        return getLabelsToNodesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProtoOrBuilder getLabelsToNodesOrBuilder(
          int index) {
        if (labelsToNodesBuilder_ == null) {
          return labelsToNodes_.get(index);  } else {
          return labelsToNodesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProtoOrBuilder> 
           getLabelsToNodesOrBuilderList() {
        if (labelsToNodesBuilder_ != null) {
          return labelsToNodesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(labelsToNodes_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.Builder addLabelsToNodesBuilder() {
        return getLabelsToNodesFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.Builder addLabelsToNodesBuilder(
          int index) {
        return getLabelsToNodesFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.LabelsToNodeIdsProto labelsToNodes = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.Builder> 
           getLabelsToNodesBuilderList() {
        return getLabelsToNodesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProtoOrBuilder> 
          getLabelsToNodesFieldBuilder() {
        if (labelsToNodesBuilder_ == null) {
          labelsToNodesBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProtoOrBuilder>(
                  labelsToNodes_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          labelsToNodes_ = null;
        }
        return labelsToNodesBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetLabelsToNodesResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetLabelsToNodesResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetLabelsToNodesResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetLabelsToNodesResponseProto>() {
      public GetLabelsToNodesResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetLabelsToNodesResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetLabelsToNodesResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetLabelsToNodesResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetLabelsToNodesResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetClusterNodeLabelsRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetClusterNodeLabelsRequestProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetClusterNodeLabelsRequestProto}
   */
  public  static final class GetClusterNodeLabelsRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetClusterNodeLabelsRequestProto)
      GetClusterNodeLabelsRequestProtoOrBuilder {
    // Use GetClusterNodeLabelsRequestProto.newBuilder() to construct.
    private GetClusterNodeLabelsRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetClusterNodeLabelsRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetClusterNodeLabelsRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodeLabelsRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodeLabelsRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetClusterNodeLabelsRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetClusterNodeLabelsRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodeLabelsRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodeLabelsRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodeLabelsRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetClusterNodeLabelsRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetClusterNodeLabelsRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetClusterNodeLabelsRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetClusterNodeLabelsRequestProto>() {
      public GetClusterNodeLabelsRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetClusterNodeLabelsRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetClusterNodeLabelsRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetClusterNodeLabelsRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetClusterNodeLabelsResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetClusterNodeLabelsResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto> 
        getNodeLabelsList();
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto getNodeLabels(int index);
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    int getNodeLabelsCount();
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder> 
        getNodeLabelsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder getNodeLabelsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetClusterNodeLabelsResponseProto}
   */
  public  static final class GetClusterNodeLabelsResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetClusterNodeLabelsResponseProto)
      GetClusterNodeLabelsResponseProtoOrBuilder {
    // Use GetClusterNodeLabelsResponseProto.newBuilder() to construct.
    private GetClusterNodeLabelsResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetClusterNodeLabelsResponseProto() {
      nodeLabels_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetClusterNodeLabelsResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                nodeLabels_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              nodeLabels_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          nodeLabels_ = java.util.Collections.unmodifiableList(nodeLabels_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodeLabelsResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodeLabelsResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto.Builder.class);
    }

    public static final int NODELABELS_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto> nodeLabels_;
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto> getNodeLabelsList() {
      return nodeLabels_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder> 
        getNodeLabelsOrBuilderList() {
      return nodeLabels_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    public int getNodeLabelsCount() {
      return nodeLabels_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto getNodeLabels(int index) {
      return nodeLabels_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder getNodeLabelsOrBuilder(
        int index) {
      return nodeLabels_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < nodeLabels_.size(); i++) {
        output.writeMessage(1, nodeLabels_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < nodeLabels_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, nodeLabels_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto) obj;

      boolean result = true;
      result = result && getNodeLabelsList()
          .equals(other.getNodeLabelsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getNodeLabelsCount() > 0) {
        hash = (37 * hash) + NODELABELS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeLabelsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetClusterNodeLabelsResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetClusterNodeLabelsResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodeLabelsResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodeLabelsResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNodeLabelsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (nodeLabelsBuilder_ == null) {
          nodeLabels_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          nodeLabelsBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetClusterNodeLabelsResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (nodeLabelsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            nodeLabels_ = java.util.Collections.unmodifiableList(nodeLabels_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.nodeLabels_ = nodeLabels_;
        } else {
          result.nodeLabels_ = nodeLabelsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto.getDefaultInstance()) return this;
        if (nodeLabelsBuilder_ == null) {
          if (!other.nodeLabels_.isEmpty()) {
            if (nodeLabels_.isEmpty()) {
              nodeLabels_ = other.nodeLabels_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureNodeLabelsIsMutable();
              nodeLabels_.addAll(other.nodeLabels_);
            }
            onChanged();
          }
        } else {
          if (!other.nodeLabels_.isEmpty()) {
            if (nodeLabelsBuilder_.isEmpty()) {
              nodeLabelsBuilder_.dispose();
              nodeLabelsBuilder_ = null;
              nodeLabels_ = other.nodeLabels_;
              bitField0_ = (bitField0_ & ~0x00000001);
              nodeLabelsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getNodeLabelsFieldBuilder() : null;
            } else {
              nodeLabelsBuilder_.addAllMessages(other.nodeLabels_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto> nodeLabels_ =
        java.util.Collections.emptyList();
      private void ensureNodeLabelsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          nodeLabels_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto>(nodeLabels_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder> nodeLabelsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto> getNodeLabelsList() {
        if (nodeLabelsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(nodeLabels_);
        } else {
          return nodeLabelsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public int getNodeLabelsCount() {
        if (nodeLabelsBuilder_ == null) {
          return nodeLabels_.size();
        } else {
          return nodeLabelsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto getNodeLabels(int index) {
        if (nodeLabelsBuilder_ == null) {
          return nodeLabels_.get(index);
        } else {
          return nodeLabelsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder setNodeLabels(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto value) {
        if (nodeLabelsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeLabelsIsMutable();
          nodeLabels_.set(index, value);
          onChanged();
        } else {
          nodeLabelsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder setNodeLabels(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder builderForValue) {
        if (nodeLabelsBuilder_ == null) {
          ensureNodeLabelsIsMutable();
          nodeLabels_.set(index, builderForValue.build());
          onChanged();
        } else {
          nodeLabelsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder addNodeLabels(org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto value) {
        if (nodeLabelsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeLabelsIsMutable();
          nodeLabels_.add(value);
          onChanged();
        } else {
          nodeLabelsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder addNodeLabels(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto value) {
        if (nodeLabelsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeLabelsIsMutable();
          nodeLabels_.add(index, value);
          onChanged();
        } else {
          nodeLabelsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder addNodeLabels(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder builderForValue) {
        if (nodeLabelsBuilder_ == null) {
          ensureNodeLabelsIsMutable();
          nodeLabels_.add(builderForValue.build());
          onChanged();
        } else {
          nodeLabelsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder addNodeLabels(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder builderForValue) {
        if (nodeLabelsBuilder_ == null) {
          ensureNodeLabelsIsMutable();
          nodeLabels_.add(index, builderForValue.build());
          onChanged();
        } else {
          nodeLabelsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder addAllNodeLabels(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto> values) {
        if (nodeLabelsBuilder_ == null) {
          ensureNodeLabelsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, nodeLabels_);
          onChanged();
        } else {
          nodeLabelsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder clearNodeLabels() {
        if (nodeLabelsBuilder_ == null) {
          nodeLabels_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          nodeLabelsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder removeNodeLabels(int index) {
        if (nodeLabelsBuilder_ == null) {
          ensureNodeLabelsIsMutable();
          nodeLabels_.remove(index);
          onChanged();
        } else {
          nodeLabelsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder getNodeLabelsBuilder(
          int index) {
        return getNodeLabelsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder getNodeLabelsOrBuilder(
          int index) {
        if (nodeLabelsBuilder_ == null) {
          return nodeLabels_.get(index);  } else {
          return nodeLabelsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder> 
           getNodeLabelsOrBuilderList() {
        if (nodeLabelsBuilder_ != null) {
          return nodeLabelsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(nodeLabels_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder addNodeLabelsBuilder() {
        return getNodeLabelsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder addNodeLabelsBuilder(
          int index) {
        return getNodeLabelsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder> 
           getNodeLabelsBuilderList() {
        return getNodeLabelsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder> 
          getNodeLabelsFieldBuilder() {
        if (nodeLabelsBuilder_ == null) {
          nodeLabelsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder>(
                  nodeLabels_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          nodeLabels_ = null;
        }
        return nodeLabelsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetClusterNodeLabelsResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetClusterNodeLabelsResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetClusterNodeLabelsResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetClusterNodeLabelsResponseProto>() {
      public GetClusterNodeLabelsResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetClusterNodeLabelsResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetClusterNodeLabelsResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetClusterNodeLabelsResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodeLabelsResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface UpdateApplicationPriorityRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.UpdateApplicationPriorityRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>required .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>required .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();

    /**
     * <code>required .hadoop.yarn.PriorityProto applicationPriority = 2;</code>
     */
    boolean hasApplicationPriority();
    /**
     * <code>required .hadoop.yarn.PriorityProto applicationPriority = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto getApplicationPriority();
    /**
     * <code>required .hadoop.yarn.PriorityProto applicationPriority = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getApplicationPriorityOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.UpdateApplicationPriorityRequestProto}
   */
  public  static final class UpdateApplicationPriorityRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.UpdateApplicationPriorityRequestProto)
      UpdateApplicationPriorityRequestProtoOrBuilder {
    // Use UpdateApplicationPriorityRequestProto.newBuilder() to construct.
    private UpdateApplicationPriorityRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private UpdateApplicationPriorityRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private UpdateApplicationPriorityRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = applicationPriority_.toBuilder();
              }
              applicationPriority_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationPriority_);
                applicationPriority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UpdateApplicationPriorityRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UpdateApplicationPriorityRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATIONID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>required .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }
    /**
     * <code>required .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }

    public static final int APPLICATIONPRIORITY_FIELD_NUMBER = 2;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto applicationPriority_;
    /**
     * <code>required .hadoop.yarn.PriorityProto applicationPriority = 2;</code>
     */
    public boolean hasApplicationPriority() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hadoop.yarn.PriorityProto applicationPriority = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto getApplicationPriority() {
      return applicationPriority_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : applicationPriority_;
    }
    /**
     * <code>required .hadoop.yarn.PriorityProto applicationPriority = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getApplicationPriorityOrBuilder() {
      return applicationPriority_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : applicationPriority_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasApplicationId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasApplicationPriority()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getApplicationPriority());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getApplicationPriority());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasApplicationPriority() == other.hasApplicationPriority());
      if (hasApplicationPriority()) {
        result = result && getApplicationPriority()
            .equals(other.getApplicationPriority());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATIONID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasApplicationPriority()) {
        hash = (37 * hash) + APPLICATIONPRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationPriority().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.UpdateApplicationPriorityRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.UpdateApplicationPriorityRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UpdateApplicationPriorityRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UpdateApplicationPriorityRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
          getApplicationPriorityFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (applicationPriorityBuilder_ == null) {
          applicationPriority_ = null;
        } else {
          applicationPriorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UpdateApplicationPriorityRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (applicationPriorityBuilder_ == null) {
          result.applicationPriority_ = applicationPriority_;
        } else {
          result.applicationPriority_ = applicationPriorityBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasApplicationPriority()) {
          mergeApplicationPriority(other.getApplicationPriority());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasApplicationId()) {
          return false;
        }
        if (!hasApplicationPriority()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder setApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder setApplicationId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder mergeApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != null &&
              applicationId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        }
      }
      /**
       * <code>required .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  getApplicationId(),
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto applicationPriority_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> applicationPriorityBuilder_;
      /**
       * <code>required .hadoop.yarn.PriorityProto applicationPriority = 2;</code>
       */
      public boolean hasApplicationPriority() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hadoop.yarn.PriorityProto applicationPriority = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto getApplicationPriority() {
        if (applicationPriorityBuilder_ == null) {
          return applicationPriority_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : applicationPriority_;
        } else {
          return applicationPriorityBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hadoop.yarn.PriorityProto applicationPriority = 2;</code>
       */
      public Builder setApplicationPriority(org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (applicationPriorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationPriority_ = value;
          onChanged();
        } else {
          applicationPriorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hadoop.yarn.PriorityProto applicationPriority = 2;</code>
       */
      public Builder setApplicationPriority(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (applicationPriorityBuilder_ == null) {
          applicationPriority_ = builderForValue.build();
          onChanged();
        } else {
          applicationPriorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hadoop.yarn.PriorityProto applicationPriority = 2;</code>
       */
      public Builder mergeApplicationPriority(org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (applicationPriorityBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              applicationPriority_ != null &&
              applicationPriority_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            applicationPriority_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(applicationPriority_).mergeFrom(value).buildPartial();
          } else {
            applicationPriority_ = value;
          }
          onChanged();
        } else {
          applicationPriorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hadoop.yarn.PriorityProto applicationPriority = 2;</code>
       */
      public Builder clearApplicationPriority() {
        if (applicationPriorityBuilder_ == null) {
          applicationPriority_ = null;
          onChanged();
        } else {
          applicationPriorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hadoop.yarn.PriorityProto applicationPriority = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getApplicationPriorityBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getApplicationPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hadoop.yarn.PriorityProto applicationPriority = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getApplicationPriorityOrBuilder() {
        if (applicationPriorityBuilder_ != null) {
          return applicationPriorityBuilder_.getMessageOrBuilder();
        } else {
          return applicationPriority_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : applicationPriority_;
        }
      }
      /**
       * <code>required .hadoop.yarn.PriorityProto applicationPriority = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getApplicationPriorityFieldBuilder() {
        if (applicationPriorityBuilder_ == null) {
          applicationPriorityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  getApplicationPriority(),
                  getParentForChildren(),
                  isClean());
          applicationPriority_ = null;
        }
        return applicationPriorityBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.UpdateApplicationPriorityRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.UpdateApplicationPriorityRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<UpdateApplicationPriorityRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<UpdateApplicationPriorityRequestProto>() {
      public UpdateApplicationPriorityRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new UpdateApplicationPriorityRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<UpdateApplicationPriorityRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<UpdateApplicationPriorityRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface UpdateApplicationPriorityResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.UpdateApplicationPriorityResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.PriorityProto applicationPriority = 1;</code>
     */
    boolean hasApplicationPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto applicationPriority = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto getApplicationPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto applicationPriority = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getApplicationPriorityOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.UpdateApplicationPriorityResponseProto}
   */
  public  static final class UpdateApplicationPriorityResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.UpdateApplicationPriorityResponseProto)
      UpdateApplicationPriorityResponseProtoOrBuilder {
    // Use UpdateApplicationPriorityResponseProto.newBuilder() to construct.
    private UpdateApplicationPriorityResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private UpdateApplicationPriorityResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private UpdateApplicationPriorityResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationPriority_.toBuilder();
              }
              applicationPriority_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationPriority_);
                applicationPriority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UpdateApplicationPriorityResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UpdateApplicationPriorityResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATIONPRIORITY_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto applicationPriority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto applicationPriority = 1;</code>
     */
    public boolean hasApplicationPriority() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto applicationPriority = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto getApplicationPriority() {
      return applicationPriority_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : applicationPriority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto applicationPriority = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getApplicationPriorityOrBuilder() {
      return applicationPriority_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : applicationPriority_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationPriority());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationPriority());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto) obj;

      boolean result = true;
      result = result && (hasApplicationPriority() == other.hasApplicationPriority());
      if (hasApplicationPriority()) {
        result = result && getApplicationPriority()
            .equals(other.getApplicationPriority());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationPriority()) {
        hash = (37 * hash) + APPLICATIONPRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationPriority().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.UpdateApplicationPriorityResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.UpdateApplicationPriorityResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UpdateApplicationPriorityResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UpdateApplicationPriorityResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationPriorityFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationPriorityBuilder_ == null) {
          applicationPriority_ = null;
        } else {
          applicationPriorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UpdateApplicationPriorityResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationPriorityBuilder_ == null) {
          result.applicationPriority_ = applicationPriority_;
        } else {
          result.applicationPriority_ = applicationPriorityBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto.getDefaultInstance()) return this;
        if (other.hasApplicationPriority()) {
          mergeApplicationPriority(other.getApplicationPriority());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto applicationPriority_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> applicationPriorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto applicationPriority = 1;</code>
       */
      public boolean hasApplicationPriority() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto applicationPriority = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto getApplicationPriority() {
        if (applicationPriorityBuilder_ == null) {
          return applicationPriority_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : applicationPriority_;
        } else {
          return applicationPriorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto applicationPriority = 1;</code>
       */
      public Builder setApplicationPriority(org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (applicationPriorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationPriority_ = value;
          onChanged();
        } else {
          applicationPriorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto applicationPriority = 1;</code>
       */
      public Builder setApplicationPriority(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (applicationPriorityBuilder_ == null) {
          applicationPriority_ = builderForValue.build();
          onChanged();
        } else {
          applicationPriorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto applicationPriority = 1;</code>
       */
      public Builder mergeApplicationPriority(org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (applicationPriorityBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationPriority_ != null &&
              applicationPriority_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            applicationPriority_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(applicationPriority_).mergeFrom(value).buildPartial();
          } else {
            applicationPriority_ = value;
          }
          onChanged();
        } else {
          applicationPriorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto applicationPriority = 1;</code>
       */
      public Builder clearApplicationPriority() {
        if (applicationPriorityBuilder_ == null) {
          applicationPriority_ = null;
          onChanged();
        } else {
          applicationPriorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto applicationPriority = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getApplicationPriorityBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto applicationPriority = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getApplicationPriorityOrBuilder() {
        if (applicationPriorityBuilder_ != null) {
          return applicationPriorityBuilder_.getMessageOrBuilder();
        } else {
          return applicationPriority_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : applicationPriority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto applicationPriority = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getApplicationPriorityFieldBuilder() {
        if (applicationPriorityBuilder_ == null) {
          applicationPriorityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  getApplicationPriority(),
                  getParentForChildren(),
                  isClean());
          applicationPriority_ = null;
        }
        return applicationPriorityBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.UpdateApplicationPriorityResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.UpdateApplicationPriorityResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<UpdateApplicationPriorityResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<UpdateApplicationPriorityResponseProto>() {
      public UpdateApplicationPriorityResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new UpdateApplicationPriorityResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<UpdateApplicationPriorityResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<UpdateApplicationPriorityResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UpdateApplicationPriorityResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SignalContainerRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.SignalContainerRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>required .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>required .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    /**
     * <code>required .hadoop.yarn.SignalContainerCommandProto command = 2;</code>
     */
    boolean hasCommand();
    /**
     * <code>required .hadoop.yarn.SignalContainerCommandProto command = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.SignalContainerCommandProto getCommand();
  }
  /**
   * Protobuf type {@code hadoop.yarn.SignalContainerRequestProto}
   */
  public  static final class SignalContainerRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.SignalContainerRequestProto)
      SignalContainerRequestProtoOrBuilder {
    // Use SignalContainerRequestProto.newBuilder() to construct.
    private SignalContainerRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SignalContainerRequestProto() {
      command_ = 1;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SignalContainerRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.spiderdt.hadoop.yarn.proto.YarnProtos.SignalContainerCommandProto value = org.spiderdt.hadoop.yarn.proto.YarnProtos.SignalContainerCommandProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000002;
                command_ = rawValue;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SignalContainerRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SignalContainerRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>required .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }
    /**
     * <code>required .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }

    public static final int COMMAND_FIELD_NUMBER = 2;
    private int command_;
    /**
     * <code>required .hadoop.yarn.SignalContainerCommandProto command = 2;</code>
     */
    public boolean hasCommand() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hadoop.yarn.SignalContainerCommandProto command = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.SignalContainerCommandProto getCommand() {
      org.spiderdt.hadoop.yarn.proto.YarnProtos.SignalContainerCommandProto result = org.spiderdt.hadoop.yarn.proto.YarnProtos.SignalContainerCommandProto.valueOf(command_);
      return result == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.SignalContainerCommandProto.OUTPUT_THREAD_DUMP : result;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasContainerId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasCommand()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getContainerId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeEnum(2, command_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getContainerId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, command_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasCommand() == other.hasCommand());
      if (hasCommand()) {
        result = result && command_ == other.command_;
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasCommand()) {
        hash = (37 * hash) + COMMAND_FIELD_NUMBER;
        hash = (53 * hash) + command_;
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.SignalContainerRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.SignalContainerRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SignalContainerRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SignalContainerRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = null;
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        command_ = 1;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SignalContainerRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.command_ = command_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasCommand()) {
          setCommand(other.getCommand());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasContainerId()) {
          return false;
        }
        if (!hasCommand()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>required .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != null &&
              containerId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = null;
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        }
      }
      /**
       * <code>required .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  getContainerId(),
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      private int command_ = 1;
      /**
       * <code>required .hadoop.yarn.SignalContainerCommandProto command = 2;</code>
       */
      public boolean hasCommand() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hadoop.yarn.SignalContainerCommandProto command = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.SignalContainerCommandProto getCommand() {
        org.spiderdt.hadoop.yarn.proto.YarnProtos.SignalContainerCommandProto result = org.spiderdt.hadoop.yarn.proto.YarnProtos.SignalContainerCommandProto.valueOf(command_);
        return result == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.SignalContainerCommandProto.OUTPUT_THREAD_DUMP : result;
      }
      /**
       * <code>required .hadoop.yarn.SignalContainerCommandProto command = 2;</code>
       */
      public Builder setCommand(org.spiderdt.hadoop.yarn.proto.YarnProtos.SignalContainerCommandProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        command_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hadoop.yarn.SignalContainerCommandProto command = 2;</code>
       */
      public Builder clearCommand() {
        bitField0_ = (bitField0_ & ~0x00000002);
        command_ = 1;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.SignalContainerRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.SignalContainerRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<SignalContainerRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<SignalContainerRequestProto>() {
      public SignalContainerRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new SignalContainerRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<SignalContainerRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<SignalContainerRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SignalContainerResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.SignalContainerResponseProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.SignalContainerResponseProto}
   */
  public  static final class SignalContainerResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.SignalContainerResponseProto)
      SignalContainerResponseProtoOrBuilder {
    // Use SignalContainerResponseProto.newBuilder() to construct.
    private SignalContainerResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SignalContainerResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SignalContainerResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SignalContainerResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SignalContainerResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.SignalContainerResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.SignalContainerResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SignalContainerResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SignalContainerResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_SignalContainerResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.SignalContainerResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.SignalContainerResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<SignalContainerResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<SignalContainerResponseProto>() {
      public SignalContainerResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new SignalContainerResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<SignalContainerResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<SignalContainerResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.SignalContainerResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StartContainerRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.StartContainerRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;</code>
     */
    boolean hasContainerLaunchContext();
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getContainerLaunchContext();
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder getContainerLaunchContextOrBuilder();

    /**
     * <code>optional .hadoop.common.TokenProto container_token = 2;</code>
     */
    boolean hasContainerToken();
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 2;</code>
     */
    org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken();
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 2;</code>
     */
    org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.StartContainerRequestProto}
   */
  public  static final class StartContainerRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.StartContainerRequestProto)
      StartContainerRequestProtoOrBuilder {
    // Use StartContainerRequestProto.newBuilder() to construct.
    private StartContainerRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StartContainerRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private StartContainerRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerLaunchContext_.toBuilder();
              }
              containerLaunchContext_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerLaunchContext_);
                containerLaunchContext_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = containerToken_.toBuilder();
              }
              containerToken_ = input.readMessage(org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerToken_);
                containerToken_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainerRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainerRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int CONTAINER_LAUNCH_CONTEXT_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto containerLaunchContext_;
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;</code>
     */
    public boolean hasContainerLaunchContext() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getContainerLaunchContext() {
      return containerLaunchContext_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance() : containerLaunchContext_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder getContainerLaunchContextOrBuilder() {
      return containerLaunchContext_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance() : containerLaunchContext_;
    }

    public static final int CONTAINER_TOKEN_FIELD_NUMBER = 2;
    private org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto containerToken_;
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 2;</code>
     */
    public boolean hasContainerToken() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 2;</code>
     */
    public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken() {
      return containerToken_ == null ? org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : containerToken_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 2;</code>
     */
    public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder() {
      return containerToken_ == null ? org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : containerToken_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasContainerToken()) {
        if (!getContainerToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getContainerLaunchContext());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getContainerToken());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getContainerLaunchContext());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getContainerToken());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto) obj;

      boolean result = true;
      result = result && (hasContainerLaunchContext() == other.hasContainerLaunchContext());
      if (hasContainerLaunchContext()) {
        result = result && getContainerLaunchContext()
            .equals(other.getContainerLaunchContext());
      }
      result = result && (hasContainerToken() == other.hasContainerToken());
      if (hasContainerToken()) {
        result = result && getContainerToken()
            .equals(other.getContainerToken());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerLaunchContext()) {
        hash = (37 * hash) + CONTAINER_LAUNCH_CONTEXT_FIELD_NUMBER;
        hash = (53 * hash) + getContainerLaunchContext().hashCode();
      }
      if (hasContainerToken()) {
        hash = (37 * hash) + CONTAINER_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getContainerToken().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StartContainerRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.StartContainerRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainerRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainerRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainerLaunchContextFieldBuilder();
          getContainerTokenFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containerLaunchContextBuilder_ == null) {
          containerLaunchContext_ = null;
        } else {
          containerLaunchContextBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (containerTokenBuilder_ == null) {
          containerToken_ = null;
        } else {
          containerTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainerRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerLaunchContextBuilder_ == null) {
          result.containerLaunchContext_ = containerLaunchContext_;
        } else {
          result.containerLaunchContext_ = containerLaunchContextBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (containerTokenBuilder_ == null) {
          result.containerToken_ = containerToken_;
        } else {
          result.containerToken_ = containerTokenBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.getDefaultInstance()) return this;
        if (other.hasContainerLaunchContext()) {
          mergeContainerLaunchContext(other.getContainerLaunchContext());
        }
        if (other.hasContainerToken()) {
          mergeContainerToken(other.getContainerToken());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (hasContainerToken()) {
          if (!getContainerToken().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto containerLaunchContext_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder> containerLaunchContextBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;</code>
       */
      public boolean hasContainerLaunchContext() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getContainerLaunchContext() {
        if (containerLaunchContextBuilder_ == null) {
          return containerLaunchContext_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance() : containerLaunchContext_;
        } else {
          return containerLaunchContextBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;</code>
       */
      public Builder setContainerLaunchContext(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto value) {
        if (containerLaunchContextBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerLaunchContext_ = value;
          onChanged();
        } else {
          containerLaunchContextBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;</code>
       */
      public Builder setContainerLaunchContext(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder builderForValue) {
        if (containerLaunchContextBuilder_ == null) {
          containerLaunchContext_ = builderForValue.build();
          onChanged();
        } else {
          containerLaunchContextBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;</code>
       */
      public Builder mergeContainerLaunchContext(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto value) {
        if (containerLaunchContextBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerLaunchContext_ != null &&
              containerLaunchContext_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance()) {
            containerLaunchContext_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.newBuilder(containerLaunchContext_).mergeFrom(value).buildPartial();
          } else {
            containerLaunchContext_ = value;
          }
          onChanged();
        } else {
          containerLaunchContextBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;</code>
       */
      public Builder clearContainerLaunchContext() {
        if (containerLaunchContextBuilder_ == null) {
          containerLaunchContext_ = null;
          onChanged();
        } else {
          containerLaunchContextBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder getContainerLaunchContextBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerLaunchContextFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder getContainerLaunchContextOrBuilder() {
        if (containerLaunchContextBuilder_ != null) {
          return containerLaunchContextBuilder_.getMessageOrBuilder();
        } else {
          return containerLaunchContext_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance() : containerLaunchContext_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder> 
          getContainerLaunchContextFieldBuilder() {
        if (containerLaunchContextBuilder_ == null) {
          containerLaunchContextBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder>(
                  getContainerLaunchContext(),
                  getParentForChildren(),
                  isClean());
          containerLaunchContext_ = null;
        }
        return containerLaunchContextBuilder_;
      }

      private org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto containerToken_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> containerTokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 2;</code>
       */
      public boolean hasContainerToken() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 2;</code>
       */
      public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken() {
        if (containerTokenBuilder_ == null) {
          return containerToken_ == null ? org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : containerToken_;
        } else {
          return containerTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 2;</code>
       */
      public Builder setContainerToken(org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (containerTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerToken_ = value;
          onChanged();
        } else {
          containerTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 2;</code>
       */
      public Builder setContainerToken(
          org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (containerTokenBuilder_ == null) {
          containerToken_ = builderForValue.build();
          onChanged();
        } else {
          containerTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 2;</code>
       */
      public Builder mergeContainerToken(org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (containerTokenBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              containerToken_ != null &&
              containerToken_ != org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            containerToken_ =
              org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(containerToken_).mergeFrom(value).buildPartial();
          } else {
            containerToken_ = value;
          }
          onChanged();
        } else {
          containerTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 2;</code>
       */
      public Builder clearContainerToken() {
        if (containerTokenBuilder_ == null) {
          containerToken_ = null;
          onChanged();
        } else {
          containerTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 2;</code>
       */
      public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder getContainerTokenBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getContainerTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 2;</code>
       */
      public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder() {
        if (containerTokenBuilder_ != null) {
          return containerTokenBuilder_.getMessageOrBuilder();
        } else {
          return containerToken_ == null ?
              org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : containerToken_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getContainerTokenFieldBuilder() {
        if (containerTokenBuilder_ == null) {
          containerTokenBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  getContainerToken(),
                  getParentForChildren(),
                  isClean());
          containerToken_ = null;
        }
        return containerTokenBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StartContainerRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StartContainerRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<StartContainerRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<StartContainerRequestProto>() {
      public StartContainerRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StartContainerRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StartContainerRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StartContainerRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StartContainerResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.StartContainerResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> 
        getServicesMetaDataList();
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServicesMetaData(int index);
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    int getServicesMetaDataCount();
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
        getServicesMetaDataOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServicesMetaDataOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.StartContainerResponseProto}
   */
  public  static final class StartContainerResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.StartContainerResponseProto)
      StartContainerResponseProtoOrBuilder {
    // Use StartContainerResponseProto.newBuilder() to construct.
    private StartContainerResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StartContainerResponseProto() {
      servicesMetaData_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private StartContainerResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                servicesMetaData_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              servicesMetaData_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          servicesMetaData_ = java.util.Collections.unmodifiableList(servicesMetaData_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainerResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainerResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto.Builder.class);
    }

    public static final int SERVICES_META_DATA_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> servicesMetaData_;
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> getServicesMetaDataList() {
      return servicesMetaData_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
        getServicesMetaDataOrBuilderList() {
      return servicesMetaData_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    public int getServicesMetaDataCount() {
      return servicesMetaData_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServicesMetaData(int index) {
      return servicesMetaData_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServicesMetaDataOrBuilder(
        int index) {
      return servicesMetaData_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < servicesMetaData_.size(); i++) {
        output.writeMessage(1, servicesMetaData_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < servicesMetaData_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, servicesMetaData_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto) obj;

      boolean result = true;
      result = result && getServicesMetaDataList()
          .equals(other.getServicesMetaDataList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getServicesMetaDataCount() > 0) {
        hash = (37 * hash) + SERVICES_META_DATA_FIELD_NUMBER;
        hash = (53 * hash) + getServicesMetaDataList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StartContainerResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.StartContainerResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainerResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainerResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getServicesMetaDataFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (servicesMetaDataBuilder_ == null) {
          servicesMetaData_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          servicesMetaDataBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainerResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (servicesMetaDataBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            servicesMetaData_ = java.util.Collections.unmodifiableList(servicesMetaData_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.servicesMetaData_ = servicesMetaData_;
        } else {
          result.servicesMetaData_ = servicesMetaDataBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto.getDefaultInstance()) return this;
        if (servicesMetaDataBuilder_ == null) {
          if (!other.servicesMetaData_.isEmpty()) {
            if (servicesMetaData_.isEmpty()) {
              servicesMetaData_ = other.servicesMetaData_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureServicesMetaDataIsMutable();
              servicesMetaData_.addAll(other.servicesMetaData_);
            }
            onChanged();
          }
        } else {
          if (!other.servicesMetaData_.isEmpty()) {
            if (servicesMetaDataBuilder_.isEmpty()) {
              servicesMetaDataBuilder_.dispose();
              servicesMetaDataBuilder_ = null;
              servicesMetaData_ = other.servicesMetaData_;
              bitField0_ = (bitField0_ & ~0x00000001);
              servicesMetaDataBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getServicesMetaDataFieldBuilder() : null;
            } else {
              servicesMetaDataBuilder_.addAllMessages(other.servicesMetaData_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> servicesMetaData_ =
        java.util.Collections.emptyList();
      private void ensureServicesMetaDataIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          servicesMetaData_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto>(servicesMetaData_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> servicesMetaDataBuilder_;

      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> getServicesMetaDataList() {
        if (servicesMetaDataBuilder_ == null) {
          return java.util.Collections.unmodifiableList(servicesMetaData_);
        } else {
          return servicesMetaDataBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public int getServicesMetaDataCount() {
        if (servicesMetaDataBuilder_ == null) {
          return servicesMetaData_.size();
        } else {
          return servicesMetaDataBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServicesMetaData(int index) {
        if (servicesMetaDataBuilder_ == null) {
          return servicesMetaData_.get(index);
        } else {
          return servicesMetaDataBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder setServicesMetaData(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (servicesMetaDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServicesMetaDataIsMutable();
          servicesMetaData_.set(index, value);
          onChanged();
        } else {
          servicesMetaDataBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder setServicesMetaData(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (servicesMetaDataBuilder_ == null) {
          ensureServicesMetaDataIsMutable();
          servicesMetaData_.set(index, builderForValue.build());
          onChanged();
        } else {
          servicesMetaDataBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder addServicesMetaData(org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (servicesMetaDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServicesMetaDataIsMutable();
          servicesMetaData_.add(value);
          onChanged();
        } else {
          servicesMetaDataBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder addServicesMetaData(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (servicesMetaDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServicesMetaDataIsMutable();
          servicesMetaData_.add(index, value);
          onChanged();
        } else {
          servicesMetaDataBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder addServicesMetaData(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (servicesMetaDataBuilder_ == null) {
          ensureServicesMetaDataIsMutable();
          servicesMetaData_.add(builderForValue.build());
          onChanged();
        } else {
          servicesMetaDataBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder addServicesMetaData(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (servicesMetaDataBuilder_ == null) {
          ensureServicesMetaDataIsMutable();
          servicesMetaData_.add(index, builderForValue.build());
          onChanged();
        } else {
          servicesMetaDataBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder addAllServicesMetaData(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> values) {
        if (servicesMetaDataBuilder_ == null) {
          ensureServicesMetaDataIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, servicesMetaData_);
          onChanged();
        } else {
          servicesMetaDataBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder clearServicesMetaData() {
        if (servicesMetaDataBuilder_ == null) {
          servicesMetaData_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          servicesMetaDataBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder removeServicesMetaData(int index) {
        if (servicesMetaDataBuilder_ == null) {
          ensureServicesMetaDataIsMutable();
          servicesMetaData_.remove(index);
          onChanged();
        } else {
          servicesMetaDataBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder getServicesMetaDataBuilder(
          int index) {
        return getServicesMetaDataFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServicesMetaDataOrBuilder(
          int index) {
        if (servicesMetaDataBuilder_ == null) {
          return servicesMetaData_.get(index);  } else {
          return servicesMetaDataBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
           getServicesMetaDataOrBuilderList() {
        if (servicesMetaDataBuilder_ != null) {
          return servicesMetaDataBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(servicesMetaData_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder addServicesMetaDataBuilder() {
        return getServicesMetaDataFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder addServicesMetaDataBuilder(
          int index) {
        return getServicesMetaDataFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder> 
           getServicesMetaDataBuilderList() {
        return getServicesMetaDataFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
          getServicesMetaDataFieldBuilder() {
        if (servicesMetaDataBuilder_ == null) {
          servicesMetaDataBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder>(
                  servicesMetaData_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          servicesMetaData_ = null;
        }
        return servicesMetaDataBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StartContainerResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StartContainerResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<StartContainerResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<StartContainerResponseProto>() {
      public StartContainerResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StartContainerResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StartContainerResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StartContainerResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StopContainerRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.StopContainerRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.StopContainerRequestProto}
   */
  public  static final class StopContainerRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.StopContainerRequestProto)
      StopContainerRequestProtoOrBuilder {
    // Use StopContainerRequestProto.newBuilder() to construct.
    private StopContainerRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StopContainerRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private StopContainerRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainerRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainerRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getContainerId());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getContainerId());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StopContainerRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.StopContainerRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainerRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainerRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = null;
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainerRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != null &&
              containerId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = null;
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  getContainerId(),
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StopContainerRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StopContainerRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<StopContainerRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<StopContainerRequestProto>() {
      public StopContainerRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StopContainerRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StopContainerRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StopContainerRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StopContainerResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.StopContainerResponseProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.StopContainerResponseProto}
   */
  public  static final class StopContainerResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.StopContainerResponseProto)
      StopContainerResponseProtoOrBuilder {
    // Use StopContainerResponseProto.newBuilder() to construct.
    private StopContainerResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StopContainerResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private StopContainerResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainerResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainerResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StopContainerResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.StopContainerResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainerResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainerResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainerResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StopContainerResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StopContainerResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<StopContainerResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<StopContainerResponseProto>() {
      public StopContainerResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StopContainerResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StopContainerResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StopContainerResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ResourceLocalizationRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ResourceLocalizationRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> 
        getLocalResourcesList();
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getLocalResources(int index);
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
     */
    int getLocalResourcesCount();
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
        getLocalResourcesOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder getLocalResourcesOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.ResourceLocalizationRequestProto}
   */
  public  static final class ResourceLocalizationRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ResourceLocalizationRequestProto)
      ResourceLocalizationRequestProtoOrBuilder {
    // Use ResourceLocalizationRequestProto.newBuilder() to construct.
    private ResourceLocalizationRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ResourceLocalizationRequestProto() {
      localResources_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceLocalizationRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                localResources_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto>();
                mutable_bitField0_ |= 0x00000002;
              }
              localResources_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          localResources_ = java.util.Collections.unmodifiableList(localResources_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ResourceLocalizationRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ResourceLocalizationRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }

    public static final int LOCAL_RESOURCES_FIELD_NUMBER = 2;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> localResources_;
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> getLocalResourcesList() {
      return localResources_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
        getLocalResourcesOrBuilderList() {
      return localResources_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
     */
    public int getLocalResourcesCount() {
      return localResources_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getLocalResources(int index) {
      return localResources_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder getLocalResourcesOrBuilder(
        int index) {
      return localResources_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getContainerId());
      }
      for (int i = 0; i < localResources_.size(); i++) {
        output.writeMessage(2, localResources_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getContainerId());
      }
      for (int i = 0; i < localResources_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, localResources_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && getLocalResourcesList()
          .equals(other.getLocalResourcesList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (getLocalResourcesCount() > 0) {
        hash = (37 * hash) + LOCAL_RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getLocalResourcesList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ResourceLocalizationRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ResourceLocalizationRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ResourceLocalizationRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ResourceLocalizationRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
          getLocalResourcesFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = null;
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (localResourcesBuilder_ == null) {
          localResources_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          localResourcesBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ResourceLocalizationRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (localResourcesBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            localResources_ = java.util.Collections.unmodifiableList(localResources_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.localResources_ = localResources_;
        } else {
          result.localResources_ = localResourcesBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (localResourcesBuilder_ == null) {
          if (!other.localResources_.isEmpty()) {
            if (localResources_.isEmpty()) {
              localResources_ = other.localResources_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureLocalResourcesIsMutable();
              localResources_.addAll(other.localResources_);
            }
            onChanged();
          }
        } else {
          if (!other.localResources_.isEmpty()) {
            if (localResourcesBuilder_.isEmpty()) {
              localResourcesBuilder_.dispose();
              localResourcesBuilder_ = null;
              localResources_ = other.localResources_;
              bitField0_ = (bitField0_ & ~0x00000002);
              localResourcesBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getLocalResourcesFieldBuilder() : null;
            } else {
              localResourcesBuilder_.addAllMessages(other.localResources_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != null &&
              containerId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = null;
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  getContainerId(),
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> localResources_ =
        java.util.Collections.emptyList();
      private void ensureLocalResourcesIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          localResources_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto>(localResources_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> localResourcesBuilder_;

      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> getLocalResourcesList() {
        if (localResourcesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(localResources_);
        } else {
          return localResourcesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public int getLocalResourcesCount() {
        if (localResourcesBuilder_ == null) {
          return localResources_.size();
        } else {
          return localResourcesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getLocalResources(int index) {
        if (localResourcesBuilder_ == null) {
          return localResources_.get(index);
        } else {
          return localResourcesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public Builder setLocalResources(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto value) {
        if (localResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLocalResourcesIsMutable();
          localResources_.set(index, value);
          onChanged();
        } else {
          localResourcesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public Builder setLocalResources(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder builderForValue) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.set(index, builderForValue.build());
          onChanged();
        } else {
          localResourcesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public Builder addLocalResources(org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto value) {
        if (localResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLocalResourcesIsMutable();
          localResources_.add(value);
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public Builder addLocalResources(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto value) {
        if (localResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLocalResourcesIsMutable();
          localResources_.add(index, value);
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public Builder addLocalResources(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder builderForValue) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.add(builderForValue.build());
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public Builder addLocalResources(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder builderForValue) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.add(index, builderForValue.build());
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public Builder addAllLocalResources(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> values) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, localResources_);
          onChanged();
        } else {
          localResourcesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public Builder clearLocalResources() {
        if (localResourcesBuilder_ == null) {
          localResources_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          localResourcesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public Builder removeLocalResources(int index) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.remove(index);
          onChanged();
        } else {
          localResourcesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder getLocalResourcesBuilder(
          int index) {
        return getLocalResourcesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder getLocalResourcesOrBuilder(
          int index) {
        if (localResourcesBuilder_ == null) {
          return localResources_.get(index);  } else {
          return localResourcesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
           getLocalResourcesOrBuilderList() {
        if (localResourcesBuilder_ != null) {
          return localResourcesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(localResources_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder addLocalResourcesBuilder() {
        return getLocalResourcesFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder addLocalResourcesBuilder(
          int index) {
        return getLocalResourcesFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto local_resources = 2;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder> 
           getLocalResourcesBuilderList() {
        return getLocalResourcesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
          getLocalResourcesFieldBuilder() {
        if (localResourcesBuilder_ == null) {
          localResourcesBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder>(
                  localResources_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          localResources_ = null;
        }
        return localResourcesBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceLocalizationRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceLocalizationRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ResourceLocalizationRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<ResourceLocalizationRequestProto>() {
      public ResourceLocalizationRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ResourceLocalizationRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ResourceLocalizationRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceLocalizationRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ResourceLocalizationResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ResourceLocalizationResponseProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.ResourceLocalizationResponseProto}
   */
  public  static final class ResourceLocalizationResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ResourceLocalizationResponseProto)
      ResourceLocalizationResponseProtoOrBuilder {
    // Use ResourceLocalizationResponseProto.newBuilder() to construct.
    private ResourceLocalizationResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ResourceLocalizationResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceLocalizationResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ResourceLocalizationResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ResourceLocalizationResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ResourceLocalizationResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ResourceLocalizationResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ResourceLocalizationResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ResourceLocalizationResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ResourceLocalizationResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceLocalizationResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceLocalizationResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ResourceLocalizationResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<ResourceLocalizationResponseProto>() {
      public ResourceLocalizationResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ResourceLocalizationResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ResourceLocalizationResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceLocalizationResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ResourceLocalizationResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StartContainersRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.StartContainersRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto> 
        getStartContainerRequestList();
    /**
     * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto getStartContainerRequest(int index);
    /**
     * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
     */
    int getStartContainerRequestCount();
    /**
     * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProtoOrBuilder> 
        getStartContainerRequestOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProtoOrBuilder getStartContainerRequestOrBuilder(
        int index);
  }
  /**
   * <pre>
   *&#47;/ bulk API records
   * </pre>
   *
   * Protobuf type {@code hadoop.yarn.StartContainersRequestProto}
   */
  public  static final class StartContainersRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.StartContainersRequestProto)
      StartContainersRequestProtoOrBuilder {
    // Use StartContainersRequestProto.newBuilder() to construct.
    private StartContainersRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StartContainersRequestProto() {
      startContainerRequest_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private StartContainersRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                startContainerRequest_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              startContainerRequest_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          startContainerRequest_ = java.util.Collections.unmodifiableList(startContainerRequest_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainersRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainersRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto.Builder.class);
    }

    public static final int START_CONTAINER_REQUEST_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto> startContainerRequest_;
    /**
     * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto> getStartContainerRequestList() {
      return startContainerRequest_;
    }
    /**
     * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProtoOrBuilder> 
        getStartContainerRequestOrBuilderList() {
      return startContainerRequest_;
    }
    /**
     * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
     */
    public int getStartContainerRequestCount() {
      return startContainerRequest_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto getStartContainerRequest(int index) {
      return startContainerRequest_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProtoOrBuilder getStartContainerRequestOrBuilder(
        int index) {
      return startContainerRequest_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getStartContainerRequestCount(); i++) {
        if (!getStartContainerRequest(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < startContainerRequest_.size(); i++) {
        output.writeMessage(1, startContainerRequest_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < startContainerRequest_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, startContainerRequest_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto) obj;

      boolean result = true;
      result = result && getStartContainerRequestList()
          .equals(other.getStartContainerRequestList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getStartContainerRequestCount() > 0) {
        hash = (37 * hash) + START_CONTAINER_REQUEST_FIELD_NUMBER;
        hash = (53 * hash) + getStartContainerRequestList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#47;/ bulk API records
     * </pre>
     *
     * Protobuf type {@code hadoop.yarn.StartContainersRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.StartContainersRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainersRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainersRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getStartContainerRequestFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (startContainerRequestBuilder_ == null) {
          startContainerRequest_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          startContainerRequestBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainersRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto(this);
        int from_bitField0_ = bitField0_;
        if (startContainerRequestBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            startContainerRequest_ = java.util.Collections.unmodifiableList(startContainerRequest_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.startContainerRequest_ = startContainerRequest_;
        } else {
          result.startContainerRequest_ = startContainerRequestBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto.getDefaultInstance()) return this;
        if (startContainerRequestBuilder_ == null) {
          if (!other.startContainerRequest_.isEmpty()) {
            if (startContainerRequest_.isEmpty()) {
              startContainerRequest_ = other.startContainerRequest_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureStartContainerRequestIsMutable();
              startContainerRequest_.addAll(other.startContainerRequest_);
            }
            onChanged();
          }
        } else {
          if (!other.startContainerRequest_.isEmpty()) {
            if (startContainerRequestBuilder_.isEmpty()) {
              startContainerRequestBuilder_.dispose();
              startContainerRequestBuilder_ = null;
              startContainerRequest_ = other.startContainerRequest_;
              bitField0_ = (bitField0_ & ~0x00000001);
              startContainerRequestBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getStartContainerRequestFieldBuilder() : null;
            } else {
              startContainerRequestBuilder_.addAllMessages(other.startContainerRequest_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getStartContainerRequestCount(); i++) {
          if (!getStartContainerRequest(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto> startContainerRequest_ =
        java.util.Collections.emptyList();
      private void ensureStartContainerRequestIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          startContainerRequest_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto>(startContainerRequest_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProtoOrBuilder> startContainerRequestBuilder_;

      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto> getStartContainerRequestList() {
        if (startContainerRequestBuilder_ == null) {
          return java.util.Collections.unmodifiableList(startContainerRequest_);
        } else {
          return startContainerRequestBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public int getStartContainerRequestCount() {
        if (startContainerRequestBuilder_ == null) {
          return startContainerRequest_.size();
        } else {
          return startContainerRequestBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto getStartContainerRequest(int index) {
        if (startContainerRequestBuilder_ == null) {
          return startContainerRequest_.get(index);
        } else {
          return startContainerRequestBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public Builder setStartContainerRequest(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto value) {
        if (startContainerRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStartContainerRequestIsMutable();
          startContainerRequest_.set(index, value);
          onChanged();
        } else {
          startContainerRequestBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public Builder setStartContainerRequest(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.Builder builderForValue) {
        if (startContainerRequestBuilder_ == null) {
          ensureStartContainerRequestIsMutable();
          startContainerRequest_.set(index, builderForValue.build());
          onChanged();
        } else {
          startContainerRequestBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public Builder addStartContainerRequest(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto value) {
        if (startContainerRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStartContainerRequestIsMutable();
          startContainerRequest_.add(value);
          onChanged();
        } else {
          startContainerRequestBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public Builder addStartContainerRequest(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto value) {
        if (startContainerRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStartContainerRequestIsMutable();
          startContainerRequest_.add(index, value);
          onChanged();
        } else {
          startContainerRequestBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public Builder addStartContainerRequest(
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.Builder builderForValue) {
        if (startContainerRequestBuilder_ == null) {
          ensureStartContainerRequestIsMutable();
          startContainerRequest_.add(builderForValue.build());
          onChanged();
        } else {
          startContainerRequestBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public Builder addStartContainerRequest(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.Builder builderForValue) {
        if (startContainerRequestBuilder_ == null) {
          ensureStartContainerRequestIsMutable();
          startContainerRequest_.add(index, builderForValue.build());
          onChanged();
        } else {
          startContainerRequestBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public Builder addAllStartContainerRequest(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto> values) {
        if (startContainerRequestBuilder_ == null) {
          ensureStartContainerRequestIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, startContainerRequest_);
          onChanged();
        } else {
          startContainerRequestBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public Builder clearStartContainerRequest() {
        if (startContainerRequestBuilder_ == null) {
          startContainerRequest_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          startContainerRequestBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public Builder removeStartContainerRequest(int index) {
        if (startContainerRequestBuilder_ == null) {
          ensureStartContainerRequestIsMutable();
          startContainerRequest_.remove(index);
          onChanged();
        } else {
          startContainerRequestBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.Builder getStartContainerRequestBuilder(
          int index) {
        return getStartContainerRequestFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProtoOrBuilder getStartContainerRequestOrBuilder(
          int index) {
        if (startContainerRequestBuilder_ == null) {
          return startContainerRequest_.get(index);  } else {
          return startContainerRequestBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProtoOrBuilder> 
           getStartContainerRequestOrBuilderList() {
        if (startContainerRequestBuilder_ != null) {
          return startContainerRequestBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(startContainerRequest_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.Builder addStartContainerRequestBuilder() {
        return getStartContainerRequestFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.Builder addStartContainerRequestBuilder(
          int index) {
        return getStartContainerRequestFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.Builder> 
           getStartContainerRequestBuilderList() {
        return getStartContainerRequestFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProtoOrBuilder> 
          getStartContainerRequestFieldBuilder() {
        if (startContainerRequestBuilder_ == null) {
          startContainerRequestBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProtoOrBuilder>(
                  startContainerRequest_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          startContainerRequest_ = null;
        }
        return startContainerRequestBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StartContainersRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StartContainersRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<StartContainersRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<StartContainersRequestProto>() {
      public StartContainersRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StartContainersRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StartContainersRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StartContainersRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ContainerExceptionMapProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ContainerExceptionMapProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto exception = 2;</code>
     */
    boolean hasException();
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto exception = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getException();
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto exception = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder getExceptionOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerExceptionMapProto}
   */
  public  static final class ContainerExceptionMapProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ContainerExceptionMapProto)
      ContainerExceptionMapProtoOrBuilder {
    // Use ContainerExceptionMapProto.newBuilder() to construct.
    private ContainerExceptionMapProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ContainerExceptionMapProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerExceptionMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = exception_.toBuilder();
              }
              exception_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(exception_);
                exception_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ContainerExceptionMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ContainerExceptionMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder.class);
    }

    private int bitField0_;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }

    public static final int EXCEPTION_FIELD_NUMBER = 2;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto exception_;
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto exception = 2;</code>
     */
    public boolean hasException() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto exception = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getException() {
      return exception_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance() : exception_;
    }
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto exception = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder getExceptionOrBuilder() {
      return exception_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance() : exception_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getContainerId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getException());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getContainerId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getException());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasException() == other.hasException());
      if (hasException()) {
        result = result && getException()
            .equals(other.getException());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasException()) {
        hash = (37 * hash) + EXCEPTION_FIELD_NUMBER;
        hash = (53 * hash) + getException().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerExceptionMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ContainerExceptionMapProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ContainerExceptionMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ContainerExceptionMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
          getExceptionFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = null;
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (exceptionBuilder_ == null) {
          exception_ = null;
        } else {
          exceptionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ContainerExceptionMapProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (exceptionBuilder_ == null) {
          result.exception_ = exception_;
        } else {
          result.exception_ = exceptionBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasException()) {
          mergeException(other.getException());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != null &&
              containerId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = null;
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  getContainerId(),
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto exception_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder> exceptionBuilder_;
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto exception = 2;</code>
       */
      public boolean hasException() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto exception = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getException() {
        if (exceptionBuilder_ == null) {
          return exception_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance() : exception_;
        } else {
          return exceptionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto exception = 2;</code>
       */
      public Builder setException(org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto value) {
        if (exceptionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          exception_ = value;
          onChanged();
        } else {
          exceptionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto exception = 2;</code>
       */
      public Builder setException(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder builderForValue) {
        if (exceptionBuilder_ == null) {
          exception_ = builderForValue.build();
          onChanged();
        } else {
          exceptionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto exception = 2;</code>
       */
      public Builder mergeException(org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto value) {
        if (exceptionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              exception_ != null &&
              exception_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance()) {
            exception_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.newBuilder(exception_).mergeFrom(value).buildPartial();
          } else {
            exception_ = value;
          }
          onChanged();
        } else {
          exceptionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto exception = 2;</code>
       */
      public Builder clearException() {
        if (exceptionBuilder_ == null) {
          exception_ = null;
          onChanged();
        } else {
          exceptionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto exception = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder getExceptionBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getExceptionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto exception = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder getExceptionOrBuilder() {
        if (exceptionBuilder_ != null) {
          return exceptionBuilder_.getMessageOrBuilder();
        } else {
          return exception_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance() : exception_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto exception = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder> 
          getExceptionFieldBuilder() {
        if (exceptionBuilder_ == null) {
          exceptionBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder>(
                  getException(),
                  getParentForChildren(),
                  isClean());
          exception_ = null;
        }
        return exceptionBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerExceptionMapProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerExceptionMapProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ContainerExceptionMapProto>
        PARSER = new com.google.protobuf.AbstractParser<ContainerExceptionMapProto>() {
      public ContainerExceptionMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ContainerExceptionMapProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ContainerExceptionMapProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerExceptionMapProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StartContainersResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.StartContainersResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> 
        getServicesMetaDataList();
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServicesMetaData(int index);
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    int getServicesMetaDataCount();
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
        getServicesMetaDataOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServicesMetaDataOrBuilder(
        int index);

    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> 
        getSucceededRequestsList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getSucceededRequests(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
     */
    int getSucceededRequestsCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getSucceededRequestsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getSucceededRequestsOrBuilder(
        int index);

    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> 
        getFailedRequestsList();
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto getFailedRequests(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
     */
    int getFailedRequestsCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
        getFailedRequestsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder getFailedRequestsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.StartContainersResponseProto}
   */
  public  static final class StartContainersResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.StartContainersResponseProto)
      StartContainersResponseProtoOrBuilder {
    // Use StartContainersResponseProto.newBuilder() to construct.
    private StartContainersResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StartContainersResponseProto() {
      servicesMetaData_ = java.util.Collections.emptyList();
      succeededRequests_ = java.util.Collections.emptyList();
      failedRequests_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private StartContainersResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                servicesMetaData_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              servicesMetaData_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.PARSER, extensionRegistry));
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                succeededRequests_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto>();
                mutable_bitField0_ |= 0x00000002;
              }
              succeededRequests_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry));
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                failedRequests_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto>();
                mutable_bitField0_ |= 0x00000004;
              }
              failedRequests_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          servicesMetaData_ = java.util.Collections.unmodifiableList(servicesMetaData_);
        }
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          succeededRequests_ = java.util.Collections.unmodifiableList(succeededRequests_);
        }
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          failedRequests_ = java.util.Collections.unmodifiableList(failedRequests_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainersResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainersResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto.Builder.class);
    }

    public static final int SERVICES_META_DATA_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> servicesMetaData_;
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> getServicesMetaDataList() {
      return servicesMetaData_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
        getServicesMetaDataOrBuilderList() {
      return servicesMetaData_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    public int getServicesMetaDataCount() {
      return servicesMetaData_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServicesMetaData(int index) {
      return servicesMetaData_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServicesMetaDataOrBuilder(
        int index) {
      return servicesMetaData_.get(index);
    }

    public static final int SUCCEEDED_REQUESTS_FIELD_NUMBER = 2;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> succeededRequests_;
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getSucceededRequestsList() {
      return succeededRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getSucceededRequestsOrBuilderList() {
      return succeededRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
     */
    public int getSucceededRequestsCount() {
      return succeededRequests_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getSucceededRequests(int index) {
      return succeededRequests_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getSucceededRequestsOrBuilder(
        int index) {
      return succeededRequests_.get(index);
    }

    public static final int FAILED_REQUESTS_FIELD_NUMBER = 3;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> failedRequests_;
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> getFailedRequestsList() {
      return failedRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
        getFailedRequestsOrBuilderList() {
      return failedRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
     */
    public int getFailedRequestsCount() {
      return failedRequests_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto getFailedRequests(int index) {
      return failedRequests_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder getFailedRequestsOrBuilder(
        int index) {
      return failedRequests_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < servicesMetaData_.size(); i++) {
        output.writeMessage(1, servicesMetaData_.get(i));
      }
      for (int i = 0; i < succeededRequests_.size(); i++) {
        output.writeMessage(2, succeededRequests_.get(i));
      }
      for (int i = 0; i < failedRequests_.size(); i++) {
        output.writeMessage(3, failedRequests_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < servicesMetaData_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, servicesMetaData_.get(i));
      }
      for (int i = 0; i < succeededRequests_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, succeededRequests_.get(i));
      }
      for (int i = 0; i < failedRequests_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, failedRequests_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto) obj;

      boolean result = true;
      result = result && getServicesMetaDataList()
          .equals(other.getServicesMetaDataList());
      result = result && getSucceededRequestsList()
          .equals(other.getSucceededRequestsList());
      result = result && getFailedRequestsList()
          .equals(other.getFailedRequestsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getServicesMetaDataCount() > 0) {
        hash = (37 * hash) + SERVICES_META_DATA_FIELD_NUMBER;
        hash = (53 * hash) + getServicesMetaDataList().hashCode();
      }
      if (getSucceededRequestsCount() > 0) {
        hash = (37 * hash) + SUCCEEDED_REQUESTS_FIELD_NUMBER;
        hash = (53 * hash) + getSucceededRequestsList().hashCode();
      }
      if (getFailedRequestsCount() > 0) {
        hash = (37 * hash) + FAILED_REQUESTS_FIELD_NUMBER;
        hash = (53 * hash) + getFailedRequestsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StartContainersResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.StartContainersResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainersResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainersResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getServicesMetaDataFieldBuilder();
          getSucceededRequestsFieldBuilder();
          getFailedRequestsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (servicesMetaDataBuilder_ == null) {
          servicesMetaData_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          servicesMetaDataBuilder_.clear();
        }
        if (succeededRequestsBuilder_ == null) {
          succeededRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          succeededRequestsBuilder_.clear();
        }
        if (failedRequestsBuilder_ == null) {
          failedRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          failedRequestsBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StartContainersResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (servicesMetaDataBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            servicesMetaData_ = java.util.Collections.unmodifiableList(servicesMetaData_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.servicesMetaData_ = servicesMetaData_;
        } else {
          result.servicesMetaData_ = servicesMetaDataBuilder_.build();
        }
        if (succeededRequestsBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            succeededRequests_ = java.util.Collections.unmodifiableList(succeededRequests_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.succeededRequests_ = succeededRequests_;
        } else {
          result.succeededRequests_ = succeededRequestsBuilder_.build();
        }
        if (failedRequestsBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            failedRequests_ = java.util.Collections.unmodifiableList(failedRequests_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.failedRequests_ = failedRequests_;
        } else {
          result.failedRequests_ = failedRequestsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto.getDefaultInstance()) return this;
        if (servicesMetaDataBuilder_ == null) {
          if (!other.servicesMetaData_.isEmpty()) {
            if (servicesMetaData_.isEmpty()) {
              servicesMetaData_ = other.servicesMetaData_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureServicesMetaDataIsMutable();
              servicesMetaData_.addAll(other.servicesMetaData_);
            }
            onChanged();
          }
        } else {
          if (!other.servicesMetaData_.isEmpty()) {
            if (servicesMetaDataBuilder_.isEmpty()) {
              servicesMetaDataBuilder_.dispose();
              servicesMetaDataBuilder_ = null;
              servicesMetaData_ = other.servicesMetaData_;
              bitField0_ = (bitField0_ & ~0x00000001);
              servicesMetaDataBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getServicesMetaDataFieldBuilder() : null;
            } else {
              servicesMetaDataBuilder_.addAllMessages(other.servicesMetaData_);
            }
          }
        }
        if (succeededRequestsBuilder_ == null) {
          if (!other.succeededRequests_.isEmpty()) {
            if (succeededRequests_.isEmpty()) {
              succeededRequests_ = other.succeededRequests_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureSucceededRequestsIsMutable();
              succeededRequests_.addAll(other.succeededRequests_);
            }
            onChanged();
          }
        } else {
          if (!other.succeededRequests_.isEmpty()) {
            if (succeededRequestsBuilder_.isEmpty()) {
              succeededRequestsBuilder_.dispose();
              succeededRequestsBuilder_ = null;
              succeededRequests_ = other.succeededRequests_;
              bitField0_ = (bitField0_ & ~0x00000002);
              succeededRequestsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getSucceededRequestsFieldBuilder() : null;
            } else {
              succeededRequestsBuilder_.addAllMessages(other.succeededRequests_);
            }
          }
        }
        if (failedRequestsBuilder_ == null) {
          if (!other.failedRequests_.isEmpty()) {
            if (failedRequests_.isEmpty()) {
              failedRequests_ = other.failedRequests_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureFailedRequestsIsMutable();
              failedRequests_.addAll(other.failedRequests_);
            }
            onChanged();
          }
        } else {
          if (!other.failedRequests_.isEmpty()) {
            if (failedRequestsBuilder_.isEmpty()) {
              failedRequestsBuilder_.dispose();
              failedRequestsBuilder_ = null;
              failedRequests_ = other.failedRequests_;
              bitField0_ = (bitField0_ & ~0x00000004);
              failedRequestsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getFailedRequestsFieldBuilder() : null;
            } else {
              failedRequestsBuilder_.addAllMessages(other.failedRequests_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> servicesMetaData_ =
        java.util.Collections.emptyList();
      private void ensureServicesMetaDataIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          servicesMetaData_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto>(servicesMetaData_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> servicesMetaDataBuilder_;

      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> getServicesMetaDataList() {
        if (servicesMetaDataBuilder_ == null) {
          return java.util.Collections.unmodifiableList(servicesMetaData_);
        } else {
          return servicesMetaDataBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public int getServicesMetaDataCount() {
        if (servicesMetaDataBuilder_ == null) {
          return servicesMetaData_.size();
        } else {
          return servicesMetaDataBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServicesMetaData(int index) {
        if (servicesMetaDataBuilder_ == null) {
          return servicesMetaData_.get(index);
        } else {
          return servicesMetaDataBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder setServicesMetaData(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (servicesMetaDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServicesMetaDataIsMutable();
          servicesMetaData_.set(index, value);
          onChanged();
        } else {
          servicesMetaDataBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder setServicesMetaData(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (servicesMetaDataBuilder_ == null) {
          ensureServicesMetaDataIsMutable();
          servicesMetaData_.set(index, builderForValue.build());
          onChanged();
        } else {
          servicesMetaDataBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder addServicesMetaData(org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (servicesMetaDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServicesMetaDataIsMutable();
          servicesMetaData_.add(value);
          onChanged();
        } else {
          servicesMetaDataBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder addServicesMetaData(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (servicesMetaDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServicesMetaDataIsMutable();
          servicesMetaData_.add(index, value);
          onChanged();
        } else {
          servicesMetaDataBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder addServicesMetaData(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (servicesMetaDataBuilder_ == null) {
          ensureServicesMetaDataIsMutable();
          servicesMetaData_.add(builderForValue.build());
          onChanged();
        } else {
          servicesMetaDataBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder addServicesMetaData(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (servicesMetaDataBuilder_ == null) {
          ensureServicesMetaDataIsMutable();
          servicesMetaData_.add(index, builderForValue.build());
          onChanged();
        } else {
          servicesMetaDataBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder addAllServicesMetaData(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> values) {
        if (servicesMetaDataBuilder_ == null) {
          ensureServicesMetaDataIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, servicesMetaData_);
          onChanged();
        } else {
          servicesMetaDataBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder clearServicesMetaData() {
        if (servicesMetaDataBuilder_ == null) {
          servicesMetaData_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          servicesMetaDataBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public Builder removeServicesMetaData(int index) {
        if (servicesMetaDataBuilder_ == null) {
          ensureServicesMetaDataIsMutable();
          servicesMetaData_.remove(index);
          onChanged();
        } else {
          servicesMetaDataBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder getServicesMetaDataBuilder(
          int index) {
        return getServicesMetaDataFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServicesMetaDataOrBuilder(
          int index) {
        if (servicesMetaDataBuilder_ == null) {
          return servicesMetaData_.get(index);  } else {
          return servicesMetaDataBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
           getServicesMetaDataOrBuilderList() {
        if (servicesMetaDataBuilder_ != null) {
          return servicesMetaDataBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(servicesMetaData_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder addServicesMetaDataBuilder() {
        return getServicesMetaDataFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder addServicesMetaDataBuilder(
          int index) {
        return getServicesMetaDataFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder> 
           getServicesMetaDataBuilderList() {
        return getServicesMetaDataFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
          getServicesMetaDataFieldBuilder() {
        if (servicesMetaDataBuilder_ == null) {
          servicesMetaDataBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder>(
                  servicesMetaData_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          servicesMetaData_ = null;
        }
        return servicesMetaDataBuilder_;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> succeededRequests_ =
        java.util.Collections.emptyList();
      private void ensureSucceededRequestsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          succeededRequests_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto>(succeededRequests_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> succeededRequestsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getSucceededRequestsList() {
        if (succeededRequestsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(succeededRequests_);
        } else {
          return succeededRequestsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public int getSucceededRequestsCount() {
        if (succeededRequestsBuilder_ == null) {
          return succeededRequests_.size();
        } else {
          return succeededRequestsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getSucceededRequests(int index) {
        if (succeededRequestsBuilder_ == null) {
          return succeededRequests_.get(index);
        } else {
          return succeededRequestsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public Builder setSucceededRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (succeededRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSucceededRequestsIsMutable();
          succeededRequests_.set(index, value);
          onChanged();
        } else {
          succeededRequestsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public Builder setSucceededRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (succeededRequestsBuilder_ == null) {
          ensureSucceededRequestsIsMutable();
          succeededRequests_.set(index, builderForValue.build());
          onChanged();
        } else {
          succeededRequestsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public Builder addSucceededRequests(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (succeededRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSucceededRequestsIsMutable();
          succeededRequests_.add(value);
          onChanged();
        } else {
          succeededRequestsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public Builder addSucceededRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (succeededRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSucceededRequestsIsMutable();
          succeededRequests_.add(index, value);
          onChanged();
        } else {
          succeededRequestsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public Builder addSucceededRequests(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (succeededRequestsBuilder_ == null) {
          ensureSucceededRequestsIsMutable();
          succeededRequests_.add(builderForValue.build());
          onChanged();
        } else {
          succeededRequestsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public Builder addSucceededRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (succeededRequestsBuilder_ == null) {
          ensureSucceededRequestsIsMutable();
          succeededRequests_.add(index, builderForValue.build());
          onChanged();
        } else {
          succeededRequestsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public Builder addAllSucceededRequests(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> values) {
        if (succeededRequestsBuilder_ == null) {
          ensureSucceededRequestsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, succeededRequests_);
          onChanged();
        } else {
          succeededRequestsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public Builder clearSucceededRequests() {
        if (succeededRequestsBuilder_ == null) {
          succeededRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          succeededRequestsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public Builder removeSucceededRequests(int index) {
        if (succeededRequestsBuilder_ == null) {
          ensureSucceededRequestsIsMutable();
          succeededRequests_.remove(index);
          onChanged();
        } else {
          succeededRequestsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getSucceededRequestsBuilder(
          int index) {
        return getSucceededRequestsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getSucceededRequestsOrBuilder(
          int index) {
        if (succeededRequestsBuilder_ == null) {
          return succeededRequests_.get(index);  } else {
          return succeededRequestsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
           getSucceededRequestsOrBuilderList() {
        if (succeededRequestsBuilder_ != null) {
          return succeededRequestsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(succeededRequests_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addSucceededRequestsBuilder() {
        return getSucceededRequestsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addSucceededRequestsBuilder(
          int index) {
        return getSucceededRequestsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder> 
           getSucceededRequestsBuilderList() {
        return getSucceededRequestsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getSucceededRequestsFieldBuilder() {
        if (succeededRequestsBuilder_ == null) {
          succeededRequestsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  succeededRequests_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          succeededRequests_ = null;
        }
        return succeededRequestsBuilder_;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> failedRequests_ =
        java.util.Collections.emptyList();
      private void ensureFailedRequestsIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          failedRequests_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto>(failedRequests_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> failedRequestsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> getFailedRequestsList() {
        if (failedRequestsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(failedRequests_);
        } else {
          return failedRequestsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public int getFailedRequestsCount() {
        if (failedRequestsBuilder_ == null) {
          return failedRequests_.size();
        } else {
          return failedRequestsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto getFailedRequests(int index) {
        if (failedRequestsBuilder_ == null) {
          return failedRequests_.get(index);
        } else {
          return failedRequestsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public Builder setFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto value) {
        if (failedRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFailedRequestsIsMutable();
          failedRequests_.set(index, value);
          onChanged();
        } else {
          failedRequestsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public Builder setFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder builderForValue) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.set(index, builderForValue.build());
          onChanged();
        } else {
          failedRequestsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public Builder addFailedRequests(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto value) {
        if (failedRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFailedRequestsIsMutable();
          failedRequests_.add(value);
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public Builder addFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto value) {
        if (failedRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFailedRequestsIsMutable();
          failedRequests_.add(index, value);
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public Builder addFailedRequests(
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder builderForValue) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.add(builderForValue.build());
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public Builder addFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder builderForValue) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.add(index, builderForValue.build());
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public Builder addAllFailedRequests(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> values) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, failedRequests_);
          onChanged();
        } else {
          failedRequestsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public Builder clearFailedRequests() {
        if (failedRequestsBuilder_ == null) {
          failedRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          failedRequestsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public Builder removeFailedRequests(int index) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.remove(index);
          onChanged();
        } else {
          failedRequestsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder getFailedRequestsBuilder(
          int index) {
        return getFailedRequestsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder getFailedRequestsOrBuilder(
          int index) {
        if (failedRequestsBuilder_ == null) {
          return failedRequests_.get(index);  } else {
          return failedRequestsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
           getFailedRequestsOrBuilderList() {
        if (failedRequestsBuilder_ != null) {
          return failedRequestsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(failedRequests_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder addFailedRequestsBuilder() {
        return getFailedRequestsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder addFailedRequestsBuilder(
          int index) {
        return getFailedRequestsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder> 
           getFailedRequestsBuilderList() {
        return getFailedRequestsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
          getFailedRequestsFieldBuilder() {
        if (failedRequestsBuilder_ == null) {
          failedRequestsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder>(
                  failedRequests_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          failedRequests_ = null;
        }
        return failedRequestsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StartContainersResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StartContainersResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<StartContainersResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<StartContainersResponseProto>() {
      public StartContainersResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StartContainersResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StartContainersResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StartContainersResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StartContainersResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StopContainersRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.StopContainersRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> 
        getContainerIdList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    int getContainerIdCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getContainerIdOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.StopContainersRequestProto}
   */
  public  static final class StopContainersRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.StopContainersRequestProto)
      StopContainersRequestProtoOrBuilder {
    // Use StopContainersRequestProto.newBuilder() to construct.
    private StopContainersRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StopContainersRequestProto() {
      containerId_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private StopContainersRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                containerId_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              containerId_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          containerId_ = java.util.Collections.unmodifiableList(containerId_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainersRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainersRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto.Builder.class);
    }

    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> containerId_;
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getContainerIdList() {
      return containerId_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getContainerIdOrBuilderList() {
      return containerId_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public int getContainerIdCount() {
      return containerId_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId(int index) {
      return containerId_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder(
        int index) {
      return containerId_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < containerId_.size(); i++) {
        output.writeMessage(1, containerId_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < containerId_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerId_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto) obj;

      boolean result = true;
      result = result && getContainerIdList()
          .equals(other.getContainerIdList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getContainerIdCount() > 0) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerIdList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StopContainersRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.StopContainersRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainersRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainersRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          containerIdBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainersRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto(this);
        int from_bitField0_ = bitField0_;
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            containerId_ = java.util.Collections.unmodifiableList(containerId_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto.getDefaultInstance()) return this;
        if (containerIdBuilder_ == null) {
          if (!other.containerId_.isEmpty()) {
            if (containerId_.isEmpty()) {
              containerId_ = other.containerId_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureContainerIdIsMutable();
              containerId_.addAll(other.containerId_);
            }
            onChanged();
          }
        } else {
          if (!other.containerId_.isEmpty()) {
            if (containerIdBuilder_.isEmpty()) {
              containerIdBuilder_.dispose();
              containerIdBuilder_ = null;
              containerId_ = other.containerId_;
              bitField0_ = (bitField0_ & ~0x00000001);
              containerIdBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getContainerIdFieldBuilder() : null;
            } else {
              containerIdBuilder_.addAllMessages(other.containerId_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> containerId_ =
        java.util.Collections.emptyList();
      private void ensureContainerIdIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          containerId_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto>(containerId_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getContainerIdList() {
        if (containerIdBuilder_ == null) {
          return java.util.Collections.unmodifiableList(containerId_);
        } else {
          return containerIdBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public int getContainerIdCount() {
        if (containerIdBuilder_ == null) {
          return containerId_.size();
        } else {
          return containerIdBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId(int index) {
        if (containerIdBuilder_ == null) {
          return containerId_.get(index);
        } else {
          return containerIdBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIdIsMutable();
          containerId_.set(index, value);
          onChanged();
        } else {
          containerIdBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          ensureContainerIdIsMutable();
          containerId_.set(index, builderForValue.build());
          onChanged();
        } else {
          containerIdBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder addContainerId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIdIsMutable();
          containerId_.add(value);
          onChanged();
        } else {
          containerIdBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder addContainerId(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIdIsMutable();
          containerId_.add(index, value);
          onChanged();
        } else {
          containerIdBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder addContainerId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          ensureContainerIdIsMutable();
          containerId_.add(builderForValue.build());
          onChanged();
        } else {
          containerIdBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder addContainerId(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          ensureContainerIdIsMutable();
          containerId_.add(index, builderForValue.build());
          onChanged();
        } else {
          containerIdBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder addAllContainerId(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> values) {
        if (containerIdBuilder_ == null) {
          ensureContainerIdIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, containerId_);
          onChanged();
        } else {
          containerIdBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder removeContainerId(int index) {
        if (containerIdBuilder_ == null) {
          ensureContainerIdIsMutable();
          containerId_.remove(index);
          onChanged();
        } else {
          containerIdBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder(
          int index) {
        return getContainerIdFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder(
          int index) {
        if (containerIdBuilder_ == null) {
          return containerId_.get(index);  } else {
          return containerIdBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
           getContainerIdOrBuilderList() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(containerId_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addContainerIdBuilder() {
        return getContainerIdFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addContainerIdBuilder(
          int index) {
        return getContainerIdFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder> 
           getContainerIdBuilderList() {
        return getContainerIdFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containerId_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StopContainersRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StopContainersRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<StopContainersRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<StopContainersRequestProto>() {
      public StopContainersRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StopContainersRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StopContainersRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StopContainersRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StopContainersResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.StopContainersResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> 
        getSucceededRequestsList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getSucceededRequests(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    int getSucceededRequestsCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getSucceededRequestsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getSucceededRequestsOrBuilder(
        int index);

    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> 
        getFailedRequestsList();
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto getFailedRequests(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    int getFailedRequestsCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
        getFailedRequestsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder getFailedRequestsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.StopContainersResponseProto}
   */
  public  static final class StopContainersResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.StopContainersResponseProto)
      StopContainersResponseProtoOrBuilder {
    // Use StopContainersResponseProto.newBuilder() to construct.
    private StopContainersResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StopContainersResponseProto() {
      succeededRequests_ = java.util.Collections.emptyList();
      failedRequests_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private StopContainersResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                succeededRequests_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              succeededRequests_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry));
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                failedRequests_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto>();
                mutable_bitField0_ |= 0x00000002;
              }
              failedRequests_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          succeededRequests_ = java.util.Collections.unmodifiableList(succeededRequests_);
        }
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          failedRequests_ = java.util.Collections.unmodifiableList(failedRequests_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainersResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainersResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto.Builder.class);
    }

    public static final int SUCCEEDED_REQUESTS_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> succeededRequests_;
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getSucceededRequestsList() {
      return succeededRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getSucceededRequestsOrBuilderList() {
      return succeededRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    public int getSucceededRequestsCount() {
      return succeededRequests_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getSucceededRequests(int index) {
      return succeededRequests_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getSucceededRequestsOrBuilder(
        int index) {
      return succeededRequests_.get(index);
    }

    public static final int FAILED_REQUESTS_FIELD_NUMBER = 2;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> failedRequests_;
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> getFailedRequestsList() {
      return failedRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
        getFailedRequestsOrBuilderList() {
      return failedRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    public int getFailedRequestsCount() {
      return failedRequests_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto getFailedRequests(int index) {
      return failedRequests_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder getFailedRequestsOrBuilder(
        int index) {
      return failedRequests_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < succeededRequests_.size(); i++) {
        output.writeMessage(1, succeededRequests_.get(i));
      }
      for (int i = 0; i < failedRequests_.size(); i++) {
        output.writeMessage(2, failedRequests_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < succeededRequests_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, succeededRequests_.get(i));
      }
      for (int i = 0; i < failedRequests_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, failedRequests_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto) obj;

      boolean result = true;
      result = result && getSucceededRequestsList()
          .equals(other.getSucceededRequestsList());
      result = result && getFailedRequestsList()
          .equals(other.getFailedRequestsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getSucceededRequestsCount() > 0) {
        hash = (37 * hash) + SUCCEEDED_REQUESTS_FIELD_NUMBER;
        hash = (53 * hash) + getSucceededRequestsList().hashCode();
      }
      if (getFailedRequestsCount() > 0) {
        hash = (37 * hash) + FAILED_REQUESTS_FIELD_NUMBER;
        hash = (53 * hash) + getFailedRequestsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StopContainersResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.StopContainersResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainersResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainersResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getSucceededRequestsFieldBuilder();
          getFailedRequestsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (succeededRequestsBuilder_ == null) {
          succeededRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          succeededRequestsBuilder_.clear();
        }
        if (failedRequestsBuilder_ == null) {
          failedRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          failedRequestsBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_StopContainersResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (succeededRequestsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            succeededRequests_ = java.util.Collections.unmodifiableList(succeededRequests_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.succeededRequests_ = succeededRequests_;
        } else {
          result.succeededRequests_ = succeededRequestsBuilder_.build();
        }
        if (failedRequestsBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            failedRequests_ = java.util.Collections.unmodifiableList(failedRequests_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.failedRequests_ = failedRequests_;
        } else {
          result.failedRequests_ = failedRequestsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto.getDefaultInstance()) return this;
        if (succeededRequestsBuilder_ == null) {
          if (!other.succeededRequests_.isEmpty()) {
            if (succeededRequests_.isEmpty()) {
              succeededRequests_ = other.succeededRequests_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureSucceededRequestsIsMutable();
              succeededRequests_.addAll(other.succeededRequests_);
            }
            onChanged();
          }
        } else {
          if (!other.succeededRequests_.isEmpty()) {
            if (succeededRequestsBuilder_.isEmpty()) {
              succeededRequestsBuilder_.dispose();
              succeededRequestsBuilder_ = null;
              succeededRequests_ = other.succeededRequests_;
              bitField0_ = (bitField0_ & ~0x00000001);
              succeededRequestsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getSucceededRequestsFieldBuilder() : null;
            } else {
              succeededRequestsBuilder_.addAllMessages(other.succeededRequests_);
            }
          }
        }
        if (failedRequestsBuilder_ == null) {
          if (!other.failedRequests_.isEmpty()) {
            if (failedRequests_.isEmpty()) {
              failedRequests_ = other.failedRequests_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureFailedRequestsIsMutable();
              failedRequests_.addAll(other.failedRequests_);
            }
            onChanged();
          }
        } else {
          if (!other.failedRequests_.isEmpty()) {
            if (failedRequestsBuilder_.isEmpty()) {
              failedRequestsBuilder_.dispose();
              failedRequestsBuilder_ = null;
              failedRequests_ = other.failedRequests_;
              bitField0_ = (bitField0_ & ~0x00000002);
              failedRequestsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getFailedRequestsFieldBuilder() : null;
            } else {
              failedRequestsBuilder_.addAllMessages(other.failedRequests_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> succeededRequests_ =
        java.util.Collections.emptyList();
      private void ensureSucceededRequestsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          succeededRequests_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto>(succeededRequests_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> succeededRequestsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getSucceededRequestsList() {
        if (succeededRequestsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(succeededRequests_);
        } else {
          return succeededRequestsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public int getSucceededRequestsCount() {
        if (succeededRequestsBuilder_ == null) {
          return succeededRequests_.size();
        } else {
          return succeededRequestsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getSucceededRequests(int index) {
        if (succeededRequestsBuilder_ == null) {
          return succeededRequests_.get(index);
        } else {
          return succeededRequestsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder setSucceededRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (succeededRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSucceededRequestsIsMutable();
          succeededRequests_.set(index, value);
          onChanged();
        } else {
          succeededRequestsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder setSucceededRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (succeededRequestsBuilder_ == null) {
          ensureSucceededRequestsIsMutable();
          succeededRequests_.set(index, builderForValue.build());
          onChanged();
        } else {
          succeededRequestsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder addSucceededRequests(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (succeededRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSucceededRequestsIsMutable();
          succeededRequests_.add(value);
          onChanged();
        } else {
          succeededRequestsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder addSucceededRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (succeededRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSucceededRequestsIsMutable();
          succeededRequests_.add(index, value);
          onChanged();
        } else {
          succeededRequestsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder addSucceededRequests(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (succeededRequestsBuilder_ == null) {
          ensureSucceededRequestsIsMutable();
          succeededRequests_.add(builderForValue.build());
          onChanged();
        } else {
          succeededRequestsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder addSucceededRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (succeededRequestsBuilder_ == null) {
          ensureSucceededRequestsIsMutable();
          succeededRequests_.add(index, builderForValue.build());
          onChanged();
        } else {
          succeededRequestsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder addAllSucceededRequests(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> values) {
        if (succeededRequestsBuilder_ == null) {
          ensureSucceededRequestsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, succeededRequests_);
          onChanged();
        } else {
          succeededRequestsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder clearSucceededRequests() {
        if (succeededRequestsBuilder_ == null) {
          succeededRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          succeededRequestsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder removeSucceededRequests(int index) {
        if (succeededRequestsBuilder_ == null) {
          ensureSucceededRequestsIsMutable();
          succeededRequests_.remove(index);
          onChanged();
        } else {
          succeededRequestsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getSucceededRequestsBuilder(
          int index) {
        return getSucceededRequestsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getSucceededRequestsOrBuilder(
          int index) {
        if (succeededRequestsBuilder_ == null) {
          return succeededRequests_.get(index);  } else {
          return succeededRequestsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
           getSucceededRequestsOrBuilderList() {
        if (succeededRequestsBuilder_ != null) {
          return succeededRequestsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(succeededRequests_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addSucceededRequestsBuilder() {
        return getSucceededRequestsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addSucceededRequestsBuilder(
          int index) {
        return getSucceededRequestsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder> 
           getSucceededRequestsBuilderList() {
        return getSucceededRequestsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getSucceededRequestsFieldBuilder() {
        if (succeededRequestsBuilder_ == null) {
          succeededRequestsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  succeededRequests_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          succeededRequests_ = null;
        }
        return succeededRequestsBuilder_;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> failedRequests_ =
        java.util.Collections.emptyList();
      private void ensureFailedRequestsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          failedRequests_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto>(failedRequests_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> failedRequestsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> getFailedRequestsList() {
        if (failedRequestsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(failedRequests_);
        } else {
          return failedRequestsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public int getFailedRequestsCount() {
        if (failedRequestsBuilder_ == null) {
          return failedRequests_.size();
        } else {
          return failedRequestsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto getFailedRequests(int index) {
        if (failedRequestsBuilder_ == null) {
          return failedRequests_.get(index);
        } else {
          return failedRequestsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder setFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto value) {
        if (failedRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFailedRequestsIsMutable();
          failedRequests_.set(index, value);
          onChanged();
        } else {
          failedRequestsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder setFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder builderForValue) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.set(index, builderForValue.build());
          onChanged();
        } else {
          failedRequestsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder addFailedRequests(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto value) {
        if (failedRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFailedRequestsIsMutable();
          failedRequests_.add(value);
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder addFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto value) {
        if (failedRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFailedRequestsIsMutable();
          failedRequests_.add(index, value);
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder addFailedRequests(
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder builderForValue) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.add(builderForValue.build());
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder addFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder builderForValue) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.add(index, builderForValue.build());
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder addAllFailedRequests(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> values) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, failedRequests_);
          onChanged();
        } else {
          failedRequestsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder clearFailedRequests() {
        if (failedRequestsBuilder_ == null) {
          failedRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          failedRequestsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder removeFailedRequests(int index) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.remove(index);
          onChanged();
        } else {
          failedRequestsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder getFailedRequestsBuilder(
          int index) {
        return getFailedRequestsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder getFailedRequestsOrBuilder(
          int index) {
        if (failedRequestsBuilder_ == null) {
          return failedRequests_.get(index);  } else {
          return failedRequestsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
           getFailedRequestsOrBuilderList() {
        if (failedRequestsBuilder_ != null) {
          return failedRequestsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(failedRequests_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder addFailedRequestsBuilder() {
        return getFailedRequestsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder addFailedRequestsBuilder(
          int index) {
        return getFailedRequestsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder> 
           getFailedRequestsBuilderList() {
        return getFailedRequestsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
          getFailedRequestsFieldBuilder() {
        if (failedRequestsBuilder_ == null) {
          failedRequestsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder>(
                  failedRequests_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          failedRequests_ = null;
        }
        return failedRequestsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StopContainersResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StopContainersResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<StopContainersResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<StopContainersResponseProto>() {
      public StopContainersResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StopContainersResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StopContainersResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StopContainersResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.StopContainersResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetContainerStatusesRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetContainerStatusesRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> 
        getContainerIdList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    int getContainerIdCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getContainerIdOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetContainerStatusesRequestProto}
   */
  public  static final class GetContainerStatusesRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetContainerStatusesRequestProto)
      GetContainerStatusesRequestProtoOrBuilder {
    // Use GetContainerStatusesRequestProto.newBuilder() to construct.
    private GetContainerStatusesRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetContainerStatusesRequestProto() {
      containerId_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetContainerStatusesRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                containerId_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              containerId_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          containerId_ = java.util.Collections.unmodifiableList(containerId_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerStatusesRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerStatusesRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto.Builder.class);
    }

    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> containerId_;
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getContainerIdList() {
      return containerId_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getContainerIdOrBuilderList() {
      return containerId_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public int getContainerIdCount() {
      return containerId_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId(int index) {
      return containerId_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder(
        int index) {
      return containerId_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < containerId_.size(); i++) {
        output.writeMessage(1, containerId_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < containerId_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerId_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto) obj;

      boolean result = true;
      result = result && getContainerIdList()
          .equals(other.getContainerIdList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getContainerIdCount() > 0) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerIdList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetContainerStatusesRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetContainerStatusesRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerStatusesRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerStatusesRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          containerIdBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerStatusesRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto(this);
        int from_bitField0_ = bitField0_;
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            containerId_ = java.util.Collections.unmodifiableList(containerId_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto.getDefaultInstance()) return this;
        if (containerIdBuilder_ == null) {
          if (!other.containerId_.isEmpty()) {
            if (containerId_.isEmpty()) {
              containerId_ = other.containerId_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureContainerIdIsMutable();
              containerId_.addAll(other.containerId_);
            }
            onChanged();
          }
        } else {
          if (!other.containerId_.isEmpty()) {
            if (containerIdBuilder_.isEmpty()) {
              containerIdBuilder_.dispose();
              containerIdBuilder_ = null;
              containerId_ = other.containerId_;
              bitField0_ = (bitField0_ & ~0x00000001);
              containerIdBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getContainerIdFieldBuilder() : null;
            } else {
              containerIdBuilder_.addAllMessages(other.containerId_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> containerId_ =
        java.util.Collections.emptyList();
      private void ensureContainerIdIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          containerId_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto>(containerId_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getContainerIdList() {
        if (containerIdBuilder_ == null) {
          return java.util.Collections.unmodifiableList(containerId_);
        } else {
          return containerIdBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public int getContainerIdCount() {
        if (containerIdBuilder_ == null) {
          return containerId_.size();
        } else {
          return containerIdBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId(int index) {
        if (containerIdBuilder_ == null) {
          return containerId_.get(index);
        } else {
          return containerIdBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIdIsMutable();
          containerId_.set(index, value);
          onChanged();
        } else {
          containerIdBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          ensureContainerIdIsMutable();
          containerId_.set(index, builderForValue.build());
          onChanged();
        } else {
          containerIdBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder addContainerId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIdIsMutable();
          containerId_.add(value);
          onChanged();
        } else {
          containerIdBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder addContainerId(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIdIsMutable();
          containerId_.add(index, value);
          onChanged();
        } else {
          containerIdBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder addContainerId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          ensureContainerIdIsMutable();
          containerId_.add(builderForValue.build());
          onChanged();
        } else {
          containerIdBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder addContainerId(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          ensureContainerIdIsMutable();
          containerId_.add(index, builderForValue.build());
          onChanged();
        } else {
          containerIdBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder addAllContainerId(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> values) {
        if (containerIdBuilder_ == null) {
          ensureContainerIdIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, containerId_);
          onChanged();
        } else {
          containerIdBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder removeContainerId(int index) {
        if (containerIdBuilder_ == null) {
          ensureContainerIdIsMutable();
          containerId_.remove(index);
          onChanged();
        } else {
          containerIdBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder(
          int index) {
        return getContainerIdFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder(
          int index) {
        if (containerIdBuilder_ == null) {
          return containerId_.get(index);  } else {
          return containerIdBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
           getContainerIdOrBuilderList() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(containerId_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addContainerIdBuilder() {
        return getContainerIdFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addContainerIdBuilder(
          int index) {
        return getContainerIdFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder> 
           getContainerIdBuilderList() {
        return getContainerIdFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containerId_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetContainerStatusesRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetContainerStatusesRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetContainerStatusesRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetContainerStatusesRequestProto>() {
      public GetContainerStatusesRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetContainerStatusesRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetContainerStatusesRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetContainerStatusesRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetContainerStatusesResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetContainerStatusesResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> 
        getStatusList();
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getStatus(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
     */
    int getStatusCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> 
        getStatusOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder getStatusOrBuilder(
        int index);

    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> 
        getFailedRequestsList();
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto getFailedRequests(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    int getFailedRequestsCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
        getFailedRequestsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder getFailedRequestsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetContainerStatusesResponseProto}
   */
  public  static final class GetContainerStatusesResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetContainerStatusesResponseProto)
      GetContainerStatusesResponseProtoOrBuilder {
    // Use GetContainerStatusesResponseProto.newBuilder() to construct.
    private GetContainerStatusesResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetContainerStatusesResponseProto() {
      status_ = java.util.Collections.emptyList();
      failedRequests_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetContainerStatusesResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                status_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              status_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.PARSER, extensionRegistry));
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                failedRequests_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto>();
                mutable_bitField0_ |= 0x00000002;
              }
              failedRequests_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          status_ = java.util.Collections.unmodifiableList(status_);
        }
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          failedRequests_ = java.util.Collections.unmodifiableList(failedRequests_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerStatusesResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerStatusesResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto.Builder.class);
    }

    public static final int STATUS_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> status_;
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> getStatusList() {
      return status_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> 
        getStatusOrBuilderList() {
      return status_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
     */
    public int getStatusCount() {
      return status_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getStatus(int index) {
      return status_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder getStatusOrBuilder(
        int index) {
      return status_.get(index);
    }

    public static final int FAILED_REQUESTS_FIELD_NUMBER = 2;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> failedRequests_;
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> getFailedRequestsList() {
      return failedRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
        getFailedRequestsOrBuilderList() {
      return failedRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    public int getFailedRequestsCount() {
      return failedRequests_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto getFailedRequests(int index) {
      return failedRequests_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder getFailedRequestsOrBuilder(
        int index) {
      return failedRequests_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < status_.size(); i++) {
        output.writeMessage(1, status_.get(i));
      }
      for (int i = 0; i < failedRequests_.size(); i++) {
        output.writeMessage(2, failedRequests_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < status_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, status_.get(i));
      }
      for (int i = 0; i < failedRequests_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, failedRequests_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto) obj;

      boolean result = true;
      result = result && getStatusList()
          .equals(other.getStatusList());
      result = result && getFailedRequestsList()
          .equals(other.getFailedRequestsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getStatusCount() > 0) {
        hash = (37 * hash) + STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getStatusList().hashCode();
      }
      if (getFailedRequestsCount() > 0) {
        hash = (37 * hash) + FAILED_REQUESTS_FIELD_NUMBER;
        hash = (53 * hash) + getFailedRequestsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetContainerStatusesResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetContainerStatusesResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerStatusesResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerStatusesResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getStatusFieldBuilder();
          getFailedRequestsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (statusBuilder_ == null) {
          status_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          statusBuilder_.clear();
        }
        if (failedRequestsBuilder_ == null) {
          failedRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          failedRequestsBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerStatusesResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (statusBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            status_ = java.util.Collections.unmodifiableList(status_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.status_ = status_;
        } else {
          result.status_ = statusBuilder_.build();
        }
        if (failedRequestsBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            failedRequests_ = java.util.Collections.unmodifiableList(failedRequests_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.failedRequests_ = failedRequests_;
        } else {
          result.failedRequests_ = failedRequestsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto.getDefaultInstance()) return this;
        if (statusBuilder_ == null) {
          if (!other.status_.isEmpty()) {
            if (status_.isEmpty()) {
              status_ = other.status_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureStatusIsMutable();
              status_.addAll(other.status_);
            }
            onChanged();
          }
        } else {
          if (!other.status_.isEmpty()) {
            if (statusBuilder_.isEmpty()) {
              statusBuilder_.dispose();
              statusBuilder_ = null;
              status_ = other.status_;
              bitField0_ = (bitField0_ & ~0x00000001);
              statusBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getStatusFieldBuilder() : null;
            } else {
              statusBuilder_.addAllMessages(other.status_);
            }
          }
        }
        if (failedRequestsBuilder_ == null) {
          if (!other.failedRequests_.isEmpty()) {
            if (failedRequests_.isEmpty()) {
              failedRequests_ = other.failedRequests_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureFailedRequestsIsMutable();
              failedRequests_.addAll(other.failedRequests_);
            }
            onChanged();
          }
        } else {
          if (!other.failedRequests_.isEmpty()) {
            if (failedRequestsBuilder_.isEmpty()) {
              failedRequestsBuilder_.dispose();
              failedRequestsBuilder_ = null;
              failedRequests_ = other.failedRequests_;
              bitField0_ = (bitField0_ & ~0x00000002);
              failedRequestsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getFailedRequestsFieldBuilder() : null;
            } else {
              failedRequestsBuilder_.addAllMessages(other.failedRequests_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> status_ =
        java.util.Collections.emptyList();
      private void ensureStatusIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          status_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto>(status_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> statusBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> getStatusList() {
        if (statusBuilder_ == null) {
          return java.util.Collections.unmodifiableList(status_);
        } else {
          return statusBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public int getStatusCount() {
        if (statusBuilder_ == null) {
          return status_.size();
        } else {
          return statusBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getStatus(int index) {
        if (statusBuilder_ == null) {
          return status_.get(index);
        } else {
          return statusBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public Builder setStatus(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto value) {
        if (statusBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStatusIsMutable();
          status_.set(index, value);
          onChanged();
        } else {
          statusBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public Builder setStatus(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder builderForValue) {
        if (statusBuilder_ == null) {
          ensureStatusIsMutable();
          status_.set(index, builderForValue.build());
          onChanged();
        } else {
          statusBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public Builder addStatus(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto value) {
        if (statusBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStatusIsMutable();
          status_.add(value);
          onChanged();
        } else {
          statusBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public Builder addStatus(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto value) {
        if (statusBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStatusIsMutable();
          status_.add(index, value);
          onChanged();
        } else {
          statusBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public Builder addStatus(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder builderForValue) {
        if (statusBuilder_ == null) {
          ensureStatusIsMutable();
          status_.add(builderForValue.build());
          onChanged();
        } else {
          statusBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public Builder addStatus(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder builderForValue) {
        if (statusBuilder_ == null) {
          ensureStatusIsMutable();
          status_.add(index, builderForValue.build());
          onChanged();
        } else {
          statusBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public Builder addAllStatus(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> values) {
        if (statusBuilder_ == null) {
          ensureStatusIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, status_);
          onChanged();
        } else {
          statusBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public Builder clearStatus() {
        if (statusBuilder_ == null) {
          status_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          statusBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public Builder removeStatus(int index) {
        if (statusBuilder_ == null) {
          ensureStatusIsMutable();
          status_.remove(index);
          onChanged();
        } else {
          statusBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder getStatusBuilder(
          int index) {
        return getStatusFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder getStatusOrBuilder(
          int index) {
        if (statusBuilder_ == null) {
          return status_.get(index);  } else {
          return statusBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> 
           getStatusOrBuilderList() {
        if (statusBuilder_ != null) {
          return statusBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(status_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder addStatusBuilder() {
        return getStatusFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder addStatusBuilder(
          int index) {
        return getStatusFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto status = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder> 
           getStatusBuilderList() {
        return getStatusFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> 
          getStatusFieldBuilder() {
        if (statusBuilder_ == null) {
          statusBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder>(
                  status_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          status_ = null;
        }
        return statusBuilder_;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> failedRequests_ =
        java.util.Collections.emptyList();
      private void ensureFailedRequestsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          failedRequests_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto>(failedRequests_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> failedRequestsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> getFailedRequestsList() {
        if (failedRequestsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(failedRequests_);
        } else {
          return failedRequestsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public int getFailedRequestsCount() {
        if (failedRequestsBuilder_ == null) {
          return failedRequests_.size();
        } else {
          return failedRequestsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto getFailedRequests(int index) {
        if (failedRequestsBuilder_ == null) {
          return failedRequests_.get(index);
        } else {
          return failedRequestsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder setFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto value) {
        if (failedRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFailedRequestsIsMutable();
          failedRequests_.set(index, value);
          onChanged();
        } else {
          failedRequestsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder setFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder builderForValue) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.set(index, builderForValue.build());
          onChanged();
        } else {
          failedRequestsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder addFailedRequests(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto value) {
        if (failedRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFailedRequestsIsMutable();
          failedRequests_.add(value);
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder addFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto value) {
        if (failedRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFailedRequestsIsMutable();
          failedRequests_.add(index, value);
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder addFailedRequests(
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder builderForValue) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.add(builderForValue.build());
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder addFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder builderForValue) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.add(index, builderForValue.build());
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder addAllFailedRequests(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> values) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, failedRequests_);
          onChanged();
        } else {
          failedRequestsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder clearFailedRequests() {
        if (failedRequestsBuilder_ == null) {
          failedRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          failedRequestsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder removeFailedRequests(int index) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.remove(index);
          onChanged();
        } else {
          failedRequestsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder getFailedRequestsBuilder(
          int index) {
        return getFailedRequestsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder getFailedRequestsOrBuilder(
          int index) {
        if (failedRequestsBuilder_ == null) {
          return failedRequests_.get(index);  } else {
          return failedRequestsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
           getFailedRequestsOrBuilderList() {
        if (failedRequestsBuilder_ != null) {
          return failedRequestsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(failedRequests_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder addFailedRequestsBuilder() {
        return getFailedRequestsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder addFailedRequestsBuilder(
          int index) {
        return getFailedRequestsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder> 
           getFailedRequestsBuilderList() {
        return getFailedRequestsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
          getFailedRequestsFieldBuilder() {
        if (failedRequestsBuilder_ == null) {
          failedRequestsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder>(
                  failedRequests_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          failedRequests_ = null;
        }
        return failedRequestsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetContainerStatusesResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetContainerStatusesResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetContainerStatusesResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetContainerStatusesResponseProto>() {
      public GetContainerStatusesResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetContainerStatusesResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetContainerStatusesResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetContainerStatusesResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusesResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface IncreaseContainersResourceRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.IncreaseContainersResourceRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto> 
        getIncreaseContainersList();
    /**
     * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
     */
    org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto getIncreaseContainers(int index);
    /**
     * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
     */
    int getIncreaseContainersCount();
    /**
     * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
        getIncreaseContainersOrBuilderList();
    /**
     * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
     */
    org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getIncreaseContainersOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.IncreaseContainersResourceRequestProto}
   */
  public  static final class IncreaseContainersResourceRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.IncreaseContainersResourceRequestProto)
      IncreaseContainersResourceRequestProtoOrBuilder {
    // Use IncreaseContainersResourceRequestProto.newBuilder() to construct.
    private IncreaseContainersResourceRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private IncreaseContainersResourceRequestProto() {
      increaseContainers_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private IncreaseContainersResourceRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                increaseContainers_ = new java.util.ArrayList<org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              increaseContainers_.add(
                  input.readMessage(org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          increaseContainers_ = java.util.Collections.unmodifiableList(increaseContainers_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_IncreaseContainersResourceRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_IncreaseContainersResourceRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto.Builder.class);
    }

    public static final int INCREASE_CONTAINERS_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto> increaseContainers_;
    /**
     * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto> getIncreaseContainersList() {
      return increaseContainers_;
    }
    /**
     * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
        getIncreaseContainersOrBuilderList() {
      return increaseContainers_;
    }
    /**
     * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
     */
    public int getIncreaseContainersCount() {
      return increaseContainers_.size();
    }
    /**
     * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
     */
    public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto getIncreaseContainers(int index) {
      return increaseContainers_.get(index);
    }
    /**
     * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
     */
    public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getIncreaseContainersOrBuilder(
        int index) {
      return increaseContainers_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getIncreaseContainersCount(); i++) {
        if (!getIncreaseContainers(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < increaseContainers_.size(); i++) {
        output.writeMessage(1, increaseContainers_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < increaseContainers_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, increaseContainers_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto) obj;

      boolean result = true;
      result = result && getIncreaseContainersList()
          .equals(other.getIncreaseContainersList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getIncreaseContainersCount() > 0) {
        hash = (37 * hash) + INCREASE_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getIncreaseContainersList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.IncreaseContainersResourceRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.IncreaseContainersResourceRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_IncreaseContainersResourceRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_IncreaseContainersResourceRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getIncreaseContainersFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (increaseContainersBuilder_ == null) {
          increaseContainers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          increaseContainersBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_IncreaseContainersResourceRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto(this);
        int from_bitField0_ = bitField0_;
        if (increaseContainersBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            increaseContainers_ = java.util.Collections.unmodifiableList(increaseContainers_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.increaseContainers_ = increaseContainers_;
        } else {
          result.increaseContainers_ = increaseContainersBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto.getDefaultInstance()) return this;
        if (increaseContainersBuilder_ == null) {
          if (!other.increaseContainers_.isEmpty()) {
            if (increaseContainers_.isEmpty()) {
              increaseContainers_ = other.increaseContainers_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureIncreaseContainersIsMutable();
              increaseContainers_.addAll(other.increaseContainers_);
            }
            onChanged();
          }
        } else {
          if (!other.increaseContainers_.isEmpty()) {
            if (increaseContainersBuilder_.isEmpty()) {
              increaseContainersBuilder_.dispose();
              increaseContainersBuilder_ = null;
              increaseContainers_ = other.increaseContainers_;
              bitField0_ = (bitField0_ & ~0x00000001);
              increaseContainersBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getIncreaseContainersFieldBuilder() : null;
            } else {
              increaseContainersBuilder_.addAllMessages(other.increaseContainers_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getIncreaseContainersCount(); i++) {
          if (!getIncreaseContainers(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto> increaseContainers_ =
        java.util.Collections.emptyList();
      private void ensureIncreaseContainersIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          increaseContainers_ = new java.util.ArrayList<org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto>(increaseContainers_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> increaseContainersBuilder_;

      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto> getIncreaseContainersList() {
        if (increaseContainersBuilder_ == null) {
          return java.util.Collections.unmodifiableList(increaseContainers_);
        } else {
          return increaseContainersBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public int getIncreaseContainersCount() {
        if (increaseContainersBuilder_ == null) {
          return increaseContainers_.size();
        } else {
          return increaseContainersBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto getIncreaseContainers(int index) {
        if (increaseContainersBuilder_ == null) {
          return increaseContainers_.get(index);
        } else {
          return increaseContainersBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public Builder setIncreaseContainers(
          int index, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (increaseContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureIncreaseContainersIsMutable();
          increaseContainers_.set(index, value);
          onChanged();
        } else {
          increaseContainersBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public Builder setIncreaseContainers(
          int index, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (increaseContainersBuilder_ == null) {
          ensureIncreaseContainersIsMutable();
          increaseContainers_.set(index, builderForValue.build());
          onChanged();
        } else {
          increaseContainersBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public Builder addIncreaseContainers(org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (increaseContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureIncreaseContainersIsMutable();
          increaseContainers_.add(value);
          onChanged();
        } else {
          increaseContainersBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public Builder addIncreaseContainers(
          int index, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (increaseContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureIncreaseContainersIsMutable();
          increaseContainers_.add(index, value);
          onChanged();
        } else {
          increaseContainersBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public Builder addIncreaseContainers(
          org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (increaseContainersBuilder_ == null) {
          ensureIncreaseContainersIsMutable();
          increaseContainers_.add(builderForValue.build());
          onChanged();
        } else {
          increaseContainersBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public Builder addIncreaseContainers(
          int index, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (increaseContainersBuilder_ == null) {
          ensureIncreaseContainersIsMutable();
          increaseContainers_.add(index, builderForValue.build());
          onChanged();
        } else {
          increaseContainersBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public Builder addAllIncreaseContainers(
          java.lang.Iterable<? extends org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto> values) {
        if (increaseContainersBuilder_ == null) {
          ensureIncreaseContainersIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, increaseContainers_);
          onChanged();
        } else {
          increaseContainersBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public Builder clearIncreaseContainers() {
        if (increaseContainersBuilder_ == null) {
          increaseContainers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          increaseContainersBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public Builder removeIncreaseContainers(int index) {
        if (increaseContainersBuilder_ == null) {
          ensureIncreaseContainersIsMutable();
          increaseContainers_.remove(index);
          onChanged();
        } else {
          increaseContainersBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder getIncreaseContainersBuilder(
          int index) {
        return getIncreaseContainersFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getIncreaseContainersOrBuilder(
          int index) {
        if (increaseContainersBuilder_ == null) {
          return increaseContainers_.get(index);  } else {
          return increaseContainersBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
           getIncreaseContainersOrBuilderList() {
        if (increaseContainersBuilder_ != null) {
          return increaseContainersBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(increaseContainers_);
        }
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder addIncreaseContainersBuilder() {
        return getIncreaseContainersFieldBuilder().addBuilder(
            org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder addIncreaseContainersBuilder(
          int index) {
        return getIncreaseContainersFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.common.TokenProto increase_containers = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder> 
           getIncreaseContainersBuilderList() {
        return getIncreaseContainersFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getIncreaseContainersFieldBuilder() {
        if (increaseContainersBuilder_ == null) {
          increaseContainersBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.spiderdt.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  increaseContainers_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          increaseContainers_ = null;
        }
        return increaseContainersBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.IncreaseContainersResourceRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.IncreaseContainersResourceRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<IncreaseContainersResourceRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<IncreaseContainersResourceRequestProto>() {
      public IncreaseContainersResourceRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new IncreaseContainersResourceRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<IncreaseContainersResourceRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<IncreaseContainersResourceRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface IncreaseContainersResourceResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.IncreaseContainersResourceResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> 
        getSucceededRequestsList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getSucceededRequests(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    int getSucceededRequestsCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getSucceededRequestsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getSucceededRequestsOrBuilder(
        int index);

    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> 
        getFailedRequestsList();
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto getFailedRequests(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    int getFailedRequestsCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
        getFailedRequestsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder getFailedRequestsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.IncreaseContainersResourceResponseProto}
   */
  public  static final class IncreaseContainersResourceResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.IncreaseContainersResourceResponseProto)
      IncreaseContainersResourceResponseProtoOrBuilder {
    // Use IncreaseContainersResourceResponseProto.newBuilder() to construct.
    private IncreaseContainersResourceResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private IncreaseContainersResourceResponseProto() {
      succeededRequests_ = java.util.Collections.emptyList();
      failedRequests_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private IncreaseContainersResourceResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                succeededRequests_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              succeededRequests_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry));
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                failedRequests_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto>();
                mutable_bitField0_ |= 0x00000002;
              }
              failedRequests_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          succeededRequests_ = java.util.Collections.unmodifiableList(succeededRequests_);
        }
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          failedRequests_ = java.util.Collections.unmodifiableList(failedRequests_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_IncreaseContainersResourceResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_IncreaseContainersResourceResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto.Builder.class);
    }

    public static final int SUCCEEDED_REQUESTS_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> succeededRequests_;
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getSucceededRequestsList() {
      return succeededRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getSucceededRequestsOrBuilderList() {
      return succeededRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    public int getSucceededRequestsCount() {
      return succeededRequests_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getSucceededRequests(int index) {
      return succeededRequests_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getSucceededRequestsOrBuilder(
        int index) {
      return succeededRequests_.get(index);
    }

    public static final int FAILED_REQUESTS_FIELD_NUMBER = 2;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> failedRequests_;
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> getFailedRequestsList() {
      return failedRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
        getFailedRequestsOrBuilderList() {
      return failedRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    public int getFailedRequestsCount() {
      return failedRequests_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto getFailedRequests(int index) {
      return failedRequests_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder getFailedRequestsOrBuilder(
        int index) {
      return failedRequests_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < succeededRequests_.size(); i++) {
        output.writeMessage(1, succeededRequests_.get(i));
      }
      for (int i = 0; i < failedRequests_.size(); i++) {
        output.writeMessage(2, failedRequests_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < succeededRequests_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, succeededRequests_.get(i));
      }
      for (int i = 0; i < failedRequests_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, failedRequests_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto) obj;

      boolean result = true;
      result = result && getSucceededRequestsList()
          .equals(other.getSucceededRequestsList());
      result = result && getFailedRequestsList()
          .equals(other.getFailedRequestsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getSucceededRequestsCount() > 0) {
        hash = (37 * hash) + SUCCEEDED_REQUESTS_FIELD_NUMBER;
        hash = (53 * hash) + getSucceededRequestsList().hashCode();
      }
      if (getFailedRequestsCount() > 0) {
        hash = (37 * hash) + FAILED_REQUESTS_FIELD_NUMBER;
        hash = (53 * hash) + getFailedRequestsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.IncreaseContainersResourceResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.IncreaseContainersResourceResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_IncreaseContainersResourceResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_IncreaseContainersResourceResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getSucceededRequestsFieldBuilder();
          getFailedRequestsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (succeededRequestsBuilder_ == null) {
          succeededRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          succeededRequestsBuilder_.clear();
        }
        if (failedRequestsBuilder_ == null) {
          failedRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          failedRequestsBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_IncreaseContainersResourceResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (succeededRequestsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            succeededRequests_ = java.util.Collections.unmodifiableList(succeededRequests_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.succeededRequests_ = succeededRequests_;
        } else {
          result.succeededRequests_ = succeededRequestsBuilder_.build();
        }
        if (failedRequestsBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            failedRequests_ = java.util.Collections.unmodifiableList(failedRequests_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.failedRequests_ = failedRequests_;
        } else {
          result.failedRequests_ = failedRequestsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto.getDefaultInstance()) return this;
        if (succeededRequestsBuilder_ == null) {
          if (!other.succeededRequests_.isEmpty()) {
            if (succeededRequests_.isEmpty()) {
              succeededRequests_ = other.succeededRequests_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureSucceededRequestsIsMutable();
              succeededRequests_.addAll(other.succeededRequests_);
            }
            onChanged();
          }
        } else {
          if (!other.succeededRequests_.isEmpty()) {
            if (succeededRequestsBuilder_.isEmpty()) {
              succeededRequestsBuilder_.dispose();
              succeededRequestsBuilder_ = null;
              succeededRequests_ = other.succeededRequests_;
              bitField0_ = (bitField0_ & ~0x00000001);
              succeededRequestsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getSucceededRequestsFieldBuilder() : null;
            } else {
              succeededRequestsBuilder_.addAllMessages(other.succeededRequests_);
            }
          }
        }
        if (failedRequestsBuilder_ == null) {
          if (!other.failedRequests_.isEmpty()) {
            if (failedRequests_.isEmpty()) {
              failedRequests_ = other.failedRequests_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureFailedRequestsIsMutable();
              failedRequests_.addAll(other.failedRequests_);
            }
            onChanged();
          }
        } else {
          if (!other.failedRequests_.isEmpty()) {
            if (failedRequestsBuilder_.isEmpty()) {
              failedRequestsBuilder_.dispose();
              failedRequestsBuilder_ = null;
              failedRequests_ = other.failedRequests_;
              bitField0_ = (bitField0_ & ~0x00000002);
              failedRequestsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getFailedRequestsFieldBuilder() : null;
            } else {
              failedRequestsBuilder_.addAllMessages(other.failedRequests_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> succeededRequests_ =
        java.util.Collections.emptyList();
      private void ensureSucceededRequestsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          succeededRequests_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto>(succeededRequests_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> succeededRequestsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getSucceededRequestsList() {
        if (succeededRequestsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(succeededRequests_);
        } else {
          return succeededRequestsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public int getSucceededRequestsCount() {
        if (succeededRequestsBuilder_ == null) {
          return succeededRequests_.size();
        } else {
          return succeededRequestsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getSucceededRequests(int index) {
        if (succeededRequestsBuilder_ == null) {
          return succeededRequests_.get(index);
        } else {
          return succeededRequestsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder setSucceededRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (succeededRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSucceededRequestsIsMutable();
          succeededRequests_.set(index, value);
          onChanged();
        } else {
          succeededRequestsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder setSucceededRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (succeededRequestsBuilder_ == null) {
          ensureSucceededRequestsIsMutable();
          succeededRequests_.set(index, builderForValue.build());
          onChanged();
        } else {
          succeededRequestsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder addSucceededRequests(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (succeededRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSucceededRequestsIsMutable();
          succeededRequests_.add(value);
          onChanged();
        } else {
          succeededRequestsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder addSucceededRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (succeededRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSucceededRequestsIsMutable();
          succeededRequests_.add(index, value);
          onChanged();
        } else {
          succeededRequestsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder addSucceededRequests(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (succeededRequestsBuilder_ == null) {
          ensureSucceededRequestsIsMutable();
          succeededRequests_.add(builderForValue.build());
          onChanged();
        } else {
          succeededRequestsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder addSucceededRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (succeededRequestsBuilder_ == null) {
          ensureSucceededRequestsIsMutable();
          succeededRequests_.add(index, builderForValue.build());
          onChanged();
        } else {
          succeededRequestsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder addAllSucceededRequests(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto> values) {
        if (succeededRequestsBuilder_ == null) {
          ensureSucceededRequestsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, succeededRequests_);
          onChanged();
        } else {
          succeededRequestsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder clearSucceededRequests() {
        if (succeededRequestsBuilder_ == null) {
          succeededRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          succeededRequestsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public Builder removeSucceededRequests(int index) {
        if (succeededRequestsBuilder_ == null) {
          ensureSucceededRequestsIsMutable();
          succeededRequests_.remove(index);
          onChanged();
        } else {
          succeededRequestsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getSucceededRequestsBuilder(
          int index) {
        return getSucceededRequestsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getSucceededRequestsOrBuilder(
          int index) {
        if (succeededRequestsBuilder_ == null) {
          return succeededRequests_.get(index);  } else {
          return succeededRequestsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
           getSucceededRequestsOrBuilderList() {
        if (succeededRequestsBuilder_ != null) {
          return succeededRequestsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(succeededRequests_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addSucceededRequestsBuilder() {
        return getSucceededRequestsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addSucceededRequestsBuilder(
          int index) {
        return getSucceededRequestsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder> 
           getSucceededRequestsBuilderList() {
        return getSucceededRequestsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getSucceededRequestsFieldBuilder() {
        if (succeededRequestsBuilder_ == null) {
          succeededRequestsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  succeededRequests_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          succeededRequests_ = null;
        }
        return succeededRequestsBuilder_;
      }

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> failedRequests_ =
        java.util.Collections.emptyList();
      private void ensureFailedRequestsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          failedRequests_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto>(failedRequests_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> failedRequestsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> getFailedRequestsList() {
        if (failedRequestsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(failedRequests_);
        } else {
          return failedRequestsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public int getFailedRequestsCount() {
        if (failedRequestsBuilder_ == null) {
          return failedRequests_.size();
        } else {
          return failedRequestsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto getFailedRequests(int index) {
        if (failedRequestsBuilder_ == null) {
          return failedRequests_.get(index);
        } else {
          return failedRequestsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder setFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto value) {
        if (failedRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFailedRequestsIsMutable();
          failedRequests_.set(index, value);
          onChanged();
        } else {
          failedRequestsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder setFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder builderForValue) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.set(index, builderForValue.build());
          onChanged();
        } else {
          failedRequestsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder addFailedRequests(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto value) {
        if (failedRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFailedRequestsIsMutable();
          failedRequests_.add(value);
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder addFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto value) {
        if (failedRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFailedRequestsIsMutable();
          failedRequests_.add(index, value);
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder addFailedRequests(
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder builderForValue) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.add(builderForValue.build());
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder addFailedRequests(
          int index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder builderForValue) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.add(index, builderForValue.build());
          onChanged();
        } else {
          failedRequestsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder addAllFailedRequests(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto> values) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, failedRequests_);
          onChanged();
        } else {
          failedRequestsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder clearFailedRequests() {
        if (failedRequestsBuilder_ == null) {
          failedRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          failedRequestsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public Builder removeFailedRequests(int index) {
        if (failedRequestsBuilder_ == null) {
          ensureFailedRequestsIsMutable();
          failedRequests_.remove(index);
          onChanged();
        } else {
          failedRequestsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder getFailedRequestsBuilder(
          int index) {
        return getFailedRequestsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder getFailedRequestsOrBuilder(
          int index) {
        if (failedRequestsBuilder_ == null) {
          return failedRequests_.get(index);  } else {
          return failedRequestsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
           getFailedRequestsOrBuilderList() {
        if (failedRequestsBuilder_ != null) {
          return failedRequestsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(failedRequests_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder addFailedRequestsBuilder() {
        return getFailedRequestsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder addFailedRequestsBuilder(
          int index) {
        return getFailedRequestsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder> 
           getFailedRequestsBuilderList() {
        return getFailedRequestsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder> 
          getFailedRequestsFieldBuilder() {
        if (failedRequestsBuilder_ == null) {
          failedRequestsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ContainerExceptionMapProtoOrBuilder>(
                  failedRequests_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          failedRequests_ = null;
        }
        return failedRequestsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.IncreaseContainersResourceResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.IncreaseContainersResourceResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<IncreaseContainersResourceResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<IncreaseContainersResourceResponseProto>() {
      public IncreaseContainersResourceResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new IncreaseContainersResourceResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<IncreaseContainersResourceResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<IncreaseContainersResourceResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.IncreaseContainersResourceResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetApplicationAttemptReportRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetApplicationAttemptReportRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    boolean hasApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetApplicationAttemptReportRequestProto}
   */
  public  static final class GetApplicationAttemptReportRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetApplicationAttemptReportRequestProto)
      GetApplicationAttemptReportRequestProtoOrBuilder {
    // Use GetApplicationAttemptReportRequestProto.newBuilder() to construct.
    private GetApplicationAttemptReportRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetApplicationAttemptReportRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetApplicationAttemptReportRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationAttemptId_.toBuilder();
              }
              applicationAttemptId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationAttemptId_);
                applicationAttemptId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptReportRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptReportRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATION_ATTEMPT_ID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    public boolean hasApplicationAttemptId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
      return applicationAttemptId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
      return applicationAttemptId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationAttemptId());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationAttemptId());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto) obj;

      boolean result = true;
      result = result && (hasApplicationAttemptId() == other.hasApplicationAttemptId());
      if (hasApplicationAttemptId()) {
        result = result && getApplicationAttemptId()
            .equals(other.getApplicationAttemptId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationAttemptId()) {
        hash = (37 * hash) + APPLICATION_ATTEMPT_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationAttemptId().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetApplicationAttemptReportRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetApplicationAttemptReportRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptReportRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptReportRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationAttemptIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = null;
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptReportRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationAttemptIdBuilder_ == null) {
          result.applicationAttemptId_ = applicationAttemptId_;
        } else {
          result.applicationAttemptId_ = applicationAttemptIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationAttemptId()) {
          mergeApplicationAttemptId(other.getApplicationAttemptId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> applicationAttemptIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public boolean hasApplicationAttemptId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          return applicationAttemptId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
        } else {
          return applicationAttemptIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder setApplicationAttemptId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationAttemptId_ = value;
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder setApplicationAttemptId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder builderForValue) {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = builderForValue.build();
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder mergeApplicationAttemptId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationAttemptId_ != null &&
              applicationAttemptId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) {
            applicationAttemptId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder(applicationAttemptId_).mergeFrom(value).buildPartial();
          } else {
            applicationAttemptId_ = value;
          }
          onChanged();
        } else {
          applicationAttemptIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder clearApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = null;
          onChanged();
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder getApplicationAttemptIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationAttemptIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
        if (applicationAttemptIdBuilder_ != null) {
          return applicationAttemptIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationAttemptId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> 
          getApplicationAttemptIdFieldBuilder() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder>(
                  getApplicationAttemptId(),
                  getParentForChildren(),
                  isClean());
          applicationAttemptId_ = null;
        }
        return applicationAttemptIdBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetApplicationAttemptReportRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetApplicationAttemptReportRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetApplicationAttemptReportRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetApplicationAttemptReportRequestProto>() {
      public GetApplicationAttemptReportRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetApplicationAttemptReportRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetApplicationAttemptReportRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetApplicationAttemptReportRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetApplicationAttemptReportResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetApplicationAttemptReportResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptReportProto application_attempt_report = 1;</code>
     */
    boolean hasApplicationAttemptReport();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptReportProto application_attempt_report = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto getApplicationAttemptReport();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptReportProto application_attempt_report = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder getApplicationAttemptReportOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetApplicationAttemptReportResponseProto}
   */
  public  static final class GetApplicationAttemptReportResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetApplicationAttemptReportResponseProto)
      GetApplicationAttemptReportResponseProtoOrBuilder {
    // Use GetApplicationAttemptReportResponseProto.newBuilder() to construct.
    private GetApplicationAttemptReportResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetApplicationAttemptReportResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetApplicationAttemptReportResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationAttemptReport_.toBuilder();
              }
              applicationAttemptReport_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationAttemptReport_);
                applicationAttemptReport_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptReportResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptReportResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATION_ATTEMPT_REPORT_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto applicationAttemptReport_;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptReportProto application_attempt_report = 1;</code>
     */
    public boolean hasApplicationAttemptReport() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptReportProto application_attempt_report = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto getApplicationAttemptReport() {
      return applicationAttemptReport_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.getDefaultInstance() : applicationAttemptReport_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptReportProto application_attempt_report = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder getApplicationAttemptReportOrBuilder() {
      return applicationAttemptReport_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.getDefaultInstance() : applicationAttemptReport_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationAttemptReport());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationAttemptReport());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto) obj;

      boolean result = true;
      result = result && (hasApplicationAttemptReport() == other.hasApplicationAttemptReport());
      if (hasApplicationAttemptReport()) {
        result = result && getApplicationAttemptReport()
            .equals(other.getApplicationAttemptReport());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationAttemptReport()) {
        hash = (37 * hash) + APPLICATION_ATTEMPT_REPORT_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationAttemptReport().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetApplicationAttemptReportResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetApplicationAttemptReportResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptReportResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptReportResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationAttemptReportFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationAttemptReportBuilder_ == null) {
          applicationAttemptReport_ = null;
        } else {
          applicationAttemptReportBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptReportResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationAttemptReportBuilder_ == null) {
          result.applicationAttemptReport_ = applicationAttemptReport_;
        } else {
          result.applicationAttemptReport_ = applicationAttemptReportBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto.getDefaultInstance()) return this;
        if (other.hasApplicationAttemptReport()) {
          mergeApplicationAttemptReport(other.getApplicationAttemptReport());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto applicationAttemptReport_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder> applicationAttemptReportBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptReportProto application_attempt_report = 1;</code>
       */
      public boolean hasApplicationAttemptReport() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptReportProto application_attempt_report = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto getApplicationAttemptReport() {
        if (applicationAttemptReportBuilder_ == null) {
          return applicationAttemptReport_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.getDefaultInstance() : applicationAttemptReport_;
        } else {
          return applicationAttemptReportBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptReportProto application_attempt_report = 1;</code>
       */
      public Builder setApplicationAttemptReport(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto value) {
        if (applicationAttemptReportBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationAttemptReport_ = value;
          onChanged();
        } else {
          applicationAttemptReportBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptReportProto application_attempt_report = 1;</code>
       */
      public Builder setApplicationAttemptReport(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder builderForValue) {
        if (applicationAttemptReportBuilder_ == null) {
          applicationAttemptReport_ = builderForValue.build();
          onChanged();
        } else {
          applicationAttemptReportBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptReportProto application_attempt_report = 1;</code>
       */
      public Builder mergeApplicationAttemptReport(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto value) {
        if (applicationAttemptReportBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationAttemptReport_ != null &&
              applicationAttemptReport_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.getDefaultInstance()) {
            applicationAttemptReport_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.newBuilder(applicationAttemptReport_).mergeFrom(value).buildPartial();
          } else {
            applicationAttemptReport_ = value;
          }
          onChanged();
        } else {
          applicationAttemptReportBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptReportProto application_attempt_report = 1;</code>
       */
      public Builder clearApplicationAttemptReport() {
        if (applicationAttemptReportBuilder_ == null) {
          applicationAttemptReport_ = null;
          onChanged();
        } else {
          applicationAttemptReportBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptReportProto application_attempt_report = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder getApplicationAttemptReportBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationAttemptReportFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptReportProto application_attempt_report = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder getApplicationAttemptReportOrBuilder() {
        if (applicationAttemptReportBuilder_ != null) {
          return applicationAttemptReportBuilder_.getMessageOrBuilder();
        } else {
          return applicationAttemptReport_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.getDefaultInstance() : applicationAttemptReport_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptReportProto application_attempt_report = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder> 
          getApplicationAttemptReportFieldBuilder() {
        if (applicationAttemptReportBuilder_ == null) {
          applicationAttemptReportBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder>(
                  getApplicationAttemptReport(),
                  getParentForChildren(),
                  isClean());
          applicationAttemptReport_ = null;
        }
        return applicationAttemptReportBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetApplicationAttemptReportResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetApplicationAttemptReportResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetApplicationAttemptReportResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetApplicationAttemptReportResponseProto>() {
      public GetApplicationAttemptReportResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetApplicationAttemptReportResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetApplicationAttemptReportResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetApplicationAttemptReportResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptReportResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetApplicationAttemptsRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetApplicationAttemptsRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetApplicationAttemptsRequestProto}
   */
  public  static final class GetApplicationAttemptsRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetApplicationAttemptsRequestProto)
      GetApplicationAttemptsRequestProtoOrBuilder {
    // Use GetApplicationAttemptsRequestProto.newBuilder() to construct.
    private GetApplicationAttemptsRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetApplicationAttemptsRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetApplicationAttemptsRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptsRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptsRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATION_ID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationId());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationId());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetApplicationAttemptsRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetApplicationAttemptsRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptsRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptsRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptsRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder mergeApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != null &&
              applicationId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  getApplicationId(),
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetApplicationAttemptsRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetApplicationAttemptsRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetApplicationAttemptsRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetApplicationAttemptsRequestProto>() {
      public GetApplicationAttemptsRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetApplicationAttemptsRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetApplicationAttemptsRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetApplicationAttemptsRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetApplicationAttemptsResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetApplicationAttemptsResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto> 
        getApplicationAttemptsList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto getApplicationAttempts(int index);
    /**
     * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
     */
    int getApplicationAttemptsCount();
    /**
     * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder> 
        getApplicationAttemptsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder getApplicationAttemptsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetApplicationAttemptsResponseProto}
   */
  public  static final class GetApplicationAttemptsResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetApplicationAttemptsResponseProto)
      GetApplicationAttemptsResponseProtoOrBuilder {
    // Use GetApplicationAttemptsResponseProto.newBuilder() to construct.
    private GetApplicationAttemptsResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetApplicationAttemptsResponseProto() {
      applicationAttempts_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetApplicationAttemptsResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                applicationAttempts_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              applicationAttempts_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          applicationAttempts_ = java.util.Collections.unmodifiableList(applicationAttempts_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptsResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptsResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto.Builder.class);
    }

    public static final int APPLICATION_ATTEMPTS_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto> applicationAttempts_;
    /**
     * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto> getApplicationAttemptsList() {
      return applicationAttempts_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder> 
        getApplicationAttemptsOrBuilderList() {
      return applicationAttempts_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
     */
    public int getApplicationAttemptsCount() {
      return applicationAttempts_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto getApplicationAttempts(int index) {
      return applicationAttempts_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder getApplicationAttemptsOrBuilder(
        int index) {
      return applicationAttempts_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < applicationAttempts_.size(); i++) {
        output.writeMessage(1, applicationAttempts_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < applicationAttempts_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationAttempts_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto) obj;

      boolean result = true;
      result = result && getApplicationAttemptsList()
          .equals(other.getApplicationAttemptsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getApplicationAttemptsCount() > 0) {
        hash = (37 * hash) + APPLICATION_ATTEMPTS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationAttemptsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetApplicationAttemptsResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetApplicationAttemptsResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptsResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptsResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationAttemptsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationAttemptsBuilder_ == null) {
          applicationAttempts_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          applicationAttemptsBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetApplicationAttemptsResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (applicationAttemptsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            applicationAttempts_ = java.util.Collections.unmodifiableList(applicationAttempts_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.applicationAttempts_ = applicationAttempts_;
        } else {
          result.applicationAttempts_ = applicationAttemptsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto.getDefaultInstance()) return this;
        if (applicationAttemptsBuilder_ == null) {
          if (!other.applicationAttempts_.isEmpty()) {
            if (applicationAttempts_.isEmpty()) {
              applicationAttempts_ = other.applicationAttempts_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureApplicationAttemptsIsMutable();
              applicationAttempts_.addAll(other.applicationAttempts_);
            }
            onChanged();
          }
        } else {
          if (!other.applicationAttempts_.isEmpty()) {
            if (applicationAttemptsBuilder_.isEmpty()) {
              applicationAttemptsBuilder_.dispose();
              applicationAttemptsBuilder_ = null;
              applicationAttempts_ = other.applicationAttempts_;
              bitField0_ = (bitField0_ & ~0x00000001);
              applicationAttemptsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getApplicationAttemptsFieldBuilder() : null;
            } else {
              applicationAttemptsBuilder_.addAllMessages(other.applicationAttempts_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto> applicationAttempts_ =
        java.util.Collections.emptyList();
      private void ensureApplicationAttemptsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          applicationAttempts_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto>(applicationAttempts_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder> applicationAttemptsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto> getApplicationAttemptsList() {
        if (applicationAttemptsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(applicationAttempts_);
        } else {
          return applicationAttemptsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public int getApplicationAttemptsCount() {
        if (applicationAttemptsBuilder_ == null) {
          return applicationAttempts_.size();
        } else {
          return applicationAttemptsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto getApplicationAttempts(int index) {
        if (applicationAttemptsBuilder_ == null) {
          return applicationAttempts_.get(index);
        } else {
          return applicationAttemptsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public Builder setApplicationAttempts(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto value) {
        if (applicationAttemptsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationAttemptsIsMutable();
          applicationAttempts_.set(index, value);
          onChanged();
        } else {
          applicationAttemptsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public Builder setApplicationAttempts(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder builderForValue) {
        if (applicationAttemptsBuilder_ == null) {
          ensureApplicationAttemptsIsMutable();
          applicationAttempts_.set(index, builderForValue.build());
          onChanged();
        } else {
          applicationAttemptsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public Builder addApplicationAttempts(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto value) {
        if (applicationAttemptsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationAttemptsIsMutable();
          applicationAttempts_.add(value);
          onChanged();
        } else {
          applicationAttemptsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public Builder addApplicationAttempts(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto value) {
        if (applicationAttemptsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationAttemptsIsMutable();
          applicationAttempts_.add(index, value);
          onChanged();
        } else {
          applicationAttemptsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public Builder addApplicationAttempts(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder builderForValue) {
        if (applicationAttemptsBuilder_ == null) {
          ensureApplicationAttemptsIsMutable();
          applicationAttempts_.add(builderForValue.build());
          onChanged();
        } else {
          applicationAttemptsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public Builder addApplicationAttempts(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder builderForValue) {
        if (applicationAttemptsBuilder_ == null) {
          ensureApplicationAttemptsIsMutable();
          applicationAttempts_.add(index, builderForValue.build());
          onChanged();
        } else {
          applicationAttemptsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public Builder addAllApplicationAttempts(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto> values) {
        if (applicationAttemptsBuilder_ == null) {
          ensureApplicationAttemptsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, applicationAttempts_);
          onChanged();
        } else {
          applicationAttemptsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public Builder clearApplicationAttempts() {
        if (applicationAttemptsBuilder_ == null) {
          applicationAttempts_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          applicationAttemptsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public Builder removeApplicationAttempts(int index) {
        if (applicationAttemptsBuilder_ == null) {
          ensureApplicationAttemptsIsMutable();
          applicationAttempts_.remove(index);
          onChanged();
        } else {
          applicationAttemptsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder getApplicationAttemptsBuilder(
          int index) {
        return getApplicationAttemptsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder getApplicationAttemptsOrBuilder(
          int index) {
        if (applicationAttemptsBuilder_ == null) {
          return applicationAttempts_.get(index);  } else {
          return applicationAttemptsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder> 
           getApplicationAttemptsOrBuilderList() {
        if (applicationAttemptsBuilder_ != null) {
          return applicationAttemptsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(applicationAttempts_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder addApplicationAttemptsBuilder() {
        return getApplicationAttemptsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder addApplicationAttemptsBuilder(
          int index) {
        return getApplicationAttemptsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationAttemptReportProto application_attempts = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder> 
           getApplicationAttemptsBuilderList() {
        return getApplicationAttemptsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder> 
          getApplicationAttemptsFieldBuilder() {
        if (applicationAttemptsBuilder_ == null) {
          applicationAttemptsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder>(
                  applicationAttempts_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          applicationAttempts_ = null;
        }
        return applicationAttemptsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetApplicationAttemptsResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetApplicationAttemptsResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetApplicationAttemptsResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetApplicationAttemptsResponseProto>() {
      public GetApplicationAttemptsResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetApplicationAttemptsResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetApplicationAttemptsResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetApplicationAttemptsResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetApplicationAttemptsResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetContainerReportRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetContainerReportRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetContainerReportRequestProto}
   */
  public  static final class GetContainerReportRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetContainerReportRequestProto)
      GetContainerReportRequestProtoOrBuilder {
    // Use GetContainerReportRequestProto.newBuilder() to construct.
    private GetContainerReportRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetContainerReportRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetContainerReportRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerReportRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerReportRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getContainerId());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getContainerId());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetContainerReportRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetContainerReportRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerReportRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerReportRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = null;
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerReportRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != null &&
              containerId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = null;
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  getContainerId(),
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetContainerReportRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetContainerReportRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetContainerReportRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetContainerReportRequestProto>() {
      public GetContainerReportRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetContainerReportRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetContainerReportRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetContainerReportRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetContainerReportResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetContainerReportResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ContainerReportProto container_report = 1;</code>
     */
    boolean hasContainerReport();
    /**
     * <code>optional .hadoop.yarn.ContainerReportProto container_report = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto getContainerReport();
    /**
     * <code>optional .hadoop.yarn.ContainerReportProto container_report = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder getContainerReportOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetContainerReportResponseProto}
   */
  public  static final class GetContainerReportResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetContainerReportResponseProto)
      GetContainerReportResponseProtoOrBuilder {
    // Use GetContainerReportResponseProto.newBuilder() to construct.
    private GetContainerReportResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetContainerReportResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetContainerReportResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerReport_.toBuilder();
              }
              containerReport_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerReport_);
                containerReport_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerReportResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerReportResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto.Builder.class);
    }

    private int bitField0_;
    public static final int CONTAINER_REPORT_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto containerReport_;
    /**
     * <code>optional .hadoop.yarn.ContainerReportProto container_report = 1;</code>
     */
    public boolean hasContainerReport() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerReportProto container_report = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto getContainerReport() {
      return containerReport_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.getDefaultInstance() : containerReport_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerReportProto container_report = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder getContainerReportOrBuilder() {
      return containerReport_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.getDefaultInstance() : containerReport_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getContainerReport());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getContainerReport());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto) obj;

      boolean result = true;
      result = result && (hasContainerReport() == other.hasContainerReport());
      if (hasContainerReport()) {
        result = result && getContainerReport()
            .equals(other.getContainerReport());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerReport()) {
        hash = (37 * hash) + CONTAINER_REPORT_FIELD_NUMBER;
        hash = (53 * hash) + getContainerReport().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetContainerReportResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetContainerReportResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerReportResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerReportResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainerReportFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containerReportBuilder_ == null) {
          containerReport_ = null;
        } else {
          containerReportBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainerReportResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerReportBuilder_ == null) {
          result.containerReport_ = containerReport_;
        } else {
          result.containerReport_ = containerReportBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto.getDefaultInstance()) return this;
        if (other.hasContainerReport()) {
          mergeContainerReport(other.getContainerReport());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto containerReport_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder> containerReportBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerReportProto container_report = 1;</code>
       */
      public boolean hasContainerReport() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerReportProto container_report = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto getContainerReport() {
        if (containerReportBuilder_ == null) {
          return containerReport_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.getDefaultInstance() : containerReport_;
        } else {
          return containerReportBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerReportProto container_report = 1;</code>
       */
      public Builder setContainerReport(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto value) {
        if (containerReportBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerReport_ = value;
          onChanged();
        } else {
          containerReportBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerReportProto container_report = 1;</code>
       */
      public Builder setContainerReport(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder builderForValue) {
        if (containerReportBuilder_ == null) {
          containerReport_ = builderForValue.build();
          onChanged();
        } else {
          containerReportBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerReportProto container_report = 1;</code>
       */
      public Builder mergeContainerReport(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto value) {
        if (containerReportBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerReport_ != null &&
              containerReport_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.getDefaultInstance()) {
            containerReport_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.newBuilder(containerReport_).mergeFrom(value).buildPartial();
          } else {
            containerReport_ = value;
          }
          onChanged();
        } else {
          containerReportBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerReportProto container_report = 1;</code>
       */
      public Builder clearContainerReport() {
        if (containerReportBuilder_ == null) {
          containerReport_ = null;
          onChanged();
        } else {
          containerReportBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerReportProto container_report = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder getContainerReportBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerReportFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerReportProto container_report = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder getContainerReportOrBuilder() {
        if (containerReportBuilder_ != null) {
          return containerReportBuilder_.getMessageOrBuilder();
        } else {
          return containerReport_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.getDefaultInstance() : containerReport_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerReportProto container_report = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder> 
          getContainerReportFieldBuilder() {
        if (containerReportBuilder_ == null) {
          containerReportBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder>(
                  getContainerReport(),
                  getParentForChildren(),
                  isClean());
          containerReport_ = null;
        }
        return containerReportBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetContainerReportResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetContainerReportResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetContainerReportResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetContainerReportResponseProto>() {
      public GetContainerReportResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetContainerReportResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetContainerReportResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetContainerReportResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainerReportResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetContainersRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetContainersRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    boolean hasApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetContainersRequestProto}
   */
  public  static final class GetContainersRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetContainersRequestProto)
      GetContainersRequestProtoOrBuilder {
    // Use GetContainersRequestProto.newBuilder() to construct.
    private GetContainersRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetContainersRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetContainersRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationAttemptId_.toBuilder();
              }
              applicationAttemptId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationAttemptId_);
                applicationAttemptId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainersRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainersRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATION_ATTEMPT_ID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    public boolean hasApplicationAttemptId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
      return applicationAttemptId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
      return applicationAttemptId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationAttemptId());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationAttemptId());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto) obj;

      boolean result = true;
      result = result && (hasApplicationAttemptId() == other.hasApplicationAttemptId());
      if (hasApplicationAttemptId()) {
        result = result && getApplicationAttemptId()
            .equals(other.getApplicationAttemptId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationAttemptId()) {
        hash = (37 * hash) + APPLICATION_ATTEMPT_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationAttemptId().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetContainersRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetContainersRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainersRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainersRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationAttemptIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = null;
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainersRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationAttemptIdBuilder_ == null) {
          result.applicationAttemptId_ = applicationAttemptId_;
        } else {
          result.applicationAttemptId_ = applicationAttemptIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationAttemptId()) {
          mergeApplicationAttemptId(other.getApplicationAttemptId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> applicationAttemptIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public boolean hasApplicationAttemptId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          return applicationAttemptId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
        } else {
          return applicationAttemptIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder setApplicationAttemptId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationAttemptId_ = value;
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder setApplicationAttemptId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder builderForValue) {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = builderForValue.build();
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder mergeApplicationAttemptId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationAttemptId_ != null &&
              applicationAttemptId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) {
            applicationAttemptId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder(applicationAttemptId_).mergeFrom(value).buildPartial();
          } else {
            applicationAttemptId_ = value;
          }
          onChanged();
        } else {
          applicationAttemptIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder clearApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = null;
          onChanged();
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder getApplicationAttemptIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationAttemptIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
        if (applicationAttemptIdBuilder_ != null) {
          return applicationAttemptIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationAttemptId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> 
          getApplicationAttemptIdFieldBuilder() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder>(
                  getApplicationAttemptId(),
                  getParentForChildren(),
                  isClean());
          applicationAttemptId_ = null;
        }
        return applicationAttemptIdBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetContainersRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetContainersRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetContainersRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetContainersRequestProto>() {
      public GetContainersRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetContainersRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetContainersRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetContainersRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetContainersResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetContainersResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto> 
        getContainersList();
    /**
     * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto getContainers(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
     */
    int getContainersCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder> 
        getContainersOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder getContainersOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetContainersResponseProto}
   */
  public  static final class GetContainersResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetContainersResponseProto)
      GetContainersResponseProtoOrBuilder {
    // Use GetContainersResponseProto.newBuilder() to construct.
    private GetContainersResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetContainersResponseProto() {
      containers_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetContainersResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                containers_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              containers_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          containers_ = java.util.Collections.unmodifiableList(containers_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainersResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainersResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto.Builder.class);
    }

    public static final int CONTAINERS_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto> containers_;
    /**
     * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto> getContainersList() {
      return containers_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder> 
        getContainersOrBuilderList() {
      return containers_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
     */
    public int getContainersCount() {
      return containers_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto getContainers(int index) {
      return containers_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder getContainersOrBuilder(
        int index) {
      return containers_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < containers_.size(); i++) {
        output.writeMessage(1, containers_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < containers_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containers_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto) obj;

      boolean result = true;
      result = result && getContainersList()
          .equals(other.getContainersList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getContainersCount() > 0) {
        hash = (37 * hash) + CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getContainersList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetContainersResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetContainersResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainersResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainersResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainersFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containersBuilder_ == null) {
          containers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          containersBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetContainersResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (containersBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            containers_ = java.util.Collections.unmodifiableList(containers_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.containers_ = containers_;
        } else {
          result.containers_ = containersBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto.getDefaultInstance()) return this;
        if (containersBuilder_ == null) {
          if (!other.containers_.isEmpty()) {
            if (containers_.isEmpty()) {
              containers_ = other.containers_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureContainersIsMutable();
              containers_.addAll(other.containers_);
            }
            onChanged();
          }
        } else {
          if (!other.containers_.isEmpty()) {
            if (containersBuilder_.isEmpty()) {
              containersBuilder_.dispose();
              containersBuilder_ = null;
              containers_ = other.containers_;
              bitField0_ = (bitField0_ & ~0x00000001);
              containersBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getContainersFieldBuilder() : null;
            } else {
              containersBuilder_.addAllMessages(other.containers_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto> containers_ =
        java.util.Collections.emptyList();
      private void ensureContainersIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          containers_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto>(containers_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder> containersBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto> getContainersList() {
        if (containersBuilder_ == null) {
          return java.util.Collections.unmodifiableList(containers_);
        } else {
          return containersBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public int getContainersCount() {
        if (containersBuilder_ == null) {
          return containers_.size();
        } else {
          return containersBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto getContainers(int index) {
        if (containersBuilder_ == null) {
          return containers_.get(index);
        } else {
          return containersBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public Builder setContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto value) {
        if (containersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersIsMutable();
          containers_.set(index, value);
          onChanged();
        } else {
          containersBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public Builder setContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder builderForValue) {
        if (containersBuilder_ == null) {
          ensureContainersIsMutable();
          containers_.set(index, builderForValue.build());
          onChanged();
        } else {
          containersBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public Builder addContainers(org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto value) {
        if (containersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersIsMutable();
          containers_.add(value);
          onChanged();
        } else {
          containersBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public Builder addContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto value) {
        if (containersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersIsMutable();
          containers_.add(index, value);
          onChanged();
        } else {
          containersBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public Builder addContainers(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder builderForValue) {
        if (containersBuilder_ == null) {
          ensureContainersIsMutable();
          containers_.add(builderForValue.build());
          onChanged();
        } else {
          containersBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public Builder addContainers(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder builderForValue) {
        if (containersBuilder_ == null) {
          ensureContainersIsMutable();
          containers_.add(index, builderForValue.build());
          onChanged();
        } else {
          containersBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public Builder addAllContainers(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto> values) {
        if (containersBuilder_ == null) {
          ensureContainersIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, containers_);
          onChanged();
        } else {
          containersBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public Builder clearContainers() {
        if (containersBuilder_ == null) {
          containers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          containersBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public Builder removeContainers(int index) {
        if (containersBuilder_ == null) {
          ensureContainersIsMutable();
          containers_.remove(index);
          onChanged();
        } else {
          containersBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder getContainersBuilder(
          int index) {
        return getContainersFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder getContainersOrBuilder(
          int index) {
        if (containersBuilder_ == null) {
          return containers_.get(index);  } else {
          return containersBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder> 
           getContainersOrBuilderList() {
        if (containersBuilder_ != null) {
          return containersBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(containers_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder addContainersBuilder() {
        return getContainersFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder addContainersBuilder(
          int index) {
        return getContainersFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerReportProto containers = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder> 
           getContainersBuilderList() {
        return getContainersFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder> 
          getContainersFieldBuilder() {
        if (containersBuilder_ == null) {
          containersBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder>(
                  containers_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          containers_ = null;
        }
        return containersBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetContainersResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetContainersResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetContainersResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetContainersResponseProto>() {
      public GetContainersResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetContainersResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetContainersResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetContainersResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetContainersResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface UseSharedCacheResourceRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.UseSharedCacheResourceRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();

    /**
     * <code>optional string resourceKey = 2;</code>
     */
    boolean hasResourceKey();
    /**
     * <code>optional string resourceKey = 2;</code>
     */
    java.lang.String getResourceKey();
    /**
     * <code>optional string resourceKey = 2;</code>
     */
    com.google.protobuf.ByteString
        getResourceKeyBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.UseSharedCacheResourceRequestProto}
   */
  public  static final class UseSharedCacheResourceRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.UseSharedCacheResourceRequestProto)
      UseSharedCacheResourceRequestProtoOrBuilder {
    // Use UseSharedCacheResourceRequestProto.newBuilder() to construct.
    private UseSharedCacheResourceRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private UseSharedCacheResourceRequestProto() {
      resourceKey_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private UseSharedCacheResourceRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              resourceKey_ = bs;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UseSharedCacheResourceRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UseSharedCacheResourceRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATIONID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }

    public static final int RESOURCEKEY_FIELD_NUMBER = 2;
    private volatile java.lang.Object resourceKey_;
    /**
     * <code>optional string resourceKey = 2;</code>
     */
    public boolean hasResourceKey() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string resourceKey = 2;</code>
     */
    public java.lang.String getResourceKey() {
      java.lang.Object ref = resourceKey_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          resourceKey_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string resourceKey = 2;</code>
     */
    public com.google.protobuf.ByteString
        getResourceKeyBytes() {
      java.lang.Object ref = resourceKey_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        resourceKey_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, resourceKey_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, resourceKey_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasResourceKey() == other.hasResourceKey());
      if (hasResourceKey()) {
        result = result && getResourceKey()
            .equals(other.getResourceKey());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATIONID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasResourceKey()) {
        hash = (37 * hash) + RESOURCEKEY_FIELD_NUMBER;
        hash = (53 * hash) + getResourceKey().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.UseSharedCacheResourceRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.UseSharedCacheResourceRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UseSharedCacheResourceRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UseSharedCacheResourceRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        resourceKey_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UseSharedCacheResourceRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.resourceKey_ = resourceKey_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasResourceKey()) {
          bitField0_ |= 0x00000002;
          resourceKey_ = other.resourceKey_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder setApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder setApplicationId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder mergeApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != null &&
              applicationId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  getApplicationId(),
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }

      private java.lang.Object resourceKey_ = "";
      /**
       * <code>optional string resourceKey = 2;</code>
       */
      public boolean hasResourceKey() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string resourceKey = 2;</code>
       */
      public java.lang.String getResourceKey() {
        java.lang.Object ref = resourceKey_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            resourceKey_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string resourceKey = 2;</code>
       */
      public com.google.protobuf.ByteString
          getResourceKeyBytes() {
        java.lang.Object ref = resourceKey_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          resourceKey_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string resourceKey = 2;</code>
       */
      public Builder setResourceKey(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        resourceKey_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string resourceKey = 2;</code>
       */
      public Builder clearResourceKey() {
        bitField0_ = (bitField0_ & ~0x00000002);
        resourceKey_ = getDefaultInstance().getResourceKey();
        onChanged();
        return this;
      }
      /**
       * <code>optional string resourceKey = 2;</code>
       */
      public Builder setResourceKeyBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        resourceKey_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.UseSharedCacheResourceRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.UseSharedCacheResourceRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<UseSharedCacheResourceRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<UseSharedCacheResourceRequestProto>() {
      public UseSharedCacheResourceRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new UseSharedCacheResourceRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<UseSharedCacheResourceRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<UseSharedCacheResourceRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface UseSharedCacheResourceResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.UseSharedCacheResourceResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string path = 1;</code>
     */
    boolean hasPath();
    /**
     * <code>optional string path = 1;</code>
     */
    java.lang.String getPath();
    /**
     * <code>optional string path = 1;</code>
     */
    com.google.protobuf.ByteString
        getPathBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.UseSharedCacheResourceResponseProto}
   */
  public  static final class UseSharedCacheResourceResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.UseSharedCacheResourceResponseProto)
      UseSharedCacheResourceResponseProtoOrBuilder {
    // Use UseSharedCacheResourceResponseProto.newBuilder() to construct.
    private UseSharedCacheResourceResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private UseSharedCacheResourceResponseProto() {
      path_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private UseSharedCacheResourceResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              path_ = bs;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UseSharedCacheResourceResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UseSharedCacheResourceResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto.Builder.class);
    }

    private int bitField0_;
    public static final int PATH_FIELD_NUMBER = 1;
    private volatile java.lang.Object path_;
    /**
     * <code>optional string path = 1;</code>
     */
    public boolean hasPath() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string path = 1;</code>
     */
    public java.lang.String getPath() {
      java.lang.Object ref = path_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          path_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string path = 1;</code>
     */
    public com.google.protobuf.ByteString
        getPathBytes() {
      java.lang.Object ref = path_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        path_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, path_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, path_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto) obj;

      boolean result = true;
      result = result && (hasPath() == other.hasPath());
      if (hasPath()) {
        result = result && getPath()
            .equals(other.getPath());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasPath()) {
        hash = (37 * hash) + PATH_FIELD_NUMBER;
        hash = (53 * hash) + getPath().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.UseSharedCacheResourceResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.UseSharedCacheResourceResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UseSharedCacheResourceResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UseSharedCacheResourceResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        path_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_UseSharedCacheResourceResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.path_ = path_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto.getDefaultInstance()) return this;
        if (other.hasPath()) {
          bitField0_ |= 0x00000001;
          path_ = other.path_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object path_ = "";
      /**
       * <code>optional string path = 1;</code>
       */
      public boolean hasPath() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string path = 1;</code>
       */
      public java.lang.String getPath() {
        java.lang.Object ref = path_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            path_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string path = 1;</code>
       */
      public com.google.protobuf.ByteString
          getPathBytes() {
        java.lang.Object ref = path_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          path_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string path = 1;</code>
       */
      public Builder setPath(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        path_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string path = 1;</code>
       */
      public Builder clearPath() {
        bitField0_ = (bitField0_ & ~0x00000001);
        path_ = getDefaultInstance().getPath();
        onChanged();
        return this;
      }
      /**
       * <code>optional string path = 1;</code>
       */
      public Builder setPathBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        path_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.UseSharedCacheResourceResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.UseSharedCacheResourceResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<UseSharedCacheResourceResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<UseSharedCacheResourceResponseProto>() {
      public UseSharedCacheResourceResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new UseSharedCacheResourceResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<UseSharedCacheResourceResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<UseSharedCacheResourceResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.UseSharedCacheResourceResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReleaseSharedCacheResourceRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ReleaseSharedCacheResourceRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();

    /**
     * <code>optional string resourceKey = 2;</code>
     */
    boolean hasResourceKey();
    /**
     * <code>optional string resourceKey = 2;</code>
     */
    java.lang.String getResourceKey();
    /**
     * <code>optional string resourceKey = 2;</code>
     */
    com.google.protobuf.ByteString
        getResourceKeyBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReleaseSharedCacheResourceRequestProto}
   */
  public  static final class ReleaseSharedCacheResourceRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ReleaseSharedCacheResourceRequestProto)
      ReleaseSharedCacheResourceRequestProtoOrBuilder {
    // Use ReleaseSharedCacheResourceRequestProto.newBuilder() to construct.
    private ReleaseSharedCacheResourceRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReleaseSharedCacheResourceRequestProto() {
      resourceKey_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReleaseSharedCacheResourceRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              resourceKey_ = bs;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReleaseSharedCacheResourceRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReleaseSharedCacheResourceRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATIONID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }

    public static final int RESOURCEKEY_FIELD_NUMBER = 2;
    private volatile java.lang.Object resourceKey_;
    /**
     * <code>optional string resourceKey = 2;</code>
     */
    public boolean hasResourceKey() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string resourceKey = 2;</code>
     */
    public java.lang.String getResourceKey() {
      java.lang.Object ref = resourceKey_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          resourceKey_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string resourceKey = 2;</code>
     */
    public com.google.protobuf.ByteString
        getResourceKeyBytes() {
      java.lang.Object ref = resourceKey_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        resourceKey_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, resourceKey_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, resourceKey_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasResourceKey() == other.hasResourceKey());
      if (hasResourceKey()) {
        result = result && getResourceKey()
            .equals(other.getResourceKey());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATIONID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasResourceKey()) {
        hash = (37 * hash) + RESOURCEKEY_FIELD_NUMBER;
        hash = (53 * hash) + getResourceKey().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReleaseSharedCacheResourceRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ReleaseSharedCacheResourceRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReleaseSharedCacheResourceRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReleaseSharedCacheResourceRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        resourceKey_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReleaseSharedCacheResourceRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.resourceKey_ = resourceKey_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasResourceKey()) {
          bitField0_ |= 0x00000002;
          resourceKey_ = other.resourceKey_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder setApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder setApplicationId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder mergeApplicationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != null &&
              applicationId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  getApplicationId(),
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }

      private java.lang.Object resourceKey_ = "";
      /**
       * <code>optional string resourceKey = 2;</code>
       */
      public boolean hasResourceKey() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string resourceKey = 2;</code>
       */
      public java.lang.String getResourceKey() {
        java.lang.Object ref = resourceKey_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            resourceKey_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string resourceKey = 2;</code>
       */
      public com.google.protobuf.ByteString
          getResourceKeyBytes() {
        java.lang.Object ref = resourceKey_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          resourceKey_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string resourceKey = 2;</code>
       */
      public Builder setResourceKey(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        resourceKey_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string resourceKey = 2;</code>
       */
      public Builder clearResourceKey() {
        bitField0_ = (bitField0_ & ~0x00000002);
        resourceKey_ = getDefaultInstance().getResourceKey();
        onChanged();
        return this;
      }
      /**
       * <code>optional string resourceKey = 2;</code>
       */
      public Builder setResourceKeyBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        resourceKey_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReleaseSharedCacheResourceRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReleaseSharedCacheResourceRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReleaseSharedCacheResourceRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<ReleaseSharedCacheResourceRequestProto>() {
      public ReleaseSharedCacheResourceRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ReleaseSharedCacheResourceRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReleaseSharedCacheResourceRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReleaseSharedCacheResourceRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReleaseSharedCacheResourceResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ReleaseSharedCacheResourceResponseProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReleaseSharedCacheResourceResponseProto}
   */
  public  static final class ReleaseSharedCacheResourceResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ReleaseSharedCacheResourceResponseProto)
      ReleaseSharedCacheResourceResponseProtoOrBuilder {
    // Use ReleaseSharedCacheResourceResponseProto.newBuilder() to construct.
    private ReleaseSharedCacheResourceResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReleaseSharedCacheResourceResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReleaseSharedCacheResourceResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReleaseSharedCacheResourceResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReleaseSharedCacheResourceResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReleaseSharedCacheResourceResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ReleaseSharedCacheResourceResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReleaseSharedCacheResourceResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReleaseSharedCacheResourceResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReleaseSharedCacheResourceResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReleaseSharedCacheResourceResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReleaseSharedCacheResourceResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReleaseSharedCacheResourceResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<ReleaseSharedCacheResourceResponseProto>() {
      public ReleaseSharedCacheResourceResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ReleaseSharedCacheResourceResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReleaseSharedCacheResourceResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReleaseSharedCacheResourceResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReleaseSharedCacheResourceResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetNewReservationRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetNewReservationRequestProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetNewReservationRequestProto}
   */
  public  static final class GetNewReservationRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetNewReservationRequestProto)
      GetNewReservationRequestProtoOrBuilder {
    // Use GetNewReservationRequestProto.newBuilder() to construct.
    private GetNewReservationRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetNewReservationRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetNewReservationRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewReservationRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewReservationRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetNewReservationRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetNewReservationRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewReservationRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewReservationRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewReservationRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetNewReservationRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetNewReservationRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetNewReservationRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<GetNewReservationRequestProto>() {
      public GetNewReservationRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetNewReservationRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetNewReservationRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetNewReservationRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetNewReservationResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.GetNewReservationResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
     */
    boolean hasReservationId();
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId();
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetNewReservationResponseProto}
   */
  public  static final class GetNewReservationResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.GetNewReservationResponseProto)
      GetNewReservationResponseProtoOrBuilder {
    // Use GetNewReservationResponseProto.newBuilder() to construct.
    private GetNewReservationResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetNewReservationResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetNewReservationResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = reservationId_.toBuilder();
              }
              reservationId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reservationId_);
                reservationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewReservationResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewReservationResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto.Builder.class);
    }

    private int bitField0_;
    public static final int RESERVATION_ID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto reservationId_;
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
     */
    public boolean hasReservationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId() {
      return reservationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder() {
      return reservationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getReservationId());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getReservationId());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto) obj;

      boolean result = true;
      result = result && (hasReservationId() == other.hasReservationId());
      if (hasReservationId()) {
        result = result && getReservationId()
            .equals(other.getReservationId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasReservationId()) {
        hash = (37 * hash) + RESERVATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getReservationId().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetNewReservationResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.GetNewReservationResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewReservationResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewReservationResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getReservationIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (reservationIdBuilder_ == null) {
          reservationId_ = null;
        } else {
          reservationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_GetNewReservationResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (reservationIdBuilder_ == null) {
          result.reservationId_ = reservationId_;
        } else {
          result.reservationId_ = reservationIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto.getDefaultInstance()) return this;
        if (other.hasReservationId()) {
          mergeReservationId(other.getReservationId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto reservationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder> reservationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public boolean hasReservationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId() {
        if (reservationIdBuilder_ == null) {
          return reservationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
        } else {
          return reservationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public Builder setReservationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto value) {
        if (reservationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reservationId_ = value;
          onChanged();
        } else {
          reservationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public Builder setReservationId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder builderForValue) {
        if (reservationIdBuilder_ == null) {
          reservationId_ = builderForValue.build();
          onChanged();
        } else {
          reservationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public Builder mergeReservationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto value) {
        if (reservationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              reservationId_ != null &&
              reservationId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance()) {
            reservationId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.newBuilder(reservationId_).mergeFrom(value).buildPartial();
          } else {
            reservationId_ = value;
          }
          onChanged();
        } else {
          reservationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public Builder clearReservationId() {
        if (reservationIdBuilder_ == null) {
          reservationId_ = null;
          onChanged();
        } else {
          reservationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder getReservationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getReservationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder() {
        if (reservationIdBuilder_ != null) {
          return reservationIdBuilder_.getMessageOrBuilder();
        } else {
          return reservationId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder> 
          getReservationIdFieldBuilder() {
        if (reservationIdBuilder_ == null) {
          reservationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder>(
                  getReservationId(),
                  getParentForChildren(),
                  isClean());
          reservationId_ = null;
        }
        return reservationIdBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetNewReservationResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetNewReservationResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<GetNewReservationResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<GetNewReservationResponseProto>() {
      public GetNewReservationResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new GetNewReservationResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetNewReservationResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetNewReservationResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.GetNewReservationResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReservationSubmissionRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ReservationSubmissionRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string queue = 1;</code>
     */
    boolean hasQueue();
    /**
     * <code>optional string queue = 1;</code>
     */
    java.lang.String getQueue();
    /**
     * <code>optional string queue = 1;</code>
     */
    com.google.protobuf.ByteString
        getQueueBytes();

    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 2;</code>
     */
    boolean hasReservationDefinition();
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto getReservationDefinition();
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder getReservationDefinitionOrBuilder();

    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 3;</code>
     */
    boolean hasReservationId();
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 3;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId();
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 3;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationSubmissionRequestProto}
   */
  public  static final class ReservationSubmissionRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ReservationSubmissionRequestProto)
      ReservationSubmissionRequestProtoOrBuilder {
    // Use ReservationSubmissionRequestProto.newBuilder() to construct.
    private ReservationSubmissionRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReservationSubmissionRequestProto() {
      queue_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationSubmissionRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              queue_ = bs;
              break;
            }
            case 18: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = reservationDefinition_.toBuilder();
              }
              reservationDefinition_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reservationDefinition_);
                reservationDefinition_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = reservationId_.toBuilder();
              }
              reservationId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reservationId_);
                reservationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationSubmissionRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationSubmissionRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int QUEUE_FIELD_NUMBER = 1;
    private volatile java.lang.Object queue_;
    /**
     * <code>optional string queue = 1;</code>
     */
    public boolean hasQueue() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string queue = 1;</code>
     */
    public java.lang.String getQueue() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queue_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queue = 1;</code>
     */
    public com.google.protobuf.ByteString
        getQueueBytes() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queue_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int RESERVATION_DEFINITION_FIELD_NUMBER = 2;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto reservationDefinition_;
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 2;</code>
     */
    public boolean hasReservationDefinition() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto getReservationDefinition() {
      return reservationDefinition_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance() : reservationDefinition_;
    }
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder getReservationDefinitionOrBuilder() {
      return reservationDefinition_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance() : reservationDefinition_;
    }

    public static final int RESERVATION_ID_FIELD_NUMBER = 3;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto reservationId_;
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 3;</code>
     */
    public boolean hasReservationId() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 3;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId() {
      return reservationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 3;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder() {
      return reservationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, queue_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getReservationDefinition());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getReservationId());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, queue_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getReservationDefinition());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getReservationId());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto) obj;

      boolean result = true;
      result = result && (hasQueue() == other.hasQueue());
      if (hasQueue()) {
        result = result && getQueue()
            .equals(other.getQueue());
      }
      result = result && (hasReservationDefinition() == other.hasReservationDefinition());
      if (hasReservationDefinition()) {
        result = result && getReservationDefinition()
            .equals(other.getReservationDefinition());
      }
      result = result && (hasReservationId() == other.hasReservationId());
      if (hasReservationId()) {
        result = result && getReservationId()
            .equals(other.getReservationId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasQueue()) {
        hash = (37 * hash) + QUEUE_FIELD_NUMBER;
        hash = (53 * hash) + getQueue().hashCode();
      }
      if (hasReservationDefinition()) {
        hash = (37 * hash) + RESERVATION_DEFINITION_FIELD_NUMBER;
        hash = (53 * hash) + getReservationDefinition().hashCode();
      }
      if (hasReservationId()) {
        hash = (37 * hash) + RESERVATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getReservationId().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationSubmissionRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ReservationSubmissionRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationSubmissionRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationSubmissionRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getReservationDefinitionFieldBuilder();
          getReservationIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        queue_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        if (reservationDefinitionBuilder_ == null) {
          reservationDefinition_ = null;
        } else {
          reservationDefinitionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (reservationIdBuilder_ == null) {
          reservationId_ = null;
        } else {
          reservationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationSubmissionRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.queue_ = queue_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (reservationDefinitionBuilder_ == null) {
          result.reservationDefinition_ = reservationDefinition_;
        } else {
          result.reservationDefinition_ = reservationDefinitionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (reservationIdBuilder_ == null) {
          result.reservationId_ = reservationId_;
        } else {
          result.reservationId_ = reservationIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto.getDefaultInstance()) return this;
        if (other.hasQueue()) {
          bitField0_ |= 0x00000001;
          queue_ = other.queue_;
          onChanged();
        }
        if (other.hasReservationDefinition()) {
          mergeReservationDefinition(other.getReservationDefinition());
        }
        if (other.hasReservationId()) {
          mergeReservationId(other.getReservationId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object queue_ = "";
      /**
       * <code>optional string queue = 1;</code>
       */
      public boolean hasQueue() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string queue = 1;</code>
       */
      public java.lang.String getQueue() {
        java.lang.Object ref = queue_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            queue_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queue = 1;</code>
       */
      public com.google.protobuf.ByteString
          getQueueBytes() {
        java.lang.Object ref = queue_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queue_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queue = 1;</code>
       */
      public Builder setQueue(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queue_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 1;</code>
       */
      public Builder clearQueue() {
        bitField0_ = (bitField0_ & ~0x00000001);
        queue_ = getDefaultInstance().getQueue();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 1;</code>
       */
      public Builder setQueueBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queue_ = value;
        onChanged();
        return this;
      }

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto reservationDefinition_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder> reservationDefinitionBuilder_;
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 2;</code>
       */
      public boolean hasReservationDefinition() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto getReservationDefinition() {
        if (reservationDefinitionBuilder_ == null) {
          return reservationDefinition_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance() : reservationDefinition_;
        } else {
          return reservationDefinitionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 2;</code>
       */
      public Builder setReservationDefinition(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto value) {
        if (reservationDefinitionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reservationDefinition_ = value;
          onChanged();
        } else {
          reservationDefinitionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 2;</code>
       */
      public Builder setReservationDefinition(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder builderForValue) {
        if (reservationDefinitionBuilder_ == null) {
          reservationDefinition_ = builderForValue.build();
          onChanged();
        } else {
          reservationDefinitionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 2;</code>
       */
      public Builder mergeReservationDefinition(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto value) {
        if (reservationDefinitionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              reservationDefinition_ != null &&
              reservationDefinition_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance()) {
            reservationDefinition_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.newBuilder(reservationDefinition_).mergeFrom(value).buildPartial();
          } else {
            reservationDefinition_ = value;
          }
          onChanged();
        } else {
          reservationDefinitionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 2;</code>
       */
      public Builder clearReservationDefinition() {
        if (reservationDefinitionBuilder_ == null) {
          reservationDefinition_ = null;
          onChanged();
        } else {
          reservationDefinitionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder getReservationDefinitionBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getReservationDefinitionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder getReservationDefinitionOrBuilder() {
        if (reservationDefinitionBuilder_ != null) {
          return reservationDefinitionBuilder_.getMessageOrBuilder();
        } else {
          return reservationDefinition_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance() : reservationDefinition_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder> 
          getReservationDefinitionFieldBuilder() {
        if (reservationDefinitionBuilder_ == null) {
          reservationDefinitionBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder>(
                  getReservationDefinition(),
                  getParentForChildren(),
                  isClean());
          reservationDefinition_ = null;
        }
        return reservationDefinitionBuilder_;
      }

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto reservationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder> reservationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 3;</code>
       */
      public boolean hasReservationId() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId() {
        if (reservationIdBuilder_ == null) {
          return reservationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
        } else {
          return reservationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 3;</code>
       */
      public Builder setReservationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto value) {
        if (reservationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reservationId_ = value;
          onChanged();
        } else {
          reservationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 3;</code>
       */
      public Builder setReservationId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder builderForValue) {
        if (reservationIdBuilder_ == null) {
          reservationId_ = builderForValue.build();
          onChanged();
        } else {
          reservationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 3;</code>
       */
      public Builder mergeReservationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto value) {
        if (reservationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              reservationId_ != null &&
              reservationId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance()) {
            reservationId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.newBuilder(reservationId_).mergeFrom(value).buildPartial();
          } else {
            reservationId_ = value;
          }
          onChanged();
        } else {
          reservationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 3;</code>
       */
      public Builder clearReservationId() {
        if (reservationIdBuilder_ == null) {
          reservationId_ = null;
          onChanged();
        } else {
          reservationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder getReservationIdBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getReservationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 3;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder() {
        if (reservationIdBuilder_ != null) {
          return reservationIdBuilder_.getMessageOrBuilder();
        } else {
          return reservationId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder> 
          getReservationIdFieldBuilder() {
        if (reservationIdBuilder_ == null) {
          reservationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder>(
                  getReservationId(),
                  getParentForChildren(),
                  isClean());
          reservationId_ = null;
        }
        return reservationIdBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationSubmissionRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationSubmissionRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReservationSubmissionRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<ReservationSubmissionRequestProto>() {
      public ReservationSubmissionRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ReservationSubmissionRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReservationSubmissionRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationSubmissionRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReservationSubmissionResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ReservationSubmissionResponseProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationSubmissionResponseProto}
   */
  public  static final class ReservationSubmissionResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ReservationSubmissionResponseProto)
      ReservationSubmissionResponseProtoOrBuilder {
    // Use ReservationSubmissionResponseProto.newBuilder() to construct.
    private ReservationSubmissionResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReservationSubmissionResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationSubmissionResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationSubmissionResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationSubmissionResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationSubmissionResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ReservationSubmissionResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationSubmissionResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationSubmissionResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationSubmissionResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationSubmissionResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationSubmissionResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReservationSubmissionResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<ReservationSubmissionResponseProto>() {
      public ReservationSubmissionResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ReservationSubmissionResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReservationSubmissionResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationSubmissionResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationSubmissionResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReservationUpdateRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ReservationUpdateRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
     */
    boolean hasReservationDefinition();
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto getReservationDefinition();
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder getReservationDefinitionOrBuilder();

    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 2;</code>
     */
    boolean hasReservationId();
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId();
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 2;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationUpdateRequestProto}
   */
  public  static final class ReservationUpdateRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ReservationUpdateRequestProto)
      ReservationUpdateRequestProtoOrBuilder {
    // Use ReservationUpdateRequestProto.newBuilder() to construct.
    private ReservationUpdateRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReservationUpdateRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationUpdateRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = reservationDefinition_.toBuilder();
              }
              reservationDefinition_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reservationDefinition_);
                reservationDefinition_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = reservationId_.toBuilder();
              }
              reservationId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reservationId_);
                reservationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationUpdateRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationUpdateRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int RESERVATION_DEFINITION_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto reservationDefinition_;
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
     */
    public boolean hasReservationDefinition() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto getReservationDefinition() {
      return reservationDefinition_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance() : reservationDefinition_;
    }
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder getReservationDefinitionOrBuilder() {
      return reservationDefinition_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance() : reservationDefinition_;
    }

    public static final int RESERVATION_ID_FIELD_NUMBER = 2;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto reservationId_;
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 2;</code>
     */
    public boolean hasReservationId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId() {
      return reservationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 2;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder() {
      return reservationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getReservationDefinition());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getReservationId());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getReservationDefinition());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getReservationId());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto) obj;

      boolean result = true;
      result = result && (hasReservationDefinition() == other.hasReservationDefinition());
      if (hasReservationDefinition()) {
        result = result && getReservationDefinition()
            .equals(other.getReservationDefinition());
      }
      result = result && (hasReservationId() == other.hasReservationId());
      if (hasReservationId()) {
        result = result && getReservationId()
            .equals(other.getReservationId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasReservationDefinition()) {
        hash = (37 * hash) + RESERVATION_DEFINITION_FIELD_NUMBER;
        hash = (53 * hash) + getReservationDefinition().hashCode();
      }
      if (hasReservationId()) {
        hash = (37 * hash) + RESERVATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getReservationId().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationUpdateRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ReservationUpdateRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationUpdateRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationUpdateRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getReservationDefinitionFieldBuilder();
          getReservationIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (reservationDefinitionBuilder_ == null) {
          reservationDefinition_ = null;
        } else {
          reservationDefinitionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (reservationIdBuilder_ == null) {
          reservationId_ = null;
        } else {
          reservationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationUpdateRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (reservationDefinitionBuilder_ == null) {
          result.reservationDefinition_ = reservationDefinition_;
        } else {
          result.reservationDefinition_ = reservationDefinitionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (reservationIdBuilder_ == null) {
          result.reservationId_ = reservationId_;
        } else {
          result.reservationId_ = reservationIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto.getDefaultInstance()) return this;
        if (other.hasReservationDefinition()) {
          mergeReservationDefinition(other.getReservationDefinition());
        }
        if (other.hasReservationId()) {
          mergeReservationId(other.getReservationId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto reservationDefinition_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder> reservationDefinitionBuilder_;
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public boolean hasReservationDefinition() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto getReservationDefinition() {
        if (reservationDefinitionBuilder_ == null) {
          return reservationDefinition_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance() : reservationDefinition_;
        } else {
          return reservationDefinitionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public Builder setReservationDefinition(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto value) {
        if (reservationDefinitionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reservationDefinition_ = value;
          onChanged();
        } else {
          reservationDefinitionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public Builder setReservationDefinition(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder builderForValue) {
        if (reservationDefinitionBuilder_ == null) {
          reservationDefinition_ = builderForValue.build();
          onChanged();
        } else {
          reservationDefinitionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public Builder mergeReservationDefinition(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto value) {
        if (reservationDefinitionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              reservationDefinition_ != null &&
              reservationDefinition_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance()) {
            reservationDefinition_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.newBuilder(reservationDefinition_).mergeFrom(value).buildPartial();
          } else {
            reservationDefinition_ = value;
          }
          onChanged();
        } else {
          reservationDefinitionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public Builder clearReservationDefinition() {
        if (reservationDefinitionBuilder_ == null) {
          reservationDefinition_ = null;
          onChanged();
        } else {
          reservationDefinitionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder getReservationDefinitionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getReservationDefinitionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder getReservationDefinitionOrBuilder() {
        if (reservationDefinitionBuilder_ != null) {
          return reservationDefinitionBuilder_.getMessageOrBuilder();
        } else {
          return reservationDefinition_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance() : reservationDefinition_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder> 
          getReservationDefinitionFieldBuilder() {
        if (reservationDefinitionBuilder_ == null) {
          reservationDefinitionBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder>(
                  getReservationDefinition(),
                  getParentForChildren(),
                  isClean());
          reservationDefinition_ = null;
        }
        return reservationDefinitionBuilder_;
      }

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto reservationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder> reservationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 2;</code>
       */
      public boolean hasReservationId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId() {
        if (reservationIdBuilder_ == null) {
          return reservationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
        } else {
          return reservationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 2;</code>
       */
      public Builder setReservationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto value) {
        if (reservationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reservationId_ = value;
          onChanged();
        } else {
          reservationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 2;</code>
       */
      public Builder setReservationId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder builderForValue) {
        if (reservationIdBuilder_ == null) {
          reservationId_ = builderForValue.build();
          onChanged();
        } else {
          reservationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 2;</code>
       */
      public Builder mergeReservationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto value) {
        if (reservationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              reservationId_ != null &&
              reservationId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance()) {
            reservationId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.newBuilder(reservationId_).mergeFrom(value).buildPartial();
          } else {
            reservationId_ = value;
          }
          onChanged();
        } else {
          reservationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 2;</code>
       */
      public Builder clearReservationId() {
        if (reservationIdBuilder_ == null) {
          reservationId_ = null;
          onChanged();
        } else {
          reservationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder getReservationIdBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getReservationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 2;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder() {
        if (reservationIdBuilder_ != null) {
          return reservationIdBuilder_.getMessageOrBuilder();
        } else {
          return reservationId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder> 
          getReservationIdFieldBuilder() {
        if (reservationIdBuilder_ == null) {
          reservationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder>(
                  getReservationId(),
                  getParentForChildren(),
                  isClean());
          reservationId_ = null;
        }
        return reservationIdBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationUpdateRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationUpdateRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReservationUpdateRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<ReservationUpdateRequestProto>() {
      public ReservationUpdateRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ReservationUpdateRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReservationUpdateRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationUpdateRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReservationUpdateResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ReservationUpdateResponseProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationUpdateResponseProto}
   */
  public  static final class ReservationUpdateResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ReservationUpdateResponseProto)
      ReservationUpdateResponseProtoOrBuilder {
    // Use ReservationUpdateResponseProto.newBuilder() to construct.
    private ReservationUpdateResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReservationUpdateResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationUpdateResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationUpdateResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationUpdateResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationUpdateResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ReservationUpdateResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationUpdateResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationUpdateResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationUpdateResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationUpdateResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationUpdateResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReservationUpdateResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<ReservationUpdateResponseProto>() {
      public ReservationUpdateResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ReservationUpdateResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReservationUpdateResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationUpdateResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationUpdateResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReservationDeleteRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ReservationDeleteRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
     */
    boolean hasReservationId();
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId();
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationDeleteRequestProto}
   */
  public  static final class ReservationDeleteRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ReservationDeleteRequestProto)
      ReservationDeleteRequestProtoOrBuilder {
    // Use ReservationDeleteRequestProto.newBuilder() to construct.
    private ReservationDeleteRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReservationDeleteRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationDeleteRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = reservationId_.toBuilder();
              }
              reservationId_ = input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reservationId_);
                reservationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationDeleteRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationDeleteRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int RESERVATION_ID_FIELD_NUMBER = 1;
    private org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto reservationId_;
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
     */
    public boolean hasReservationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId() {
      return reservationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder() {
      return reservationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getReservationId());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getReservationId());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto) obj;

      boolean result = true;
      result = result && (hasReservationId() == other.hasReservationId());
      if (hasReservationId()) {
        result = result && getReservationId()
            .equals(other.getReservationId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasReservationId()) {
        hash = (37 * hash) + RESERVATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getReservationId().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationDeleteRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ReservationDeleteRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationDeleteRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationDeleteRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getReservationIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (reservationIdBuilder_ == null) {
          reservationId_ = null;
        } else {
          reservationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationDeleteRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (reservationIdBuilder_ == null) {
          result.reservationId_ = reservationId_;
        } else {
          result.reservationId_ = reservationIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto.getDefaultInstance()) return this;
        if (other.hasReservationId()) {
          mergeReservationId(other.getReservationId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto reservationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder> reservationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public boolean hasReservationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId() {
        if (reservationIdBuilder_ == null) {
          return reservationId_ == null ? org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
        } else {
          return reservationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public Builder setReservationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto value) {
        if (reservationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reservationId_ = value;
          onChanged();
        } else {
          reservationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public Builder setReservationId(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder builderForValue) {
        if (reservationIdBuilder_ == null) {
          reservationId_ = builderForValue.build();
          onChanged();
        } else {
          reservationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public Builder mergeReservationId(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto value) {
        if (reservationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              reservationId_ != null &&
              reservationId_ != org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance()) {
            reservationId_ =
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.newBuilder(reservationId_).mergeFrom(value).buildPartial();
          } else {
            reservationId_ = value;
          }
          onChanged();
        } else {
          reservationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public Builder clearReservationId() {
        if (reservationIdBuilder_ == null) {
          reservationId_ = null;
          onChanged();
        } else {
          reservationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder getReservationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getReservationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder() {
        if (reservationIdBuilder_ != null) {
          return reservationIdBuilder_.getMessageOrBuilder();
        } else {
          return reservationId_ == null ?
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder> 
          getReservationIdFieldBuilder() {
        if (reservationIdBuilder_ == null) {
          reservationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder>(
                  getReservationId(),
                  getParentForChildren(),
                  isClean());
          reservationId_ = null;
        }
        return reservationIdBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationDeleteRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationDeleteRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReservationDeleteRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<ReservationDeleteRequestProto>() {
      public ReservationDeleteRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ReservationDeleteRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReservationDeleteRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationDeleteRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReservationDeleteResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ReservationDeleteResponseProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationDeleteResponseProto}
   */
  public  static final class ReservationDeleteResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ReservationDeleteResponseProto)
      ReservationDeleteResponseProtoOrBuilder {
    // Use ReservationDeleteResponseProto.newBuilder() to construct.
    private ReservationDeleteResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReservationDeleteResponseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationDeleteResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationDeleteResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationDeleteResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationDeleteResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ReservationDeleteResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationDeleteResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationDeleteResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationDeleteResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationDeleteResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationDeleteResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReservationDeleteResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<ReservationDeleteResponseProto>() {
      public ReservationDeleteResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ReservationDeleteResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReservationDeleteResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationDeleteResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationDeleteResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReservationListRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ReservationListRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string queue = 1;</code>
     */
    boolean hasQueue();
    /**
     * <code>optional string queue = 1;</code>
     */
    java.lang.String getQueue();
    /**
     * <code>optional string queue = 1;</code>
     */
    com.google.protobuf.ByteString
        getQueueBytes();

    /**
     * <code>optional string reservation_id = 3;</code>
     */
    boolean hasReservationId();
    /**
     * <code>optional string reservation_id = 3;</code>
     */
    java.lang.String getReservationId();
    /**
     * <code>optional string reservation_id = 3;</code>
     */
    com.google.protobuf.ByteString
        getReservationIdBytes();

    /**
     * <code>optional int64 start_time = 4;</code>
     */
    boolean hasStartTime();
    /**
     * <code>optional int64 start_time = 4;</code>
     */
    long getStartTime();

    /**
     * <code>optional int64 end_time = 5;</code>
     */
    boolean hasEndTime();
    /**
     * <code>optional int64 end_time = 5;</code>
     */
    long getEndTime();

    /**
     * <code>optional bool include_resource_allocations = 6;</code>
     */
    boolean hasIncludeResourceAllocations();
    /**
     * <code>optional bool include_resource_allocations = 6;</code>
     */
    boolean getIncludeResourceAllocations();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationListRequestProto}
   */
  public  static final class ReservationListRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ReservationListRequestProto)
      ReservationListRequestProtoOrBuilder {
    // Use ReservationListRequestProto.newBuilder() to construct.
    private ReservationListRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReservationListRequestProto() {
      queue_ = "";
      reservationId_ = "";
      startTime_ = 0L;
      endTime_ = 0L;
      includeResourceAllocations_ = false;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationListRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              queue_ = bs;
              break;
            }
            case 26: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              reservationId_ = bs;
              break;
            }
            case 32: {
              bitField0_ |= 0x00000004;
              startTime_ = input.readInt64();
              break;
            }
            case 40: {
              bitField0_ |= 0x00000008;
              endTime_ = input.readInt64();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000010;
              includeResourceAllocations_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationListRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationListRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int QUEUE_FIELD_NUMBER = 1;
    private volatile java.lang.Object queue_;
    /**
     * <code>optional string queue = 1;</code>
     */
    public boolean hasQueue() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string queue = 1;</code>
     */
    public java.lang.String getQueue() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queue_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queue = 1;</code>
     */
    public com.google.protobuf.ByteString
        getQueueBytes() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queue_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int RESERVATION_ID_FIELD_NUMBER = 3;
    private volatile java.lang.Object reservationId_;
    /**
     * <code>optional string reservation_id = 3;</code>
     */
    public boolean hasReservationId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string reservation_id = 3;</code>
     */
    public java.lang.String getReservationId() {
      java.lang.Object ref = reservationId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          reservationId_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string reservation_id = 3;</code>
     */
    public com.google.protobuf.ByteString
        getReservationIdBytes() {
      java.lang.Object ref = reservationId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        reservationId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int START_TIME_FIELD_NUMBER = 4;
    private long startTime_;
    /**
     * <code>optional int64 start_time = 4;</code>
     */
    public boolean hasStartTime() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int64 start_time = 4;</code>
     */
    public long getStartTime() {
      return startTime_;
    }

    public static final int END_TIME_FIELD_NUMBER = 5;
    private long endTime_;
    /**
     * <code>optional int64 end_time = 5;</code>
     */
    public boolean hasEndTime() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional int64 end_time = 5;</code>
     */
    public long getEndTime() {
      return endTime_;
    }

    public static final int INCLUDE_RESOURCE_ALLOCATIONS_FIELD_NUMBER = 6;
    private boolean includeResourceAllocations_;
    /**
     * <code>optional bool include_resource_allocations = 6;</code>
     */
    public boolean hasIncludeResourceAllocations() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional bool include_resource_allocations = 6;</code>
     */
    public boolean getIncludeResourceAllocations() {
      return includeResourceAllocations_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, queue_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, reservationId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt64(4, startTime_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt64(5, endTime_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBool(6, includeResourceAllocations_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, queue_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, reservationId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(4, startTime_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(5, endTime_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, includeResourceAllocations_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto) obj;

      boolean result = true;
      result = result && (hasQueue() == other.hasQueue());
      if (hasQueue()) {
        result = result && getQueue()
            .equals(other.getQueue());
      }
      result = result && (hasReservationId() == other.hasReservationId());
      if (hasReservationId()) {
        result = result && getReservationId()
            .equals(other.getReservationId());
      }
      result = result && (hasStartTime() == other.hasStartTime());
      if (hasStartTime()) {
        result = result && (getStartTime()
            == other.getStartTime());
      }
      result = result && (hasEndTime() == other.hasEndTime());
      if (hasEndTime()) {
        result = result && (getEndTime()
            == other.getEndTime());
      }
      result = result && (hasIncludeResourceAllocations() == other.hasIncludeResourceAllocations());
      if (hasIncludeResourceAllocations()) {
        result = result && (getIncludeResourceAllocations()
            == other.getIncludeResourceAllocations());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasQueue()) {
        hash = (37 * hash) + QUEUE_FIELD_NUMBER;
        hash = (53 * hash) + getQueue().hashCode();
      }
      if (hasReservationId()) {
        hash = (37 * hash) + RESERVATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getReservationId().hashCode();
      }
      if (hasStartTime()) {
        hash = (37 * hash) + START_TIME_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getStartTime());
      }
      if (hasEndTime()) {
        hash = (37 * hash) + END_TIME_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getEndTime());
      }
      if (hasIncludeResourceAllocations()) {
        hash = (37 * hash) + INCLUDE_RESOURCE_ALLOCATIONS_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getIncludeResourceAllocations());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationListRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ReservationListRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationListRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationListRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        queue_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        reservationId_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        startTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        endTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000008);
        includeResourceAllocations_ = false;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationListRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.queue_ = queue_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.reservationId_ = reservationId_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.startTime_ = startTime_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.endTime_ = endTime_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.includeResourceAllocations_ = includeResourceAllocations_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto.getDefaultInstance()) return this;
        if (other.hasQueue()) {
          bitField0_ |= 0x00000001;
          queue_ = other.queue_;
          onChanged();
        }
        if (other.hasReservationId()) {
          bitField0_ |= 0x00000002;
          reservationId_ = other.reservationId_;
          onChanged();
        }
        if (other.hasStartTime()) {
          setStartTime(other.getStartTime());
        }
        if (other.hasEndTime()) {
          setEndTime(other.getEndTime());
        }
        if (other.hasIncludeResourceAllocations()) {
          setIncludeResourceAllocations(other.getIncludeResourceAllocations());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object queue_ = "";
      /**
       * <code>optional string queue = 1;</code>
       */
      public boolean hasQueue() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string queue = 1;</code>
       */
      public java.lang.String getQueue() {
        java.lang.Object ref = queue_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            queue_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queue = 1;</code>
       */
      public com.google.protobuf.ByteString
          getQueueBytes() {
        java.lang.Object ref = queue_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queue_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queue = 1;</code>
       */
      public Builder setQueue(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queue_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 1;</code>
       */
      public Builder clearQueue() {
        bitField0_ = (bitField0_ & ~0x00000001);
        queue_ = getDefaultInstance().getQueue();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 1;</code>
       */
      public Builder setQueueBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queue_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object reservationId_ = "";
      /**
       * <code>optional string reservation_id = 3;</code>
       */
      public boolean hasReservationId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string reservation_id = 3;</code>
       */
      public java.lang.String getReservationId() {
        java.lang.Object ref = reservationId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            reservationId_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string reservation_id = 3;</code>
       */
      public com.google.protobuf.ByteString
          getReservationIdBytes() {
        java.lang.Object ref = reservationId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          reservationId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string reservation_id = 3;</code>
       */
      public Builder setReservationId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        reservationId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string reservation_id = 3;</code>
       */
      public Builder clearReservationId() {
        bitField0_ = (bitField0_ & ~0x00000002);
        reservationId_ = getDefaultInstance().getReservationId();
        onChanged();
        return this;
      }
      /**
       * <code>optional string reservation_id = 3;</code>
       */
      public Builder setReservationIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        reservationId_ = value;
        onChanged();
        return this;
      }

      private long startTime_ ;
      /**
       * <code>optional int64 start_time = 4;</code>
       */
      public boolean hasStartTime() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int64 start_time = 4;</code>
       */
      public long getStartTime() {
        return startTime_;
      }
      /**
       * <code>optional int64 start_time = 4;</code>
       */
      public Builder setStartTime(long value) {
        bitField0_ |= 0x00000004;
        startTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 start_time = 4;</code>
       */
      public Builder clearStartTime() {
        bitField0_ = (bitField0_ & ~0x00000004);
        startTime_ = 0L;
        onChanged();
        return this;
      }

      private long endTime_ ;
      /**
       * <code>optional int64 end_time = 5;</code>
       */
      public boolean hasEndTime() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int64 end_time = 5;</code>
       */
      public long getEndTime() {
        return endTime_;
      }
      /**
       * <code>optional int64 end_time = 5;</code>
       */
      public Builder setEndTime(long value) {
        bitField0_ |= 0x00000008;
        endTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 end_time = 5;</code>
       */
      public Builder clearEndTime() {
        bitField0_ = (bitField0_ & ~0x00000008);
        endTime_ = 0L;
        onChanged();
        return this;
      }

      private boolean includeResourceAllocations_ ;
      /**
       * <code>optional bool include_resource_allocations = 6;</code>
       */
      public boolean hasIncludeResourceAllocations() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional bool include_resource_allocations = 6;</code>
       */
      public boolean getIncludeResourceAllocations() {
        return includeResourceAllocations_;
      }
      /**
       * <code>optional bool include_resource_allocations = 6;</code>
       */
      public Builder setIncludeResourceAllocations(boolean value) {
        bitField0_ |= 0x00000010;
        includeResourceAllocations_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool include_resource_allocations = 6;</code>
       */
      public Builder clearIncludeResourceAllocations() {
        bitField0_ = (bitField0_ & ~0x00000010);
        includeResourceAllocations_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationListRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationListRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReservationListRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<ReservationListRequestProto>() {
      public ReservationListRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ReservationListRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReservationListRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationListRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReservationListResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ReservationListResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
     */
    java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto> 
        getReservationsList();
    /**
     * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto getReservations(int index);
    /**
     * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
     */
    int getReservationsCount();
    /**
     * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
     */
    java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProtoOrBuilder> 
        getReservationsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
     */
    org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProtoOrBuilder getReservationsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationListResponseProto}
   */
  public  static final class ReservationListResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ReservationListResponseProto)
      ReservationListResponseProtoOrBuilder {
    // Use ReservationListResponseProto.newBuilder() to construct.
    private ReservationListResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReservationListResponseProto() {
      reservations_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationListResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                reservations_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              reservations_.add(
                  input.readMessage(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          reservations_ = java.util.Collections.unmodifiableList(reservations_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationListResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationListResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto.Builder.class);
    }

    public static final int RESERVATIONS_FIELD_NUMBER = 1;
    private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto> reservations_;
    /**
     * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
     */
    public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto> getReservationsList() {
      return reservations_;
    }
    /**
     * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
     */
    public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProtoOrBuilder> 
        getReservationsOrBuilderList() {
      return reservations_;
    }
    /**
     * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
     */
    public int getReservationsCount() {
      return reservations_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto getReservations(int index) {
      return reservations_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
     */
    public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProtoOrBuilder getReservationsOrBuilder(
        int index) {
      return reservations_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < reservations_.size(); i++) {
        output.writeMessage(1, reservations_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < reservations_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, reservations_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto) obj;

      boolean result = true;
      result = result && getReservationsList()
          .equals(other.getReservationsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getReservationsCount() > 0) {
        hash = (37 * hash) + RESERVATIONS_FIELD_NUMBER;
        hash = (53 * hash) + getReservationsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationListResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ReservationListResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationListResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationListResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getReservationsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (reservationsBuilder_ == null) {
          reservations_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          reservationsBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_ReservationListResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (reservationsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            reservations_ = java.util.Collections.unmodifiableList(reservations_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.reservations_ = reservations_;
        } else {
          result.reservations_ = reservationsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto.getDefaultInstance()) return this;
        if (reservationsBuilder_ == null) {
          if (!other.reservations_.isEmpty()) {
            if (reservations_.isEmpty()) {
              reservations_ = other.reservations_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureReservationsIsMutable();
              reservations_.addAll(other.reservations_);
            }
            onChanged();
          }
        } else {
          if (!other.reservations_.isEmpty()) {
            if (reservationsBuilder_.isEmpty()) {
              reservationsBuilder_.dispose();
              reservationsBuilder_ = null;
              reservations_ = other.reservations_;
              bitField0_ = (bitField0_ & ~0x00000001);
              reservationsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getReservationsFieldBuilder() : null;
            } else {
              reservationsBuilder_.addAllMessages(other.reservations_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto> reservations_ =
        java.util.Collections.emptyList();
      private void ensureReservationsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          reservations_ = new java.util.ArrayList<org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto>(reservations_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProtoOrBuilder> reservationsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto> getReservationsList() {
        if (reservationsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(reservations_);
        } else {
          return reservationsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public int getReservationsCount() {
        if (reservationsBuilder_ == null) {
          return reservations_.size();
        } else {
          return reservationsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto getReservations(int index) {
        if (reservationsBuilder_ == null) {
          return reservations_.get(index);
        } else {
          return reservationsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public Builder setReservations(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto value) {
        if (reservationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReservationsIsMutable();
          reservations_.set(index, value);
          onChanged();
        } else {
          reservationsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public Builder setReservations(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.Builder builderForValue) {
        if (reservationsBuilder_ == null) {
          ensureReservationsIsMutable();
          reservations_.set(index, builderForValue.build());
          onChanged();
        } else {
          reservationsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public Builder addReservations(org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto value) {
        if (reservationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReservationsIsMutable();
          reservations_.add(value);
          onChanged();
        } else {
          reservationsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public Builder addReservations(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto value) {
        if (reservationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReservationsIsMutable();
          reservations_.add(index, value);
          onChanged();
        } else {
          reservationsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public Builder addReservations(
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.Builder builderForValue) {
        if (reservationsBuilder_ == null) {
          ensureReservationsIsMutable();
          reservations_.add(builderForValue.build());
          onChanged();
        } else {
          reservationsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public Builder addReservations(
          int index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.Builder builderForValue) {
        if (reservationsBuilder_ == null) {
          ensureReservationsIsMutable();
          reservations_.add(index, builderForValue.build());
          onChanged();
        } else {
          reservationsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public Builder addAllReservations(
          java.lang.Iterable<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto> values) {
        if (reservationsBuilder_ == null) {
          ensureReservationsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, reservations_);
          onChanged();
        } else {
          reservationsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public Builder clearReservations() {
        if (reservationsBuilder_ == null) {
          reservations_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          reservationsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public Builder removeReservations(int index) {
        if (reservationsBuilder_ == null) {
          ensureReservationsIsMutable();
          reservations_.remove(index);
          onChanged();
        } else {
          reservationsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.Builder getReservationsBuilder(
          int index) {
        return getReservationsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProtoOrBuilder getReservationsOrBuilder(
          int index) {
        if (reservationsBuilder_ == null) {
          return reservations_.get(index);  } else {
          return reservationsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public java.util.List<? extends org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProtoOrBuilder> 
           getReservationsOrBuilderList() {
        if (reservationsBuilder_ != null) {
          return reservationsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(reservations_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.Builder addReservationsBuilder() {
        return getReservationsFieldBuilder().addBuilder(
            org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.Builder addReservationsBuilder(
          int index) {
        return getReservationsFieldBuilder().addBuilder(
            index, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationAllocationStateProto reservations = 1;</code>
       */
      public java.util.List<org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.Builder> 
           getReservationsBuilderList() {
        return getReservationsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProtoOrBuilder> 
          getReservationsFieldBuilder() {
        if (reservationsBuilder_ == null) {
          reservationsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.Builder, org.spiderdt.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProtoOrBuilder>(
                  reservations_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          reservations_ = null;
        }
        return reservationsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationListResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationListResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReservationListResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<ReservationListResponseProto>() {
      public ReservationListResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ReservationListResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReservationListResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationListResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.ReservationListResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RunSharedCacheCleanerTaskRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.RunSharedCacheCleanerTaskRequestProto)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.RunSharedCacheCleanerTaskRequestProto}
   */
  public  static final class RunSharedCacheCleanerTaskRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.RunSharedCacheCleanerTaskRequestProto)
      RunSharedCacheCleanerTaskRequestProtoOrBuilder {
    // Use RunSharedCacheCleanerTaskRequestProto.newBuilder() to construct.
    private RunSharedCacheCleanerTaskRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RunSharedCacheCleanerTaskRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RunSharedCacheCleanerTaskRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RunSharedCacheCleanerTaskRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RunSharedCacheCleanerTaskRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.RunSharedCacheCleanerTaskRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.RunSharedCacheCleanerTaskRequestProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RunSharedCacheCleanerTaskRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RunSharedCacheCleanerTaskRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RunSharedCacheCleanerTaskRequestProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.RunSharedCacheCleanerTaskRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.RunSharedCacheCleanerTaskRequestProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<RunSharedCacheCleanerTaskRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<RunSharedCacheCleanerTaskRequestProto>() {
      public RunSharedCacheCleanerTaskRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new RunSharedCacheCleanerTaskRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<RunSharedCacheCleanerTaskRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<RunSharedCacheCleanerTaskRequestProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RunSharedCacheCleanerTaskResponseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.RunSharedCacheCleanerTaskResponseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional bool accepted = 1;</code>
     */
    boolean hasAccepted();
    /**
     * <code>optional bool accepted = 1;</code>
     */
    boolean getAccepted();
  }
  /**
   * Protobuf type {@code hadoop.yarn.RunSharedCacheCleanerTaskResponseProto}
   */
  public  static final class RunSharedCacheCleanerTaskResponseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.RunSharedCacheCleanerTaskResponseProto)
      RunSharedCacheCleanerTaskResponseProtoOrBuilder {
    // Use RunSharedCacheCleanerTaskResponseProto.newBuilder() to construct.
    private RunSharedCacheCleanerTaskResponseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RunSharedCacheCleanerTaskResponseProto() {
      accepted_ = false;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RunSharedCacheCleanerTaskResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              accepted_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RunSharedCacheCleanerTaskResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RunSharedCacheCleanerTaskResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto.Builder.class);
    }

    private int bitField0_;
    public static final int ACCEPTED_FIELD_NUMBER = 1;
    private boolean accepted_;
    /**
     * <code>optional bool accepted = 1;</code>
     */
    public boolean hasAccepted() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bool accepted = 1;</code>
     */
    public boolean getAccepted() {
      return accepted_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBool(1, accepted_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, accepted_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto)) {
        return super.equals(obj);
      }
      org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto other = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto) obj;

      boolean result = true;
      result = result && (hasAccepted() == other.hasAccepted());
      if (hasAccepted()) {
        result = result && (getAccepted()
            == other.getAccepted());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasAccepted()) {
        hash = (37 * hash) + ACCEPTED_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getAccepted());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.RunSharedCacheCleanerTaskResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.RunSharedCacheCleanerTaskResponseProto)
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RunSharedCacheCleanerTaskResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RunSharedCacheCleanerTaskResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto.class, org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto.Builder.class);
      }

      // Construct using org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        accepted_ = false;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.internal_static_hadoop_yarn_RunSharedCacheCleanerTaskResponseProto_descriptor;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto getDefaultInstanceForType() {
        return org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto.getDefaultInstance();
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto build() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto buildPartial() {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto result = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.accepted_ = accepted_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto) {
          return mergeFrom((org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto other) {
        if (other == org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto.getDefaultInstance()) return this;
        if (other.hasAccepted()) {
          setAccepted(other.getAccepted());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private boolean accepted_ ;
      /**
       * <code>optional bool accepted = 1;</code>
       */
      public boolean hasAccepted() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional bool accepted = 1;</code>
       */
      public boolean getAccepted() {
        return accepted_;
      }
      /**
       * <code>optional bool accepted = 1;</code>
       */
      public Builder setAccepted(boolean value) {
        bitField0_ |= 0x00000001;
        accepted_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool accepted = 1;</code>
       */
      public Builder clearAccepted() {
        bitField0_ = (bitField0_ & ~0x00000001);
        accepted_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.RunSharedCacheCleanerTaskResponseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.RunSharedCacheCleanerTaskResponseProto)
    private static final org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto();
    }

    public static org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<RunSharedCacheCleanerTaskResponseProto>
        PARSER = new com.google.protobuf.AbstractParser<RunSharedCacheCleanerTaskResponseProto>() {
      public RunSharedCacheCleanerTaskResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new RunSharedCacheCleanerTaskResponseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<RunSharedCacheCleanerTaskResponseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<RunSharedCacheCleanerTaskResponseProto> getParserForType() {
      return PARSER;
    }

    public org.spiderdt.hadoop.yarn.proto.YarnServiceProtos.RunSharedCacheCleanerTaskResponseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_RegisterApplicationMasterRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_RegisterApplicationMasterRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_RegisterApplicationMasterResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_RegisterApplicationMasterResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_FinishApplicationMasterRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_FinishApplicationMasterRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_FinishApplicationMasterResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_FinishApplicationMasterResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_AllocateRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_AllocateRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NMTokenProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_NMTokenProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_AllocateResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_AllocateResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetNewApplicationRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetNewApplicationRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetNewApplicationResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetNewApplicationResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetApplicationReportRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetApplicationReportRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetApplicationReportResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetApplicationReportResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_SubmitApplicationRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_SubmitApplicationRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_SubmitApplicationResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_SubmitApplicationResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_FailApplicationAttemptRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_FailApplicationAttemptRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_FailApplicationAttemptResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_FailApplicationAttemptResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_KillApplicationRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_KillApplicationRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_KillApplicationResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_KillApplicationResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetClusterMetricsRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetClusterMetricsRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetClusterMetricsResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetClusterMetricsResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_MoveApplicationAcrossQueuesRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_MoveApplicationAcrossQueuesRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_MoveApplicationAcrossQueuesResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_MoveApplicationAcrossQueuesResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetApplicationsRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetApplicationsRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetApplicationsResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetApplicationsResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetClusterNodesRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetClusterNodesRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetClusterNodesResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetClusterNodesResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetQueueInfoRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetQueueInfoRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetQueueInfoResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetQueueInfoResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetQueueUserAclsInfoRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetQueueUserAclsInfoRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetQueueUserAclsInfoResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetQueueUserAclsInfoResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetNodesToLabelsRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetNodesToLabelsRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetNodesToLabelsResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetNodesToLabelsResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetLabelsToNodesRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetLabelsToNodesRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetLabelsToNodesResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetLabelsToNodesResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetClusterNodeLabelsRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetClusterNodeLabelsRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetClusterNodeLabelsResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetClusterNodeLabelsResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_UpdateApplicationPriorityRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_UpdateApplicationPriorityRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_UpdateApplicationPriorityResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_UpdateApplicationPriorityResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_SignalContainerRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_SignalContainerRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_SignalContainerResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_SignalContainerResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StartContainerRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_StartContainerRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StartContainerResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_StartContainerResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StopContainerRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_StopContainerRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StopContainerResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_StopContainerResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceLocalizationRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceLocalizationRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceLocalizationResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceLocalizationResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StartContainersRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_StartContainersRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerExceptionMapProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerExceptionMapProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StartContainersResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_StartContainersResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StopContainersRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_StopContainersRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StopContainersResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_StopContainersResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetContainerStatusesRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetContainerStatusesRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetContainerStatusesResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetContainerStatusesResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_IncreaseContainersResourceRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_IncreaseContainersResourceRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_IncreaseContainersResourceResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_IncreaseContainersResourceResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetApplicationAttemptReportRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetApplicationAttemptReportRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetApplicationAttemptReportResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetApplicationAttemptReportResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetApplicationAttemptsRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetApplicationAttemptsRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetApplicationAttemptsResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetApplicationAttemptsResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetContainerReportRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetContainerReportRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetContainerReportResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetContainerReportResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetContainersRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetContainersRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetContainersResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetContainersResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_UseSharedCacheResourceRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_UseSharedCacheResourceRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_UseSharedCacheResourceResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_UseSharedCacheResourceResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReleaseSharedCacheResourceRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ReleaseSharedCacheResourceRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReleaseSharedCacheResourceResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ReleaseSharedCacheResourceResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetNewReservationRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetNewReservationRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetNewReservationResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_GetNewReservationResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationSubmissionRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationSubmissionRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationSubmissionResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationSubmissionResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationUpdateRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationUpdateRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationUpdateResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationUpdateResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationDeleteRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationDeleteRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationDeleteResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationDeleteResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationListRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationListRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationListResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationListResponseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_RunSharedCacheCleanerTaskRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_RunSharedCacheCleanerTaskRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_RunSharedCacheCleanerTaskResponseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_RunSharedCacheCleanerTaskResponseProto_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\031yarn_service_protos.proto\022\013hadoop.yarn" +
      "\032\016Security.proto\032\021yarn_protos.proto\"]\n%R" +
      "egisterApplicationMasterRequestProto\022\014\n\004" +
      "host\030\001 \001(\t\022\020\n\010rpc_port\030\002 \001(\005\022\024\n\014tracking" +
      "_url\030\003 \001(\t\"\250\003\n&RegisterApplicationMaster" +
      "ResponseProto\0225\n\021maximumCapability\030\001 \001(\013" +
      "2\032.hadoop.yarn.ResourceProto\022%\n\035client_t" +
      "o_am_token_master_key\030\002 \001(\014\022=\n\020applicati" +
      "on_ACLs\030\003 \003(\0132#.hadoop.yarn.ApplicationA" +
      "CLMapProto\022F\n!containers_from_previous_a",
      "ttempts\030\004 \003(\0132\033.hadoop.yarn.ContainerPro" +
      "to\022\r\n\005queue\030\005 \001(\t\022C\n nm_tokens_from_prev" +
      "ious_attempts\030\006 \003(\0132\031.hadoop.yarn.NMToke" +
      "nProto\022E\n\030scheduler_resource_types\030\007 \003(\016" +
      "2#.hadoop.yarn.SchedulerResourceTypes\"\234\001" +
      "\n#FinishApplicationMasterRequestProto\022\023\n" +
      "\013diagnostics\030\001 \001(\t\022\024\n\014tracking_url\030\002 \001(\t" +
      "\022J\n\030final_application_status\030\003 \001(\0162(.had" +
      "oop.yarn.FinalApplicationStatusProto\"E\n$" +
      "FinishApplicationMasterResponseProto\022\035\n\016",
      "isUnregistered\030\001 \001(\010:\005false\"\374\002\n\024Allocate" +
      "RequestProto\022.\n\003ask\030\001 \003(\0132!.hadoop.yarn." +
      "ResourceRequestProto\022.\n\007release\030\002 \003(\0132\035." +
      "hadoop.yarn.ContainerIdProto\022E\n\021blacklis" +
      "t_request\030\003 \001(\0132*.hadoop.yarn.ResourceBl" +
      "acklistRequestProto\022\023\n\013response_id\030\004 \001(\005" +
      "\022\020\n\010progress\030\005 \001(\002\022J\n\020increase_request\030\006" +
      " \003(\01320.hadoop.yarn.ContainerResourceChan" +
      "geRequestProto\022J\n\020decrease_request\030\007 \003(\013" +
      "20.hadoop.yarn.ContainerResourceChangeRe",
      "questProto\"b\n\014NMTokenProto\022(\n\006nodeId\030\001 \001" +
      "(\0132\030.hadoop.yarn.NodeIdProto\022(\n\005token\030\002 " +
      "\001(\0132\031.hadoop.common.TokenProto\"\271\005\n\025Alloc" +
      "ateResponseProto\0220\n\013a_m_command\030\001 \001(\0162\033." +
      "hadoop.yarn.AMCommandProto\022\023\n\013response_i" +
      "d\030\002 \001(\005\0229\n\024allocated_containers\030\003 \003(\0132\033." +
      "hadoop.yarn.ContainerProto\022G\n\034completed_" +
      "container_statuses\030\004 \003(\0132!.hadoop.yarn.C" +
      "ontainerStatusProto\022)\n\005limit\030\005 \001(\0132\032.had" +
      "oop.yarn.ResourceProto\0223\n\rupdated_nodes\030",
      "\006 \003(\0132\034.hadoop.yarn.NodeReportProto\022\031\n\021n" +
      "um_cluster_nodes\030\007 \001(\005\0224\n\007preempt\030\010 \001(\0132" +
      "#.hadoop.yarn.PreemptionMessageProto\022,\n\t" +
      "nm_tokens\030\t \003(\0132\031.hadoop.yarn.NMTokenPro" +
      "to\0229\n\024increased_containers\030\n \003(\0132\033.hadoo" +
      "p.yarn.ContainerProto\0229\n\024decreased_conta" +
      "iners\030\013 \003(\0132\033.hadoop.yarn.ContainerProto" +
      "\022.\n\013am_rm_token\030\014 \001(\0132\031.hadoop.common.To" +
      "kenProto\0228\n\024application_priority\030\r \001(\0132\032" +
      ".hadoop.yarn.PriorityProto\022\026\n\016collector_",
      "addr\030\016 \001(\t\"\037\n\035GetNewApplicationRequestPr" +
      "oto\"\220\001\n\036GetNewApplicationResponseProto\0227" +
      "\n\016application_id\030\001 \001(\0132\037.hadoop.yarn.App" +
      "licationIdProto\0225\n\021maximumCapability\030\002 \001" +
      "(\0132\032.hadoop.yarn.ResourceProto\"[\n GetApp" +
      "licationReportRequestProto\0227\n\016applicatio" +
      "n_id\030\001 \001(\0132\037.hadoop.yarn.ApplicationIdPr" +
      "oto\"d\n!GetApplicationReportResponseProto" +
      "\022?\n\022application_report\030\001 \001(\0132#.hadoop.ya" +
      "rn.ApplicationReportProto\"w\n\035SubmitAppli",
      "cationRequestProto\022V\n\036application_submis" +
      "sion_context\030\001 \001(\0132..hadoop.yarn.Applica" +
      "tionSubmissionContextProto\" \n\036SubmitAppl" +
      "icationResponseProto\"l\n\"FailApplicationA" +
      "ttemptRequestProto\022F\n\026application_attemp" +
      "t_id\030\001 \001(\0132&.hadoop.yarn.ApplicationAtte" +
      "mptIdProto\"%\n#FailApplicationAttemptResp" +
      "onseProto\"V\n\033KillApplicationRequestProto" +
      "\0227\n\016application_id\030\001 \001(\0132\037.hadoop.yarn.A" +
      "pplicationIdProto\"@\n\034KillApplicationResp",
      "onseProto\022 \n\021is_kill_completed\030\001 \001(\010:\005fa" +
      "lse\"\037\n\035GetClusterMetricsRequestProto\"_\n\036" +
      "GetClusterMetricsResponseProto\022=\n\017cluste" +
      "r_metrics\030\001 \001(\0132$.hadoop.yarn.YarnCluste" +
      "rMetricsProto\"x\n\'MoveApplicationAcrossQu" +
      "euesRequestProto\0227\n\016application_id\030\001 \002(\013" +
      "2\037.hadoop.yarn.ApplicationIdProto\022\024\n\014tar" +
      "get_queue\030\002 \002(\t\"*\n(MoveApplicationAcross" +
      "QueuesResponseProto\"\325\002\n\033GetApplicationsR" +
      "equestProto\022\031\n\021application_types\030\001 \003(\t\022B",
      "\n\022application_states\030\002 \003(\0162&.hadoop.yarn" +
      ".YarnApplicationStateProto\022\r\n\005users\030\003 \003(" +
      "\t\022\016\n\006queues\030\004 \003(\t\022\r\n\005limit\030\005 \001(\003\022\023\n\013star" +
      "t_begin\030\006 \001(\003\022\021\n\tstart_end\030\007 \001(\003\022\024\n\014fini" +
      "sh_begin\030\010 \001(\003\022\022\n\nfinish_end\030\t \001(\003\022\027\n\017ap" +
      "plicationTags\030\n \003(\t\022>\n\005scope\030\013 \001(\0162*.had" +
      "oop.yarn.ApplicationsRequestScopeProto:\003" +
      "ALL\"Y\n\034GetApplicationsResponseProto\0229\n\014a" +
      "pplications\030\001 \003(\0132#.hadoop.yarn.Applicat" +
      "ionReportProto\"N\n\033GetClusterNodesRequest",
      "Proto\022/\n\nnodeStates\030\001 \003(\0162\033.hadoop.yarn." +
      "NodeStateProto\"Q\n\034GetClusterNodesRespons" +
      "eProto\0221\n\013nodeReports\030\001 \003(\0132\034.hadoop.yar" +
      "n.NodeReportProto\"y\n\030GetQueueInfoRequest" +
      "Proto\022\021\n\tqueueName\030\001 \001(\t\022\033\n\023includeAppli" +
      "cations\030\002 \001(\010\022\032\n\022includeChildQueues\030\003 \001(" +
      "\010\022\021\n\trecursive\030\004 \001(\010\"K\n\031GetQueueInfoResp" +
      "onseProto\022.\n\tqueueInfo\030\001 \001(\0132\033.hadoop.ya" +
      "rn.QueueInfoProto\"\"\n GetQueueUserAclsInf" +
      "oRequestProto\"^\n!GetQueueUserAclsInfoRes",
      "ponseProto\0229\n\rqueueUserAcls\030\001 \003(\0132\".hado" +
      "op.yarn.QueueUserACLInfoProto\"\036\n\034GetNode" +
      "sToLabelsRequestProto\"[\n\035GetNodesToLabel" +
      "sResponseProto\022:\n\014nodeToLabels\030\001 \003(\0132$.h" +
      "adoop.yarn.NodeIdToLabelsInfoProto\"2\n\034Ge" +
      "tLabelsToNodesRequestProto\022\022\n\nnodeLabels" +
      "\030\001 \003(\t\"Y\n\035GetLabelsToNodesResponseProto\022" +
      "8\n\rlabelsToNodes\030\001 \003(\0132!.hadoop.yarn.Lab" +
      "elsToNodeIdsProto\"\"\n GetClusterNodeLabel" +
      "sRequestProto\"T\n!GetClusterNodeLabelsRes",
      "ponseProto\022/\n\nnodeLabels\030\001 \003(\0132\033.hadoop." +
      "yarn.NodeLabelProto\"\230\001\n%UpdateApplicatio" +
      "nPriorityRequestProto\0226\n\rapplicationId\030\001" +
      " \002(\0132\037.hadoop.yarn.ApplicationIdProto\0227\n" +
      "\023applicationPriority\030\002 \002(\0132\032.hadoop.yarn" +
      ".PriorityProto\"a\n&UpdateApplicationPrior" +
      "ityResponseProto\0227\n\023applicationPriority\030" +
      "\001 \001(\0132\032.hadoop.yarn.PriorityProto\"\215\001\n\033Si" +
      "gnalContainerRequestProto\0223\n\014container_i" +
      "d\030\001 \002(\0132\035.hadoop.yarn.ContainerIdProto\0229",
      "\n\007command\030\002 \002(\0162(.hadoop.yarn.SignalCont" +
      "ainerCommandProto\"\036\n\034SignalContainerResp" +
      "onseProto\"\234\001\n\032StartContainerRequestProto" +
      "\022J\n\030container_launch_context\030\001 \001(\0132(.had" +
      "oop.yarn.ContainerLaunchContextProto\0222\n\017" +
      "container_token\030\002 \001(\0132\031.hadoop.common.To" +
      "kenProto\"[\n\033StartContainerResponseProto\022" +
      "<\n\022services_meta_data\030\001 \003(\0132 .hadoop.yar" +
      "n.StringBytesMapProto\"P\n\031StopContainerRe" +
      "questProto\0223\n\014container_id\030\001 \001(\0132\035.hadoo",
      "p.yarn.ContainerIdProto\"\034\n\032StopContainer" +
      "ResponseProto\"\232\001\n ResourceLocalizationRe" +
      "questProto\0223\n\014container_id\030\001 \001(\0132\035.hadoo" +
      "p.yarn.ContainerIdProto\022A\n\017local_resourc" +
      "es\030\002 \003(\0132(.hadoop.yarn.StringLocalResour" +
      "ceMapProto\"#\n!ResourceLocalizationRespon" +
      "seProto\"g\n\033StartContainersRequestProto\022H" +
      "\n\027start_container_request\030\001 \003(\0132\'.hadoop" +
      ".yarn.StartContainerRequestProto\"\213\001\n\032Con" +
      "tainerExceptionMapProto\0223\n\014container_id\030",
      "\001 \001(\0132\035.hadoop.yarn.ContainerIdProto\0228\n\t" +
      "exception\030\002 \001(\0132%.hadoop.yarn.Serialized" +
      "ExceptionProto\"\331\001\n\034StartContainersRespon" +
      "seProto\022<\n\022services_meta_data\030\001 \003(\0132 .ha" +
      "doop.yarn.StringBytesMapProto\0229\n\022succeed" +
      "ed_requests\030\002 \003(\0132\035.hadoop.yarn.Containe" +
      "rIdProto\022@\n\017failed_requests\030\003 \003(\0132\'.hado" +
      "op.yarn.ContainerExceptionMapProto\"Q\n\032St" +
      "opContainersRequestProto\0223\n\014container_id" +
      "\030\001 \003(\0132\035.hadoop.yarn.ContainerIdProto\"\232\001",
      "\n\033StopContainersResponseProto\0229\n\022succeed" +
      "ed_requests\030\001 \003(\0132\035.hadoop.yarn.Containe" +
      "rIdProto\022@\n\017failed_requests\030\002 \003(\0132\'.hado" +
      "op.yarn.ContainerExceptionMapProto\"W\n Ge" +
      "tContainerStatusesRequestProto\0223\n\014contai" +
      "ner_id\030\001 \003(\0132\035.hadoop.yarn.ContainerIdPr" +
      "oto\"\230\001\n!GetContainerStatusesResponseProt" +
      "o\0221\n\006status\030\001 \003(\0132!.hadoop.yarn.Containe" +
      "rStatusProto\022@\n\017failed_requests\030\002 \003(\0132\'." +
      "hadoop.yarn.ContainerExceptionMapProto\"`",
      "\n&IncreaseContainersResourceRequestProto" +
      "\0226\n\023increase_containers\030\001 \003(\0132\031.hadoop.c" +
      "ommon.TokenProto\"\246\001\n\'IncreaseContainersR" +
      "esourceResponseProto\0229\n\022succeeded_reques" +
      "ts\030\001 \003(\0132\035.hadoop.yarn.ContainerIdProto\022" +
      "@\n\017failed_requests\030\002 \003(\0132\'.hadoop.yarn.C" +
      "ontainerExceptionMapProto\"q\n\'GetApplicat" +
      "ionAttemptReportRequestProto\022F\n\026applicat" +
      "ion_attempt_id\030\001 \001(\0132&.hadoop.yarn.Appli" +
      "cationAttemptIdProto\"z\n(GetApplicationAt",
      "temptReportResponseProto\022N\n\032application_" +
      "attempt_report\030\001 \001(\0132*.hadoop.yarn.Appli" +
      "cationAttemptReportProto\"]\n\"GetApplicati" +
      "onAttemptsRequestProto\0227\n\016application_id" +
      "\030\001 \001(\0132\037.hadoop.yarn.ApplicationIdProto\"" +
      "o\n#GetApplicationAttemptsResponseProto\022H" +
      "\n\024application_attempts\030\001 \003(\0132*.hadoop.ya" +
      "rn.ApplicationAttemptReportProto\"U\n\036GetC" +
      "ontainerReportRequestProto\0223\n\014container_" +
      "id\030\001 \001(\0132\035.hadoop.yarn.ContainerIdProto\"",
      "^\n\037GetContainerReportResponseProto\022;\n\020co" +
      "ntainer_report\030\001 \001(\0132!.hadoop.yarn.Conta" +
      "inerReportProto\"c\n\031GetContainersRequestP" +
      "roto\022F\n\026application_attempt_id\030\001 \001(\0132&.h" +
      "adoop.yarn.ApplicationAttemptIdProto\"S\n\032" +
      "GetContainersResponseProto\0225\n\ncontainers" +
      "\030\001 \003(\0132!.hadoop.yarn.ContainerReportProt" +
      "o\"q\n\"UseSharedCacheResourceRequestProto\022" +
      "6\n\rapplicationId\030\001 \001(\0132\037.hadoop.yarn.App" +
      "licationIdProto\022\023\n\013resourceKey\030\002 \001(\t\"3\n#",
      "UseSharedCacheResourceResponseProto\022\014\n\004p" +
      "ath\030\001 \001(\t\"u\n&ReleaseSharedCacheResourceR" +
      "equestProto\0226\n\rapplicationId\030\001 \001(\0132\037.had" +
      "oop.yarn.ApplicationIdProto\022\023\n\013resourceK" +
      "ey\030\002 \001(\t\")\n\'ReleaseSharedCacheResourceRe" +
      "sponseProto\"\037\n\035GetNewReservationRequestP" +
      "roto\"Y\n\036GetNewReservationResponseProto\0227" +
      "\n\016reservation_id\030\001 \001(\0132\037.hadoop.yarn.Res" +
      "ervationIdProto\"\264\001\n!ReservationSubmissio" +
      "nRequestProto\022\r\n\005queue\030\001 \001(\t\022G\n\026reservat",
      "ion_definition\030\002 \001(\0132\'.hadoop.yarn.Reser" +
      "vationDefinitionProto\0227\n\016reservation_id\030" +
      "\003 \001(\0132\037.hadoop.yarn.ReservationIdProto\"$" +
      "\n\"ReservationSubmissionResponseProto\"\241\001\n" +
      "\035ReservationUpdateRequestProto\022G\n\026reserv" +
      "ation_definition\030\001 \001(\0132\'.hadoop.yarn.Res" +
      "ervationDefinitionProto\0227\n\016reservation_i" +
      "d\030\002 \001(\0132\037.hadoop.yarn.ReservationIdProto" +
      "\" \n\036ReservationUpdateResponseProto\"X\n\035Re" +
      "servationDeleteRequestProto\0227\n\016reservati",
      "on_id\030\001 \001(\0132\037.hadoop.yarn.ReservationIdP" +
      "roto\" \n\036ReservationDeleteResponseProto\"\220" +
      "\001\n\033ReservationListRequestProto\022\r\n\005queue\030" +
      "\001 \001(\t\022\026\n\016reservation_id\030\003 \001(\t\022\022\n\nstart_t" +
      "ime\030\004 \001(\003\022\020\n\010end_time\030\005 \001(\003\022$\n\034include_r" +
      "esource_allocations\030\006 \001(\010\"b\n\034Reservation" +
      "ListResponseProto\022B\n\014reservations\030\001 \003(\0132" +
      ",.hadoop.yarn.ReservationAllocationState" +
      "Proto\"\'\n%RunSharedCacheCleanerTaskReques" +
      "tProto\":\n&RunSharedCacheCleanerTaskRespo",
      "nseProto\022\020\n\010accepted\030\001 \001(\010*-\n\026SchedulerR" +
      "esourceTypes\022\n\n\006MEMORY\020\000\022\007\n\003CPU\020\001*?\n\035App" +
      "licationsRequestScopeProto\022\007\n\003ALL\020\000\022\014\n\010V" +
      "IEWABLE\020\001\022\007\n\003OWN\020\002B9\n\036org.spiderdt.hadoo" +
      "p.yarn.protoB\021YarnServiceProtos\210\001\001\240\001\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
        new com.google.protobuf.Descriptors.FileDescriptor.    InternalDescriptorAssigner() {
          public com.google.protobuf.ExtensionRegistry assignDescriptors(
              com.google.protobuf.Descriptors.FileDescriptor root) {
            descriptor = root;
            return null;
          }
        };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.spiderdt.hadoop.security.proto.SecurityProtos.getDescriptor(),
          org.spiderdt.hadoop.yarn.proto.YarnProtos.getDescriptor(),
        }, assigner);
    internal_static_hadoop_yarn_RegisterApplicationMasterRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_hadoop_yarn_RegisterApplicationMasterRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_RegisterApplicationMasterRequestProto_descriptor,
        new java.lang.String[] { "Host", "RpcPort", "TrackingUrl", });
    internal_static_hadoop_yarn_RegisterApplicationMasterResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_hadoop_yarn_RegisterApplicationMasterResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_RegisterApplicationMasterResponseProto_descriptor,
        new java.lang.String[] { "MaximumCapability", "ClientToAmTokenMasterKey", "ApplicationACLs", "ContainersFromPreviousAttempts", "Queue", "NmTokensFromPreviousAttempts", "SchedulerResourceTypes", });
    internal_static_hadoop_yarn_FinishApplicationMasterRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_hadoop_yarn_FinishApplicationMasterRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_FinishApplicationMasterRequestProto_descriptor,
        new java.lang.String[] { "Diagnostics", "TrackingUrl", "FinalApplicationStatus", });
    internal_static_hadoop_yarn_FinishApplicationMasterResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_hadoop_yarn_FinishApplicationMasterResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_FinishApplicationMasterResponseProto_descriptor,
        new java.lang.String[] { "IsUnregistered", });
    internal_static_hadoop_yarn_AllocateRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_hadoop_yarn_AllocateRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_AllocateRequestProto_descriptor,
        new java.lang.String[] { "Ask", "Release", "BlacklistRequest", "ResponseId", "Progress", "IncreaseRequest", "DecreaseRequest", });
    internal_static_hadoop_yarn_NMTokenProto_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_hadoop_yarn_NMTokenProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_NMTokenProto_descriptor,
        new java.lang.String[] { "NodeId", "Token", });
    internal_static_hadoop_yarn_AllocateResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_hadoop_yarn_AllocateResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_AllocateResponseProto_descriptor,
        new java.lang.String[] { "AMCommand", "ResponseId", "AllocatedContainers", "CompletedContainerStatuses", "Limit", "UpdatedNodes", "NumClusterNodes", "Preempt", "NmTokens", "IncreasedContainers", "DecreasedContainers", "AmRmToken", "ApplicationPriority", "CollectorAddr", });
    internal_static_hadoop_yarn_GetNewApplicationRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_hadoop_yarn_GetNewApplicationRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetNewApplicationRequestProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_GetNewApplicationResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_hadoop_yarn_GetNewApplicationResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetNewApplicationResponseProto_descriptor,
        new java.lang.String[] { "ApplicationId", "MaximumCapability", });
    internal_static_hadoop_yarn_GetApplicationReportRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(9);
    internal_static_hadoop_yarn_GetApplicationReportRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetApplicationReportRequestProto_descriptor,
        new java.lang.String[] { "ApplicationId", });
    internal_static_hadoop_yarn_GetApplicationReportResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(10);
    internal_static_hadoop_yarn_GetApplicationReportResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetApplicationReportResponseProto_descriptor,
        new java.lang.String[] { "ApplicationReport", });
    internal_static_hadoop_yarn_SubmitApplicationRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(11);
    internal_static_hadoop_yarn_SubmitApplicationRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_SubmitApplicationRequestProto_descriptor,
        new java.lang.String[] { "ApplicationSubmissionContext", });
    internal_static_hadoop_yarn_SubmitApplicationResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(12);
    internal_static_hadoop_yarn_SubmitApplicationResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_SubmitApplicationResponseProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_FailApplicationAttemptRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(13);
    internal_static_hadoop_yarn_FailApplicationAttemptRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_FailApplicationAttemptRequestProto_descriptor,
        new java.lang.String[] { "ApplicationAttemptId", });
    internal_static_hadoop_yarn_FailApplicationAttemptResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(14);
    internal_static_hadoop_yarn_FailApplicationAttemptResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_FailApplicationAttemptResponseProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_KillApplicationRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(15);
    internal_static_hadoop_yarn_KillApplicationRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_KillApplicationRequestProto_descriptor,
        new java.lang.String[] { "ApplicationId", });
    internal_static_hadoop_yarn_KillApplicationResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(16);
    internal_static_hadoop_yarn_KillApplicationResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_KillApplicationResponseProto_descriptor,
        new java.lang.String[] { "IsKillCompleted", });
    internal_static_hadoop_yarn_GetClusterMetricsRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(17);
    internal_static_hadoop_yarn_GetClusterMetricsRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetClusterMetricsRequestProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_GetClusterMetricsResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(18);
    internal_static_hadoop_yarn_GetClusterMetricsResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetClusterMetricsResponseProto_descriptor,
        new java.lang.String[] { "ClusterMetrics", });
    internal_static_hadoop_yarn_MoveApplicationAcrossQueuesRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(19);
    internal_static_hadoop_yarn_MoveApplicationAcrossQueuesRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_MoveApplicationAcrossQueuesRequestProto_descriptor,
        new java.lang.String[] { "ApplicationId", "TargetQueue", });
    internal_static_hadoop_yarn_MoveApplicationAcrossQueuesResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(20);
    internal_static_hadoop_yarn_MoveApplicationAcrossQueuesResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_MoveApplicationAcrossQueuesResponseProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_GetApplicationsRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(21);
    internal_static_hadoop_yarn_GetApplicationsRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetApplicationsRequestProto_descriptor,
        new java.lang.String[] { "ApplicationTypes", "ApplicationStates", "Users", "Queues", "Limit", "StartBegin", "StartEnd", "FinishBegin", "FinishEnd", "ApplicationTags", "Scope", });
    internal_static_hadoop_yarn_GetApplicationsResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(22);
    internal_static_hadoop_yarn_GetApplicationsResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetApplicationsResponseProto_descriptor,
        new java.lang.String[] { "Applications", });
    internal_static_hadoop_yarn_GetClusterNodesRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(23);
    internal_static_hadoop_yarn_GetClusterNodesRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetClusterNodesRequestProto_descriptor,
        new java.lang.String[] { "NodeStates", });
    internal_static_hadoop_yarn_GetClusterNodesResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(24);
    internal_static_hadoop_yarn_GetClusterNodesResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetClusterNodesResponseProto_descriptor,
        new java.lang.String[] { "NodeReports", });
    internal_static_hadoop_yarn_GetQueueInfoRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(25);
    internal_static_hadoop_yarn_GetQueueInfoRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetQueueInfoRequestProto_descriptor,
        new java.lang.String[] { "QueueName", "IncludeApplications", "IncludeChildQueues", "Recursive", });
    internal_static_hadoop_yarn_GetQueueInfoResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(26);
    internal_static_hadoop_yarn_GetQueueInfoResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetQueueInfoResponseProto_descriptor,
        new java.lang.String[] { "QueueInfo", });
    internal_static_hadoop_yarn_GetQueueUserAclsInfoRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(27);
    internal_static_hadoop_yarn_GetQueueUserAclsInfoRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetQueueUserAclsInfoRequestProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_GetQueueUserAclsInfoResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(28);
    internal_static_hadoop_yarn_GetQueueUserAclsInfoResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetQueueUserAclsInfoResponseProto_descriptor,
        new java.lang.String[] { "QueueUserAcls", });
    internal_static_hadoop_yarn_GetNodesToLabelsRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(29);
    internal_static_hadoop_yarn_GetNodesToLabelsRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetNodesToLabelsRequestProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_GetNodesToLabelsResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(30);
    internal_static_hadoop_yarn_GetNodesToLabelsResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetNodesToLabelsResponseProto_descriptor,
        new java.lang.String[] { "NodeToLabels", });
    internal_static_hadoop_yarn_GetLabelsToNodesRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(31);
    internal_static_hadoop_yarn_GetLabelsToNodesRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetLabelsToNodesRequestProto_descriptor,
        new java.lang.String[] { "NodeLabels", });
    internal_static_hadoop_yarn_GetLabelsToNodesResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(32);
    internal_static_hadoop_yarn_GetLabelsToNodesResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetLabelsToNodesResponseProto_descriptor,
        new java.lang.String[] { "LabelsToNodes", });
    internal_static_hadoop_yarn_GetClusterNodeLabelsRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(33);
    internal_static_hadoop_yarn_GetClusterNodeLabelsRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetClusterNodeLabelsRequestProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_GetClusterNodeLabelsResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(34);
    internal_static_hadoop_yarn_GetClusterNodeLabelsResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetClusterNodeLabelsResponseProto_descriptor,
        new java.lang.String[] { "NodeLabels", });
    internal_static_hadoop_yarn_UpdateApplicationPriorityRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(35);
    internal_static_hadoop_yarn_UpdateApplicationPriorityRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_UpdateApplicationPriorityRequestProto_descriptor,
        new java.lang.String[] { "ApplicationId", "ApplicationPriority", });
    internal_static_hadoop_yarn_UpdateApplicationPriorityResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(36);
    internal_static_hadoop_yarn_UpdateApplicationPriorityResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_UpdateApplicationPriorityResponseProto_descriptor,
        new java.lang.String[] { "ApplicationPriority", });
    internal_static_hadoop_yarn_SignalContainerRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(37);
    internal_static_hadoop_yarn_SignalContainerRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_SignalContainerRequestProto_descriptor,
        new java.lang.String[] { "ContainerId", "Command", });
    internal_static_hadoop_yarn_SignalContainerResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(38);
    internal_static_hadoop_yarn_SignalContainerResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_SignalContainerResponseProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_StartContainerRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(39);
    internal_static_hadoop_yarn_StartContainerRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_StartContainerRequestProto_descriptor,
        new java.lang.String[] { "ContainerLaunchContext", "ContainerToken", });
    internal_static_hadoop_yarn_StartContainerResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(40);
    internal_static_hadoop_yarn_StartContainerResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_StartContainerResponseProto_descriptor,
        new java.lang.String[] { "ServicesMetaData", });
    internal_static_hadoop_yarn_StopContainerRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(41);
    internal_static_hadoop_yarn_StopContainerRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_StopContainerRequestProto_descriptor,
        new java.lang.String[] { "ContainerId", });
    internal_static_hadoop_yarn_StopContainerResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(42);
    internal_static_hadoop_yarn_StopContainerResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_StopContainerResponseProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_ResourceLocalizationRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(43);
    internal_static_hadoop_yarn_ResourceLocalizationRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ResourceLocalizationRequestProto_descriptor,
        new java.lang.String[] { "ContainerId", "LocalResources", });
    internal_static_hadoop_yarn_ResourceLocalizationResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(44);
    internal_static_hadoop_yarn_ResourceLocalizationResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ResourceLocalizationResponseProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_StartContainersRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(45);
    internal_static_hadoop_yarn_StartContainersRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_StartContainersRequestProto_descriptor,
        new java.lang.String[] { "StartContainerRequest", });
    internal_static_hadoop_yarn_ContainerExceptionMapProto_descriptor =
      getDescriptor().getMessageTypes().get(46);
    internal_static_hadoop_yarn_ContainerExceptionMapProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ContainerExceptionMapProto_descriptor,
        new java.lang.String[] { "ContainerId", "Exception", });
    internal_static_hadoop_yarn_StartContainersResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(47);
    internal_static_hadoop_yarn_StartContainersResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_StartContainersResponseProto_descriptor,
        new java.lang.String[] { "ServicesMetaData", "SucceededRequests", "FailedRequests", });
    internal_static_hadoop_yarn_StopContainersRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(48);
    internal_static_hadoop_yarn_StopContainersRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_StopContainersRequestProto_descriptor,
        new java.lang.String[] { "ContainerId", });
    internal_static_hadoop_yarn_StopContainersResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(49);
    internal_static_hadoop_yarn_StopContainersResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_StopContainersResponseProto_descriptor,
        new java.lang.String[] { "SucceededRequests", "FailedRequests", });
    internal_static_hadoop_yarn_GetContainerStatusesRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(50);
    internal_static_hadoop_yarn_GetContainerStatusesRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetContainerStatusesRequestProto_descriptor,
        new java.lang.String[] { "ContainerId", });
    internal_static_hadoop_yarn_GetContainerStatusesResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(51);
    internal_static_hadoop_yarn_GetContainerStatusesResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetContainerStatusesResponseProto_descriptor,
        new java.lang.String[] { "Status", "FailedRequests", });
    internal_static_hadoop_yarn_IncreaseContainersResourceRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(52);
    internal_static_hadoop_yarn_IncreaseContainersResourceRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_IncreaseContainersResourceRequestProto_descriptor,
        new java.lang.String[] { "IncreaseContainers", });
    internal_static_hadoop_yarn_IncreaseContainersResourceResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(53);
    internal_static_hadoop_yarn_IncreaseContainersResourceResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_IncreaseContainersResourceResponseProto_descriptor,
        new java.lang.String[] { "SucceededRequests", "FailedRequests", });
    internal_static_hadoop_yarn_GetApplicationAttemptReportRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(54);
    internal_static_hadoop_yarn_GetApplicationAttemptReportRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetApplicationAttemptReportRequestProto_descriptor,
        new java.lang.String[] { "ApplicationAttemptId", });
    internal_static_hadoop_yarn_GetApplicationAttemptReportResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(55);
    internal_static_hadoop_yarn_GetApplicationAttemptReportResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetApplicationAttemptReportResponseProto_descriptor,
        new java.lang.String[] { "ApplicationAttemptReport", });
    internal_static_hadoop_yarn_GetApplicationAttemptsRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(56);
    internal_static_hadoop_yarn_GetApplicationAttemptsRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetApplicationAttemptsRequestProto_descriptor,
        new java.lang.String[] { "ApplicationId", });
    internal_static_hadoop_yarn_GetApplicationAttemptsResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(57);
    internal_static_hadoop_yarn_GetApplicationAttemptsResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetApplicationAttemptsResponseProto_descriptor,
        new java.lang.String[] { "ApplicationAttempts", });
    internal_static_hadoop_yarn_GetContainerReportRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(58);
    internal_static_hadoop_yarn_GetContainerReportRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetContainerReportRequestProto_descriptor,
        new java.lang.String[] { "ContainerId", });
    internal_static_hadoop_yarn_GetContainerReportResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(59);
    internal_static_hadoop_yarn_GetContainerReportResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetContainerReportResponseProto_descriptor,
        new java.lang.String[] { "ContainerReport", });
    internal_static_hadoop_yarn_GetContainersRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(60);
    internal_static_hadoop_yarn_GetContainersRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetContainersRequestProto_descriptor,
        new java.lang.String[] { "ApplicationAttemptId", });
    internal_static_hadoop_yarn_GetContainersResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(61);
    internal_static_hadoop_yarn_GetContainersResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetContainersResponseProto_descriptor,
        new java.lang.String[] { "Containers", });
    internal_static_hadoop_yarn_UseSharedCacheResourceRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(62);
    internal_static_hadoop_yarn_UseSharedCacheResourceRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_UseSharedCacheResourceRequestProto_descriptor,
        new java.lang.String[] { "ApplicationId", "ResourceKey", });
    internal_static_hadoop_yarn_UseSharedCacheResourceResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(63);
    internal_static_hadoop_yarn_UseSharedCacheResourceResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_UseSharedCacheResourceResponseProto_descriptor,
        new java.lang.String[] { "Path", });
    internal_static_hadoop_yarn_ReleaseSharedCacheResourceRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(64);
    internal_static_hadoop_yarn_ReleaseSharedCacheResourceRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ReleaseSharedCacheResourceRequestProto_descriptor,
        new java.lang.String[] { "ApplicationId", "ResourceKey", });
    internal_static_hadoop_yarn_ReleaseSharedCacheResourceResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(65);
    internal_static_hadoop_yarn_ReleaseSharedCacheResourceResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ReleaseSharedCacheResourceResponseProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_GetNewReservationRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(66);
    internal_static_hadoop_yarn_GetNewReservationRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetNewReservationRequestProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_GetNewReservationResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(67);
    internal_static_hadoop_yarn_GetNewReservationResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_GetNewReservationResponseProto_descriptor,
        new java.lang.String[] { "ReservationId", });
    internal_static_hadoop_yarn_ReservationSubmissionRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(68);
    internal_static_hadoop_yarn_ReservationSubmissionRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ReservationSubmissionRequestProto_descriptor,
        new java.lang.String[] { "Queue", "ReservationDefinition", "ReservationId", });
    internal_static_hadoop_yarn_ReservationSubmissionResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(69);
    internal_static_hadoop_yarn_ReservationSubmissionResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ReservationSubmissionResponseProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_ReservationUpdateRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(70);
    internal_static_hadoop_yarn_ReservationUpdateRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ReservationUpdateRequestProto_descriptor,
        new java.lang.String[] { "ReservationDefinition", "ReservationId", });
    internal_static_hadoop_yarn_ReservationUpdateResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(71);
    internal_static_hadoop_yarn_ReservationUpdateResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ReservationUpdateResponseProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_ReservationDeleteRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(72);
    internal_static_hadoop_yarn_ReservationDeleteRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ReservationDeleteRequestProto_descriptor,
        new java.lang.String[] { "ReservationId", });
    internal_static_hadoop_yarn_ReservationDeleteResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(73);
    internal_static_hadoop_yarn_ReservationDeleteResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ReservationDeleteResponseProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_ReservationListRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(74);
    internal_static_hadoop_yarn_ReservationListRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ReservationListRequestProto_descriptor,
        new java.lang.String[] { "Queue", "ReservationId", "StartTime", "EndTime", "IncludeResourceAllocations", });
    internal_static_hadoop_yarn_ReservationListResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(75);
    internal_static_hadoop_yarn_ReservationListResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ReservationListResponseProto_descriptor,
        new java.lang.String[] { "Reservations", });
    internal_static_hadoop_yarn_RunSharedCacheCleanerTaskRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(76);
    internal_static_hadoop_yarn_RunSharedCacheCleanerTaskRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_RunSharedCacheCleanerTaskRequestProto_descriptor,
        new java.lang.String[] { });
    internal_static_hadoop_yarn_RunSharedCacheCleanerTaskResponseProto_descriptor =
      getDescriptor().getMessageTypes().get(77);
    internal_static_hadoop_yarn_RunSharedCacheCleanerTaskResponseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_RunSharedCacheCleanerTaskResponseProto_descriptor,
        new java.lang.String[] { "Accepted", });
    org.spiderdt.hadoop.security.proto.SecurityProtos.getDescriptor();
    org.spiderdt.hadoop.yarn.proto.YarnProtos.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
